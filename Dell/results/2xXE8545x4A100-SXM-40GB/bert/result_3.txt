Beginning trial 04 of 10
:::DLPAL /mnt/data/bert_20221004.sif 2504 2 node[025-026]
hosts=node025 node026 
Clearing cache on node025
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665639834569, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node026
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665639839423, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
SLURM_JOB_NUM_NODES_DGXNGPU=8
3: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
1: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
2: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
0: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
4: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
5: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
6: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
7: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
1: + source ./config_2xXE8545x4A100-SXM4-40GB.sh
1: ++ export BATCHSIZE=56
1: ++ BATCHSIZE=56
1: ++ export GRADIENT_STEPS=2
1: ++ GRADIENT_STEPS=2
1: ++ export LR=0.000425
1: ++ LR=0.000425
1: ++ export MAX_SAMPLES_TERMINATION=4500000
1: ++ MAX_SAMPLES_TERMINATION=4500000
1: ++ export MAX_STEPS=6700
1: ++ MAX_STEPS=6700
1: ++ export OPT_LAMB_BETA_1=0.9
1: ++ OPT_LAMB_BETA_1=0.9
1: ++ export OPT_LAMB_BETA_2=0.999
1: ++ OPT_LAMB_BETA_2=0.999
1: ++ export START_WARMUP_STEP=0
1: ++ START_WARMUP_STEP=0
1: ++ export WARMUP_PROPORTION=0.0
1: ++ WARMUP_PROPORTION=0.0
1: ++ export WEIGHT_DECAY_RATE=0.01
1: ++ WEIGHT_DECAY_RATE=0.01
1: ++ export INIT_LOSS_SCALE=1024.0
1: ++ INIT_LOSS_SCALE=1024.0
1: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
1: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
1: ++ export PHASE=2
1: ++ PHASE=2
1: ++ export EVAL_ITER_START_SAMPLES=150000
1: ++ EVAL_ITER_START_SAMPLES=150000
1: ++ export EVAL_ITER_SAMPLES=150000
1: ++ EVAL_ITER_SAMPLES=150000
1: ++ export DGXNNODES=1
1: ++ DGXNNODES=1
1: +++ sed 's/^config_//'
1: +++ sed 's/\.sh$//'
1: ++++ readlink -f ./config_2xXE8545x4A100-SXM4-40GB.sh
1: +++ basename /workspace/bert/config_2xXE8545x4A100-SXM4-40GB.sh
1: ++ export DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
1: ++ DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
1: ++ export WALLTIME=01:15:00
1: ++ WALLTIME=01:15:00
1: ++ export DGXNGPU=4
1: ++ DGXNGPU=4
1: ++ export DGXSOCKETCORES=64
1: ++ DGXSOCKETCORES=64
1: ++ export DGXNSOCKET=2
1: ++ DGXNSOCKET=2
1: ++ export DGXHT=1
1: ++ DGXHT=1
1: ++ export MLPERF_SUBMISSION_ORG=Dell
1: ++ MLPERF_SUBMISSION_ORG=Dell
1: ++ export MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
1: ++ MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
1: ++ export OMP_NUM_THREADS=8
1: ++ OMP_NUM_THREADS=8
1: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
1: + ulimit -Sn 100000
1: + '[' '' = 1 ']'
1: + : 56
1: + : 2
1: + : 0.000425
1: + : 6700
1: + : 2
1: + : 1
1: + : ''
1: + : ''\'''\'''
1: + : 7410
1: + : 2504
1: + : 0
1: + : 4
1: + : ''
1: + : 0
1: + : 150000
1: + : 150000
1: + : 4500000
1: + : 0.9
1: + : 0.999
1: + : 0
1: + : 0.720
1: + : 0
1: + : 0.0
1: + : 0.0
1: + : 0.01
1: + : 0
1: + : 0
1: + : 0
1: + : 0
1: + : 0
1: + : 0
1: + echo 'Run vars: id 2504 gpus 4 mparams '\'''\'''
1: Run vars: id 2504 gpus 4 mparams ''
1: ++ date +%s
1: + START=1665639842
1: ++ date '+%Y-%m-%d %r'
1: + START_FMT='2022-10-13 12:44:02 AM'
1: STARTING TIMING RUN AT 2022-10-13 12:44:02 AM
1: + echo 'STARTING TIMING RUN AT 2022-10-13 12:44:02 AM'
1: + '[' '!' -z '' ']'
1: + '[' 0 -gt 0 ']'
1: + PHASE1='    --train_batch_size=56     --learning_rate=0.000425     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
1: + PHASE2='    --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
1: + PHASES=("$PHASE1" "$PHASE2")
1: + export RANK=1
1: + RANK=1
1: + export WORLD_SIZE=8
1: + WORLD_SIZE=8
1: WORLD_SIZE=8
1: + echo WORLD_SIZE=8
1: ++ cut -d - -f1
1: ++ cut -d - -f2 -
1: ++ tr -d '['
1: ++ echo 'node[025-026]'
1: + export MASTER_ADDR=node025
1: + MASTER_ADDR=node025
1: MASTER_ADDR=node025
1: + echo MASTER_ADDR=node025
1: + export MASTER_PORT=19002
1: + MASTER_PORT=19002
1: + echo HOSTNAME=node025
1: HOSTNAME=node025
1: + declare -a CMD
1: + [[ -n 1 ]]
1: + [[ 8 -gt 2 ]]
1: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
1:  --bert_config_path=/workspace/phase1/bert_config.json '
1: + '[' -n 1 ']'
1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
1:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
1: + [[ 0 != 1 ]]
1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
1:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
1: + [[ '' -ge 1 ]]
1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
1:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu  '
1: + [[ 0 != 0 ]]
1: + '[' '' = apiLog.sh ']'
1: + '[' '' = 1 ']'
1: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0     --
1: bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu   --seed=7410'
1: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=56 --learning_rate=0.000425 --opt_lamb_beta_1=0.9 --opt_lamb_beta_2=0.999 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=6700 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=150000 --eval_iter_samples=150000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=2 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --de
1: nse_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=7410
2: + source ./config_2xXE8545x4A100-SXM4-40GB.sh
2: ++ export BATCHSIZE=56
2: ++ BATCHSIZE=56
2: ++ export GRADIENT_STEPS=2
2: ++ GRADIENT_STEPS=2
2: ++ export LR=0.000425
2: ++ LR=0.000425
2: ++ export MAX_SAMPLES_TERMINATION=4500000
2: ++ MAX_SAMPLES_TERMINATION=4500000
2: ++ export MAX_STEPS=6700
2: ++ MAX_STEPS=6700
2: ++ export OPT_LAMB_BETA_1=0.9
2: ++ OPT_LAMB_BETA_1=0.9
2: ++ export OPT_LAMB_BETA_2=0.999
2: ++ OPT_LAMB_BETA_2=0.999
2: ++ export START_WARMUP_STEP=0
2: ++ START_WARMUP_STEP=0
2: ++ export WARMUP_PROPORTION=0.0
2: ++ WARMUP_PROPORTION=0.0
2: ++ export WEIGHT_DECAY_RATE=0.01
2: ++ WEIGHT_DECAY_RATE=0.01
2: ++ export INIT_LOSS_SCALE=1024.0
2: ++ INIT_LOSS_SCALE=1024.0
2: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
2: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
2: ++ export PHASE=2
2: ++ PHASE=2
2: ++ export EVAL_ITER_START_SAMPLES=150000
2: ++ EVAL_ITER_START_SAMPLES=150000
2: ++ export EVAL_ITER_SAMPLES=150000
2: ++ EVAL_ITER_SAMPLES=150000
2: ++ export DGXNNODES=1
2: ++ DGXNNODES=1
2: +++ sed 's/^config_//'
2: +++ sed 's/\.sh$//'
2: ++++ readlink -f ./config_2xXE8545x4A100-SXM4-40GB.sh
2: +++ basename /workspace/bert/config_2xXE8545x4A100-SXM4-40GB.sh
2: ++ export DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
2: ++ DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
2: ++ export WALLTIME=01:15:00
2: ++ WALLTIME=01:15:00
2: ++ export DGXNGPU=4
2: ++ DGXNGPU=4
2: ++ export DGXSOCKETCORES=64
2: ++ DGXSOCKETCORES=64
2: ++ export DGXNSOCKET=2
2: ++ DGXNSOCKET=2
2: ++ export DGXHT=1
2: ++ DGXHT=1
2: ++ export MLPERF_SUBMISSION_ORG=Dell
2: ++ MLPERF_SUBMISSION_ORG=Dell
2: ++ export MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
2: ++ MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
2: ++ export OMP_NUM_THREADS=8
2: ++ OMP_NUM_THREADS=8
2: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
2: + ulimit -Sn 100000
2: + '[' '' = 1 ']'
2: + : 56
2: + : 2
2: + : 0.000425
2: + : 6700
2: + : 2
2: + : 2
2: + : ''
2: + : ''\'''\'''
2: + : 27448
2: + : 2504
2: + : 0
2: + : 4
2: + : ''
2: + : 0
2: + : 150000
2: + : 150000
2: + : 4500000
2: + : 0.9
2: + : 0.999
2: + : 0
2: + : 0.720
2: + : 0
2: + : 0.0
2: + : 0.0
2: + : 0.01
2: + : 0
2: + : 0
2: + : 0
2: + : 0
2: + : 0
2: + : 0
2: + echo 'Run vars: id 2504 gpus 4 mparams '\'''\'''
2: Run vars: id 2504 gpus 4 mparams ''
2: ++ date +%s
2: + START=1665639842
2: ++ date '+%Y-%m-%d %r'
2: + START_FMT='2022-10-13 12:44:02 AM'
2: + echo 'STARTING TIMING RUN AT 2022-10-13 12:44:02 AM'
2: STARTING TIMING RUN AT 2022-10-13 12:44:02 AM
2: + '[' '!' -z '' ']'
2: + '[' 0 -gt 0 ']'
2: + PHASE1='    --train_batch_size=56     --learning_rate=0.000425     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
2: + PHASE2='    --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
2: + PHASES=("$PHASE1" "$PHASE2")
2: + export RANK=2
2: + RANK=2
2: + export WORLD_SIZE=8
2: + WORLD_SIZE=8
2: + echo WORLD_SIZE=8
2: WORLD_SIZE=8
2: ++ cut -d - -f1
2: ++ cut -d - -f2 -
2: ++ echo 'node[025-026]'
2: ++ tr -d '['
2: + export MASTER_ADDR=node025
2: + MASTER_ADDR=node025
2: + echo MASTER_ADDR=node025
2: MASTER_ADDR=node025
2: + export MASTER_PORT=19002
2: + MASTER_PORT=19002
2: HOSTNAME=node025
2: + echo HOSTNAME=node025
2: + declare -a CMD
2: + [[ -n 2 ]]
2: + [[ 8 -gt 2 ]]
2: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
2:  --bert_config_path=/workspace/phase1/bert_config.json '
2: + '[' -n 2 ']'
2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
2:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
2: + [[ 0 != 1 ]]
2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
2:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
2: + [[ '' -ge 1 ]]
2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
2:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu  '
2: + [[ 0 != 0 ]]
2: + '[' '' = apiLog.sh ']'
2: + '[' '' = 1 ']'
2: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0     --
2: bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu   --seed=27448'
2: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=56 --learning_rate=0.000425 --opt_lamb_beta_1=0.9 --opt_lamb_beta_2=0.999 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=6700 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=150000 --eval_iter_samples=150000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=2 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --de
2: nse_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=27448
3: + source ./config_2xXE8545x4A100-SXM4-40GB.sh
3: ++ export BATCHSIZE=56
3: ++ BATCHSIZE=56
3: ++ export GRADIENT_STEPS=2
3: ++ GRADIENT_STEPS=2
3: ++ export LR=0.000425
3: ++ LR=0.000425
3: ++ export MAX_SAMPLES_TERMINATION=4500000
3: ++ MAX_SAMPLES_TERMINATION=4500000
3: ++ export MAX_STEPS=6700
3: ++ MAX_STEPS=6700
3: ++ export OPT_LAMB_BETA_1=0.9
3: ++ OPT_LAMB_BETA_1=0.9
3: ++ export OPT_LAMB_BETA_2=0.999
3: ++ OPT_LAMB_BETA_2=0.999
3: ++ export START_WARMUP_STEP=0
3: ++ START_WARMUP_STEP=0
3: ++ export WARMUP_PROPORTION=0.0
3: ++ WARMUP_PROPORTION=0.0
3: ++ export WEIGHT_DECAY_RATE=0.01
3: ++ WEIGHT_DECAY_RATE=0.01
3: ++ export INIT_LOSS_SCALE=1024.0
3: ++ INIT_LOSS_SCALE=1024.0
3: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
3: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
3: ++ export PHASE=2
3: ++ PHASE=2
3: ++ export EVAL_ITER_START_SAMPLES=150000
3: ++ EVAL_ITER_START_SAMPLES=150000
3: ++ export EVAL_ITER_SAMPLES=150000
3: ++ EVAL_ITER_SAMPLES=150000
3: ++ export DGXNNODES=1
3: ++ DGXNNODES=1
3: +++ sed 's/^config_//'
3: ++++ readlink -f ./config_2xXE8545x4A100-SXM4-40GB.sh
3: +++ sed 's/\.sh$//'
3: +++ basename /workspace/bert/config_2xXE8545x4A100-SXM4-40GB.sh
3: ++ export DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
3: ++ DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
3: ++ export WALLTIME=01:15:00
3: ++ WALLTIME=01:15:00
3: ++ export DGXNGPU=4
3: ++ DGXNGPU=4
3: ++ export DGXSOCKETCORES=64
3: ++ DGXSOCKETCORES=64
3: ++ export DGXNSOCKET=2
3: ++ DGXNSOCKET=2
3: ++ export DGXHT=1
3: ++ DGXHT=1
3: ++ export MLPERF_SUBMISSION_ORG=Dell
3: ++ MLPERF_SUBMISSION_ORG=Dell
3: ++ export MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
3: ++ MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
3: ++ export OMP_NUM_THREADS=8
3: ++ OMP_NUM_THREADS=8
3: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
3: + ulimit -Sn 100000
3: + '[' '' = 1 ']'
3: + : 56
3: + : 2
3: + : 0.000425
3: + : 6700
3: + : 2
3: + : 3
3: + : ''
3: + : ''\'''\'''
3: + : 20747
3: + : 2504
3: + : 0
3: + : 4
3: + : ''
3: + : 0
3: + : 150000
3: + : 150000
3: + : 4500000
3: + : 0.9
3: + : 0.999
3: + : 0
3: + : 0.720
3: + : 0
3: + : 0.0
3: + : 0.0
3: + : 0.01
3: + : 0
3: + : 0
3: + : 0
3: + : 0
3: + : 0
3: + : 0
3: + echo 'Run vars: id 2504 gpus 4 mparams '\'''\'''
3: Run vars: id 2504 gpus 4 mparams ''
3: ++ date +%s
3: + START=1665639842
3: ++ date '+%Y-%m-%d %r'
3: + START_FMT='2022-10-13 12:44:02 AM'
3: + echo 'STARTING TIMING RUN AT 2022-10-13 12:44:02 AM'
3: STARTING TIMING RUN AT 2022-10-13 12:44:02 AM
3: + '[' '!' -z '' ']'
3: + '[' 0 -gt 0 ']'
3: + PHASE1='    --train_batch_size=56     --learning_rate=0.000425     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
3: + PHASE2='    --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
3: + PHASES=("$PHASE1" "$PHASE2")
3: + export RANK=3
3: + RANK=3
3: + export WORLD_SIZE=8
3: + WORLD_SIZE=8
3: + echo WORLD_SIZE=8
3: WORLD_SIZE=8
3: ++ cut -d - -f1
3: ++ cut -d - -f2 -
3: ++ echo 'node[025-026]'
3: ++ tr -d '['
3: + export MASTER_ADDR=node025
3: + MASTER_ADDR=node025
3: MASTER_ADDR=node025
3: + echo MASTER_ADDR=node025
3: + export MASTER_PORT=19002
3: + MASTER_PORT=19002
3: HOSTNAME=node025
3: + echo HOSTNAME=node025
3: + declare -a CMD
3: + [[ -n 3 ]]
3: + [[ 8 -gt 2 ]]
3: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
3:  --bert_config_path=/workspace/phase1/bert_config.json '
3: + '[' -n 3 ']'
3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
3:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
3: + [[ 0 != 1 ]]
3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
3:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
3: + [[ '' -ge 1 ]]
3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
3:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu  '
3: + [[ 0 != 0 ]]
3: + '[' '' = apiLog.sh ']'
3: + '[' '' = 1 ']'
3: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0     --
3: bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu   --seed=20747'
3: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=56 --learning_rate=0.000425 --opt_lamb_beta_1=0.9 --opt_lamb_beta_2=0.999 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=6700 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=150000 --eval_iter_samples=150000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=2 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --de
3: nse_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=20747
0: + source ./config_2xXE8545x4A100-SXM4-40GB.sh
0: ++ export BATCHSIZE=56
0: ++ BATCHSIZE=56
0: ++ export GRADIENT_STEPS=2
0: ++ GRADIENT_STEPS=2
0: ++ export LR=0.000425
0: ++ LR=0.000425
0: ++ export MAX_SAMPLES_TERMINATION=4500000
0: ++ MAX_SAMPLES_TERMINATION=4500000
0: ++ export MAX_STEPS=6700
0: ++ MAX_STEPS=6700
0: ++ export OPT_LAMB_BETA_1=0.9
0: ++ OPT_LAMB_BETA_1=0.9
0: ++ export OPT_LAMB_BETA_2=0.999
0: ++ OPT_LAMB_BETA_2=0.999
0: ++ export START_WARMUP_STEP=0
0: ++ START_WARMUP_STEP=0
0: ++ export WARMUP_PROPORTION=0.0
0: ++ WARMUP_PROPORTION=0.0
0: ++ export WEIGHT_DECAY_RATE=0.01
0: ++ WEIGHT_DECAY_RATE=0.01
0: ++ export INIT_LOSS_SCALE=1024.0
0: ++ INIT_LOSS_SCALE=1024.0
0: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
0: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
0: ++ export PHASE=2
0: ++ PHASE=2
0: ++ export EVAL_ITER_START_SAMPLES=150000
0: ++ EVAL_ITER_START_SAMPLES=150000
0: ++ export EVAL_ITER_SAMPLES=150000
0: ++ EVAL_ITER_SAMPLES=150000
0: ++ export DGXNNODES=1
0: ++ DGXNNODES=1
0: +++ sed 's/^config_//'
0: +++ sed 's/\.sh$//'
0: ++++ readlink -f ./config_2xXE8545x4A100-SXM4-40GB.sh
0: +++ basename /workspace/bert/config_2xXE8545x4A100-SXM4-40GB.sh
0: ++ export DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
0: ++ DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
0: ++ export WALLTIME=01:15:00
0: ++ WALLTIME=01:15:00
0: ++ export DGXNGPU=4
0: ++ DGXNGPU=4
0: ++ export DGXSOCKETCORES=64
0: ++ DGXSOCKETCORES=64
0: ++ export DGXNSOCKET=2
0: ++ DGXNSOCKET=2
0: ++ export DGXHT=1
0: ++ DGXHT=1
0: ++ export MLPERF_SUBMISSION_ORG=Dell
0: ++ MLPERF_SUBMISSION_ORG=Dell
0: ++ export MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
0: ++ MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
0: ++ export OMP_NUM_THREADS=8
0: ++ OMP_NUM_THREADS=8
0: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
0: + ulimit -Sn 100000
0: + '[' '' = 1 ']'
0: + : 56
0: + : 2
0: + : 0.000425
0: + : 6700
0: + : 2
0: + : 0
0: + : ''
0: + : ''\'''\'''
0: + : 13191
0: + : 2504
0: + : 0
0: + : 4
0: + : ''
0: + : 0
0: + : 150000
0: + : 150000
0: + : 4500000
0: + : 0.9
0: + : 0.999
0: + : 0
0: + : 0.720
0: + : 0
0: + : 0.0
0: + : 0.0
0: + : 0.01
0: + : 0
0: + : 0
0: + : 0
0: + : 0
0: + : 0
0: + : 0
0: + echo 'Run vars: id 2504 gpus 4 mparams '\'''\'''
0: Run vars: id 2504 gpus 4 mparams ''
0: ++ date +%s
0: + START=1665639842
0: ++ date '+%Y-%m-%d %r'
0: + START_FMT='2022-10-13 12:44:02 AM'
0: + echo 'STARTING TIMING RUN AT 2022-10-13 12:44:02 AM'
0: STARTING TIMING RUN AT 2022-10-13 12:44:02 AM
0: + '[' '!' -z '' ']'
0: + '[' 0 -gt 0 ']'
0: + PHASE1='    --train_batch_size=56     --learning_rate=0.000425     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
0: + PHASE2='    --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
0: + PHASES=("$PHASE1" "$PHASE2")
0: + export RANK=0
0: + RANK=0
0: + export WORLD_SIZE=8
0: + WORLD_SIZE=8
0: + echo WORLD_SIZE=8
0: WORLD_SIZE=8
0: ++ cut -d - -f1
0: ++ echo 'node[025-026]'
0: ++ cut -d - -f2 -
0: ++ tr -d '['
0: + export MASTER_ADDR=node025
0: + MASTER_ADDR=node025
0: MASTER_ADDR=node025
0: + echo MASTER_ADDR=node025
0: + export MASTER_PORT=19002
0: + MASTER_PORT=19002
0: + echo HOSTNAME=node025
0: HOSTNAME=node025
0: + declare -a CMD
0: + [[ -n 0 ]]
0: + [[ 8 -gt 2 ]]
0: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
0:  --bert_config_path=/workspace/phase1/bert_config.json '
0: + '[' -n 0 ']'
0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
0:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
0: + [[ 0 != 1 ]]
0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
0:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
0: + [[ '' -ge 1 ]]
0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
0:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu  '
0: + [[ 0 != 0 ]]
0: + '[' '' = apiLog.sh ']'
0: + '[' '' = 1 ']'
0: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0     --
0: bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu   --seed=13191'
0: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=56 --learning_rate=0.000425 --opt_lamb_beta_1=0.9 --opt_lamb_beta_2=0.999 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=6700 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=150000 --eval_iter_samples=150000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=2 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --de
0: nse_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=13191
4: + source ./config_2xXE8545x4A100-SXM4-40GB.sh
4: ++ export BATCHSIZE=56
4: ++ BATCHSIZE=56
4: ++ export GRADIENT_STEPS=2
4: ++ GRADIENT_STEPS=2
4: ++ export LR=0.000425
4: ++ LR=0.000425
4: ++ export MAX_SAMPLES_TERMINATION=4500000
4: ++ MAX_SAMPLES_TERMINATION=4500000
4: ++ export MAX_STEPS=6700
4: ++ MAX_STEPS=6700
4: ++ export OPT_LAMB_BETA_1=0.9
4: ++ OPT_LAMB_BETA_1=0.9
4: ++ export OPT_LAMB_BETA_2=0.999
4: ++ OPT_LAMB_BETA_2=0.999
4: ++ export START_WARMUP_STEP=0
4: ++ START_WARMUP_STEP=0
4: ++ export WARMUP_PROPORTION=0.0
4: ++ WARMUP_PROPORTION=0.0
4: ++ export WEIGHT_DECAY_RATE=0.01
4: ++ WEIGHT_DECAY_RATE=0.01
4: ++ export INIT_LOSS_SCALE=1024.0
4: ++ INIT_LOSS_SCALE=1024.0
4: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
4: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
4: ++ export PHASE=2
4: ++ PHASE=2
4: ++ export EVAL_ITER_START_SAMPLES=150000
4: ++ EVAL_ITER_START_SAMPLES=150000
4: ++ export EVAL_ITER_SAMPLES=150000
4: ++ EVAL_ITER_SAMPLES=150000
4: ++ export DGXNNODES=1
4: ++ DGXNNODES=1
4: +++ sed 's/^config_//'
4: ++++ readlink -f ./config_2xXE8545x4A100-SXM4-40GB.sh
4: +++ sed 's/\.sh$//'
4: +++ basename /workspace/bert/config_2xXE8545x4A100-SXM4-40GB.sh
4: ++ export DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
4: ++ DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
4: ++ export WALLTIME=01:15:00
4: ++ WALLTIME=01:15:00
4: ++ export DGXNGPU=4
4: ++ DGXNGPU=4
4: ++ export DGXSOCKETCORES=64
4: ++ DGXSOCKETCORES=64
4: ++ export DGXNSOCKET=2
4: ++ DGXNSOCKET=2
4: ++ export DGXHT=1
4: ++ DGXHT=1
4: ++ export MLPERF_SUBMISSION_ORG=Dell
4: ++ MLPERF_SUBMISSION_ORG=Dell
4: ++ export MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
4: ++ MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
4: ++ export OMP_NUM_THREADS=8
4: ++ OMP_NUM_THREADS=8
4: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
4: + ulimit -Sn 100000
4: + '[' '' = 1 ']'
4: + : 56
4: + : 2
4: + : 0.000425
4: + : 6700
4: + : 2
4: + : 0
4: + : ''
4: + : ''\'''\'''
4: + : 14812
4: + : 2504
4: + : 1
4: + : 4
4: + : ''
4: + : 0
4: + : 150000
4: + : 150000
4: + : 4500000
4: + : 0.9
4: + : 0.999
4: + : 0
4: + : 0.720
4: + : 0
4: + : 0.0
4: + : 0.0
4: + : 0.01
4: + : 0
4: + : 0
4: + : 0
4: + : 0
4: + : 0
4: + : 0
4: + echo 'Run vars: id 2504 gpus 4 mparams '\'''\'''
4: Run vars: id 2504 gpus 4 mparams ''
4: ++ date +%s
4: + START=1665639842
4: ++ date '+%Y-%m-%d %r'
4: + START_FMT='2022-10-13 12:44:02 AM'
4: STARTING TIMING RUN AT 2022-10-13 12:44:02 AM
4: + echo 'STARTING TIMING RUN AT 2022-10-13 12:44:02 AM'
4: + '[' '!' -z '' ']'
4: + '[' 0 -gt 0 ']'
4: + PHASE1='    --train_batch_size=56     --learning_rate=0.000425     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
4: + PHASE2='    --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
4: + PHASES=("$PHASE1" "$PHASE2")
4: + export RANK=4
4: + RANK=4
4: + export WORLD_SIZE=8
4: + WORLD_SIZE=8
4: + echo WORLD_SIZE=8
4: WORLD_SIZE=8
4: ++ cut -d - -f1
4: ++ cut -d - -f2 -
4: ++ tr -d '['
4: ++ echo 'node[025-026]'
4: + export MASTER_ADDR=node025
4: + MASTER_ADDR=node025
4: + echo MASTER_ADDR=node025
4: MASTER_ADDR=node025
4: + export MASTER_PORT=19002
4: + MASTER_PORT=19002
4: HOSTNAME=node025
4: + echo HOSTNAME=node025
4: + declare -a CMD
4: + [[ -n 0 ]]
4: + [[ 8 -gt 2 ]]
4: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
4:  --bert_config_path=/workspace/phase1/bert_config.json '
4: + '[' -n 0 ']'
4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
4:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
4: + [[ 0 != 1 ]]
4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
4:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
4: + [[ '' -ge 1 ]]
4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
4:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu  '
4: + [[ 0 != 0 ]]
4: + '[' '' = apiLog.sh ']'
4: + '[' '' = 1 ']'
4: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0     --
4: bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu   --seed=14812'
4: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=56 --learning_rate=0.000425 --opt_lamb_beta_1=0.9 --opt_lamb_beta_2=0.999 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=6700 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=150000 --eval_iter_samples=150000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=2 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --de
4: nse_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=14812
6: + source ./config_2xXE8545x4A100-SXM4-40GB.sh
6: ++ export BATCHSIZE=56
6: ++ BATCHSIZE=56
6: ++ export GRADIENT_STEPS=2
6: ++ GRADIENT_STEPS=2
6: ++ export LR=0.000425
6: ++ LR=0.000425
6: ++ export MAX_SAMPLES_TERMINATION=4500000
6: ++ MAX_SAMPLES_TERMINATION=4500000
6: ++ export MAX_STEPS=6700
6: ++ MAX_STEPS=6700
6: ++ export OPT_LAMB_BETA_1=0.9
6: ++ OPT_LAMB_BETA_1=0.9
6: ++ export OPT_LAMB_BETA_2=0.999
6: ++ OPT_LAMB_BETA_2=0.999
6: ++ export START_WARMUP_STEP=0
6: ++ START_WARMUP_STEP=0
6: ++ export WARMUP_PROPORTION=0.0
6: ++ WARMUP_PROPORTION=0.0
6: ++ export WEIGHT_DECAY_RATE=0.01
6: ++ WEIGHT_DECAY_RATE=0.01
6: ++ export INIT_LOSS_SCALE=1024.0
6: ++ INIT_LOSS_SCALE=1024.0
6: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
6: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
6: ++ export PHASE=2
6: ++ PHASE=2
6: ++ export EVAL_ITER_START_SAMPLES=150000
6: ++ EVAL_ITER_START_SAMPLES=150000
6: ++ export EVAL_ITER_SAMPLES=150000
6: ++ EVAL_ITER_SAMPLES=150000
6: ++ export DGXNNODES=1
6: ++ DGXNNODES=1
6: +++ sed 's/^config_//'
6: +++ sed 's/\.sh$//'
6: ++++ readlink -f ./config_2xXE8545x4A100-SXM4-40GB.sh
6: +++ basename /workspace/bert/config_2xXE8545x4A100-SXM4-40GB.sh
6: ++ export DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
6: ++ DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
6: ++ export WALLTIME=01:15:00
6: ++ WALLTIME=01:15:00
6: ++ export DGXNGPU=4
6: ++ DGXNGPU=4
6: ++ export DGXSOCKETCORES=64
6: ++ DGXSOCKETCORES=64
6: ++ export DGXNSOCKET=2
6: ++ DGXNSOCKET=2
6: ++ export DGXHT=1
6: ++ DGXHT=1
6: ++ export MLPERF_SUBMISSION_ORG=Dell
6: ++ MLPERF_SUBMISSION_ORG=Dell
6: ++ export MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
6: ++ MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
6: ++ export OMP_NUM_THREADS=8
6: ++ OMP_NUM_THREADS=8
6: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
6: + ulimit -Sn 100000
6: + '[' '' = 1 ']'
6: + : 56
6: + : 2
6: + : 0.000425
6: + : 6700
6: + : 2
6: + : 2
6: + : ''
6: + : ''\'''\'''
6: + : 9546
6: + : 2504
6: + : 1
6: + : 4
6: + : ''
6: + : 0
6: + : 150000
6: + : 150000
6: + : 4500000
6: + : 0.9
6: + : 0.999
6: + : 0
6: + : 0.720
6: + : 0
6: + : 0.0
6: + : 0.0
6: + : 0.01
6: + : 0
6: + : 0
6: + : 0
6: + : 0
6: + : 0
6: + : 0
6: + echo 'Run vars: id 2504 gpus 4 mparams '\'''\'''
6: Run vars: id 2504 gpus 4 mparams ''
6: ++ date +%s
6: + START=1665639842
6: ++ date '+%Y-%m-%d %r'
6: + START_FMT='2022-10-13 12:44:02 AM'
6: STARTING TIMING RUN AT 2022-10-13 12:44:02 AM
6: + echo 'STARTING TIMING RUN AT 2022-10-13 12:44:02 AM'
6: + '[' '!' -z '' ']'
6: + '[' 0 -gt 0 ']'
6: + PHASE1='    --train_batch_size=56     --learning_rate=0.000425     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
6: + PHASE2='    --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
6: + PHASES=("$PHASE1" "$PHASE2")
6: + export RANK=6
6: + RANK=6
6: + export WORLD_SIZE=8
6: + WORLD_SIZE=8
6: WORLD_SIZE=8
6: + echo WORLD_SIZE=8
6: ++ cut -d - -f1
6: ++ cut -d - -f2 -
6: ++ tr -d '['
6: ++ echo 'node[025-026]'
6: + export MASTER_ADDR=node025
6: + MASTER_ADDR=node025
6: MASTER_ADDR=node025
6: + echo MASTER_ADDR=node025
6: + export MASTER_PORT=19002
6: + MASTER_PORT=19002
6: + echo HOSTNAME=node025
6: HOSTNAME=node025
6: + declare -a CMD
6: + [[ -n 2 ]]
6: + [[ 8 -gt 2 ]]
6: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
6:  --bert_config_path=/workspace/phase1/bert_config.json '
6: + '[' -n 2 ']'
6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
6:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
6: + [[ 0 != 1 ]]
6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
6:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
6: + [[ '' -ge 1 ]]
6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
6:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu  '
6: + [[ 0 != 0 ]]
6: + '[' '' = apiLog.sh ']'
6: + '[' '' = 1 ']'
6: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0     --
6: bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu   --seed=9546'
6: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=56 --learning_rate=0.000425 --opt_lamb_beta_1=0.9 --opt_lamb_beta_2=0.999 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=6700 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=150000 --eval_iter_samples=150000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=2 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --de
6: nse_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=9546
5: + source ./config_2xXE8545x4A100-SXM4-40GB.sh
5: ++ export BATCHSIZE=56
5: ++ BATCHSIZE=56
5: ++ export GRADIENT_STEPS=2
5: ++ GRADIENT_STEPS=2
5: ++ export LR=0.000425
5: ++ LR=0.000425
5: ++ export MAX_SAMPLES_TERMINATION=4500000
5: ++ MAX_SAMPLES_TERMINATION=4500000
5: ++ export MAX_STEPS=6700
5: ++ MAX_STEPS=6700
5: ++ export OPT_LAMB_BETA_1=0.9
5: ++ OPT_LAMB_BETA_1=0.9
5: ++ export OPT_LAMB_BETA_2=0.999
5: ++ OPT_LAMB_BETA_2=0.999
5: ++ export START_WARMUP_STEP=0
5: ++ START_WARMUP_STEP=0
5: ++ export WARMUP_PROPORTION=0.0
5: ++ WARMUP_PROPORTION=0.0
5: ++ export WEIGHT_DECAY_RATE=0.01
5: ++ WEIGHT_DECAY_RATE=0.01
5: ++ export INIT_LOSS_SCALE=1024.0
5: ++ INIT_LOSS_SCALE=1024.0
5: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
5: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
5: ++ export PHASE=2
5: ++ PHASE=2
5: ++ export EVAL_ITER_START_SAMPLES=150000
5: ++ EVAL_ITER_START_SAMPLES=150000
5: ++ export EVAL_ITER_SAMPLES=150000
5: ++ EVAL_ITER_SAMPLES=150000
5: ++ export DGXNNODES=1
5: ++ DGXNNODES=1
5: +++ sed 's/^config_//'
5: +++ sed 's/\.sh$//'
5: ++++ readlink -f ./config_2xXE8545x4A100-SXM4-40GB.sh
5: +++ basename /workspace/bert/config_2xXE8545x4A100-SXM4-40GB.sh
5: ++ export DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
5: ++ DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
5: ++ export WALLTIME=01:15:00
5: ++ WALLTIME=01:15:00
5: ++ export DGXNGPU=4
5: ++ DGXNGPU=4
5: ++ export DGXSOCKETCORES=64
5: ++ DGXSOCKETCORES=64
5: ++ export DGXNSOCKET=2
5: ++ DGXNSOCKET=2
5: ++ export DGXHT=1
5: ++ DGXHT=1
5: ++ export MLPERF_SUBMISSION_ORG=Dell
5: ++ MLPERF_SUBMISSION_ORG=Dell
5: ++ export MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
5: ++ MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
5: ++ export OMP_NUM_THREADS=8
5: ++ OMP_NUM_THREADS=8
5: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
5: + ulimit -Sn 100000
5: + '[' '' = 1 ']'
5: + : 56
5: + : 2
5: + : 0.000425
5: + : 6700
5: + : 2
5: + : 1
5: + : ''
5: + : ''\'''\'''
5: + : 1302
5: + : 2504
5: + : 1
5: + : 4
5: + : ''
5: + : 0
5: + : 150000
5: + : 150000
5: + : 4500000
5: + : 0.9
5: + : 0.999
5: + : 0
5: + : 0.720
5: + : 0
5: + : 0.0
5: + : 0.0
5: + : 0.01
5: + : 0
5: + : 0
5: + : 0
5: + : 0
5: + : 0
5: + : 0
5: + echo 'Run vars: id 2504 gpus 4 mparams '\'''\'''
5: Run vars: id 2504 gpus 4 mparams ''
5: ++ date +%s
5: + START=1665639843
5: ++ date '+%Y-%m-%d %r'
5: + START_FMT='2022-10-13 12:44:03 AM'
5: STARTING TIMING RUN AT 2022-10-13 12:44:03 AM
5: + echo 'STARTING TIMING RUN AT 2022-10-13 12:44:03 AM'
5: + '[' '!' -z '' ']'
5: + '[' 0 -gt 0 ']'
5: + PHASE1='    --train_batch_size=56     --learning_rate=0.000425     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
5: + PHASE2='    --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
5: + PHASES=("$PHASE1" "$PHASE2")
5: + export RANK=5
5: + RANK=5
5: + export WORLD_SIZE=8
5: + WORLD_SIZE=8
5: + echo WORLD_SIZE=8
5: WORLD_SIZE=8
5: ++ cut -d - -f1
5: ++ cut -d - -f2 -
5: ++ echo 'node[025-026]'
5: ++ tr -d '['
5: + export MASTER_ADDR=node025
5: + MASTER_ADDR=node025
5: MASTER_ADDR=node025
5: + echo MASTER_ADDR=node025
5: + export MASTER_PORT=19002
5: + MASTER_PORT=19002
5: HOSTNAME=node025
5: + echo HOSTNAME=node025
5: + declare -a CMD
5: + [[ -n 1 ]]
5: + [[ 8 -gt 2 ]]
5: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
5:  --bert_config_path=/workspace/phase1/bert_config.json '
5: + '[' -n 1 ']'
5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
5:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
5: + [[ 0 != 1 ]]
5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
5:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
5: + [[ '' -ge 1 ]]
5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
5:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu  '
5: + [[ 0 != 0 ]]
5: + '[' '' = apiLog.sh ']'
5: + '[' '' = 1 ']'
5: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0     --
5: bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu   --seed=1302'
5: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=56 --learning_rate=0.000425 --opt_lamb_beta_1=0.9 --opt_lamb_beta_2=0.999 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=6700 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=150000 --eval_iter_samples=150000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=2 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --de
5: nse_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=1302
7: + source ./config_2xXE8545x4A100-SXM4-40GB.sh
7: ++ export BATCHSIZE=56
7: ++ BATCHSIZE=56
7: ++ export GRADIENT_STEPS=2
7: ++ GRADIENT_STEPS=2
7: ++ export LR=0.000425
7: ++ LR=0.000425
7: ++ export MAX_SAMPLES_TERMINATION=4500000
7: ++ MAX_SAMPLES_TERMINATION=4500000
7: ++ export MAX_STEPS=6700
7: ++ MAX_STEPS=6700
7: ++ export OPT_LAMB_BETA_1=0.9
7: ++ OPT_LAMB_BETA_1=0.9
7: ++ export OPT_LAMB_BETA_2=0.999
7: ++ OPT_LAMB_BETA_2=0.999
7: ++ export START_WARMUP_STEP=0
7: ++ START_WARMUP_STEP=0
7: ++ export WARMUP_PROPORTION=0.0
7: ++ WARMUP_PROPORTION=0.0
7: ++ export WEIGHT_DECAY_RATE=0.01
7: ++ WEIGHT_DECAY_RATE=0.01
7: ++ export INIT_LOSS_SCALE=1024.0
7: ++ INIT_LOSS_SCALE=1024.0
7: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
7: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu '
7: ++ export PHASE=2
7: ++ PHASE=2
7: ++ export EVAL_ITER_START_SAMPLES=150000
7: ++ EVAL_ITER_START_SAMPLES=150000
7: ++ export EVAL_ITER_SAMPLES=150000
7: ++ EVAL_ITER_SAMPLES=150000
7: ++ export DGXNNODES=1
7: ++ DGXNNODES=1
7: +++ sed 's/^config_//'
7: +++ sed 's/\.sh$//'
7: ++++ readlink -f ./config_2xXE8545x4A100-SXM4-40GB.sh
7: +++ basename /workspace/bert/config_2xXE8545x4A100-SXM4-40GB.sh
7: ++ export DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
7: ++ DGXSYSTEM=2xXE8545x4A100-SXM4-40GB
7: ++ export WALLTIME=01:15:00
7: ++ WALLTIME=01:15:00
7: ++ export DGXNGPU=4
7: ++ DGXNGPU=4
7: ++ export DGXSOCKETCORES=64
7: ++ DGXSOCKETCORES=64
7: ++ export DGXNSOCKET=2
7: ++ DGXNSOCKET=2
7: ++ export DGXHT=1
7: ++ DGXHT=1
7: ++ export MLPERF_SUBMISSION_ORG=Dell
7: ++ MLPERF_SUBMISSION_ORG=Dell
7: ++ export MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
7: ++ MLPERF_SUBMISSION_PLATFORM=2xXE8545x4A100-SXM4-40GB
7: ++ export OMP_NUM_THREADS=8
7: ++ OMP_NUM_THREADS=8
7: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
7: + ulimit -Sn 100000
7: + '[' '' = 1 ']'
7: + : 56
7: + : 2
7: + : 0.000425
7: + : 6700
7: + : 2
7: + : 3
7: + : ''
7: + : ''\'''\'''
7: + : 2152
7: + : 2504
7: + : 1
7: + : 4
7: + : ''
7: + : 0
7: + : 150000
7: + : 150000
7: + : 4500000
7: + : 0.9
7: + : 0.999
7: + : 0
7: + : 0.720
7: + : 0
7: + : 0.0
7: + : 0.0
7: + : 0.01
7: + : 0
7: + : 0
7: + : 0
7: + : 0
7: + : 0
7: + : 0
7: + echo 'Run vars: id 2504 gpus 4 mparams '\'''\'''
7: Run vars: id 2504 gpus 4 mparams ''
7: ++ date +%s
7: + START=1665639843
7: ++ date '+%Y-%m-%d %r'
7: + START_FMT='2022-10-13 12:44:03 AM'
7: STARTING TIMING RUN AT 2022-10-13 12:44:03 AM
7: + echo 'STARTING TIMING RUN AT 2022-10-13 12:44:03 AM'
7: + '[' '!' -z '' ']'
7: + '[' 0 -gt 0 ']'
7: + PHASE1='    --train_batch_size=56     --learning_rate=0.000425     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
7: + PHASE2='    --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
7: + PHASES=("$PHASE1" "$PHASE2")
7: + export RANK=7
7: + RANK=7
7: + export WORLD_SIZE=8
7: + WORLD_SIZE=8
7: WORLD_SIZE=8
7: + echo WORLD_SIZE=8
7: ++ cut -d - -f1
7: ++ echo 'node[025-026]'
7: ++ cut -d - -f2 -
7: ++ tr -d '['
7: + export MASTER_ADDR=node025
7: + MASTER_ADDR=node025
7: MASTER_ADDR=node025
7: + echo MASTER_ADDR=node025
7: + export MASTER_PORT=19002
7: + MASTER_PORT=19002
7: + echo HOSTNAME=node025
7: HOSTNAME=node025
7: + declare -a CMD
7: + [[ -n 3 ]]
7: + [[ 8 -gt 2 ]]
7: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
7:  --bert_config_path=/workspace/phase1/bert_config.json '
7: + '[' -n 3 ']'
7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
7:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
7: + [[ 0 != 1 ]]
7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
7:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
7: + [[ '' -ge 1 ]]
7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0    
7:  --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu  '
7: + [[ 0 != 0 ]]
7: + '[' '' = apiLog.sh ']'
7: + '[' '' = 1 ']'
7: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=56     --learning_rate=0.000425     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=6700     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=2     --log_freq=0     --
7: bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu   --seed=2152'
7: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=56 --learning_rate=0.000425 --opt_lamb_beta_1=0.9 --opt_lamb_beta_2=0.999 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=6700 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=150000 --eval_iter_samples=150000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=2 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --de
7: nse_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=2152
1: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
2: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
3: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
0: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
4: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
6: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
7: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
5: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
3: :::MLLOG {"namespace": "", "time_ms": 1665639845599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
2: :::MLLOG {"namespace": "", "time_ms": 1665639845599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
1: :::MLLOG {"namespace": "", "time_ms": 1665639845599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639845729, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
5: :::MLLOG {"namespace": "", "time_ms": 1665639846117, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
4: :::MLLOG {"namespace": "", "time_ms": 1665639846117, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
6: :::MLLOG {"namespace": "", "time_ms": 1665639846117, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
7: :::MLLOG {"namespace": "", "time_ms": 1665639846117, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
0: device: cuda:0 n_gpu: 8, distributed training: True, 16-bits training: True
0: :::MLLOG {"namespace": "", "time_ms": 1665639846310, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846310, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "2xXE8545x4A100-SXM4-40GB", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "seed", "value": 13191, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1188}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 448, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1190}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 28, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1192}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 2, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1194}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1196}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 6700.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1198}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639846311, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1200}}
0: parsed args:
0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, average_packing_rate=1, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=4, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=150000, eval_iter_start_samples=150000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_gemm_gelu=True, fused_mha=False, g
0: radient_accumulation_steps=2, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.000425, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_pack_factor=1, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=6700.0, min_samples_to_start_checkpoints=3000000, n_gpu=8, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.9, opt_lamb_beta_2=0.999, output_dir='/results', packed_samples=False, pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, seed=13191, skip_checkpoint=True, start_warmup_step=0.0, synthetic_input=False, target_mlm_accuracy=0.72, train_batch_size=28, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=0.0, w
0: eight_decay_rate=0.01)
4: device: cuda:0 n_gpu: 8, distributed training: True, 16-bits training: True
6: device: cuda:2 n_gpu: 8, distributed training: True, 16-bits training: True
5: device: cuda:1 n_gpu: 8, distributed training: True, 16-bits training: True
7: device: cuda:3 n_gpu: 8, distributed training: True, 16-bits training: True
2: device: cuda:2 n_gpu: 8, distributed training: True, 16-bits training: True
3: device: cuda:3 n_gpu: 8, distributed training: True, 16-bits training: True
1: device: cuda:1 n_gpu: 8, distributed training: True, 16-bits training: True
0: :::MLLOG {"namespace": "", "time_ms": 1665639848234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/word_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/position_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/token_type_embeddings"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848235, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848236, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848237, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848238, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848239, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/query/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/query/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/key/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/key/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/value/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/value/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/intermediate/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/intermediate/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/pooler/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/pooler/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/output_bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/dense/kernel"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/dense/bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/LayerNorm/gamma"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/LayerNorm/beta"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/seq_relationship/output_weights"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/seq_relationship/output_bias"}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639848707, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.000425, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 817}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639850537, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 853}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639850538, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.9, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 856}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639850538, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.999, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 857}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639850538, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.01, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 858}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639850700, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639850701, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639850701, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
5: Torch distributed is available.
5: Torch distributed is initialized.
1: Torch distributed is available.
1: Torch distributed is initialized.
2: Torch distributed is available.
2: Torch distributed is initialized.
7: Torch distributed is available.
7: Torch distributed is initialized.
3: Torch distributed is available.
3: Torch distributed is initialized.
6: Torch distributed is available.
6: Torch distributed is initialized.
4: Torch distributed is available.
4: Torch distributed is initialized.
0: Torch distributed is available.
0: Torch distributed is initialized.
0: :::MLLOG {"namespace": "", "time_ms": 1665639853627, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1521}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639853628, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1521}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639853641, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1533, "epoch_num": 0}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639853642, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1535, "first_epoch_num": 1, "epoch_count": 1}}
0: parsed args:
0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, average_packing_rate=1, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=4, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=150000, eval_iter_start_samples=150000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_gemm_gelu=True, fused_mha=False, g
0: radient_accumulation_steps=2, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.000425, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_pack_factor=1, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=6700.0, min_samples_to_start_checkpoints=3000000, n_gpu=8, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.9, opt_lamb_beta_2=0.999, output_dir='/results', packed_samples=False, pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=13191, skip_checkpoint=True, start_warmup_step=0.0, synthetic_input=False, target_mlm_accuracy=0.72, train_batch_size=28, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warm
0: up_steps=0.0, weight_decay_rate=0.01)
0: epoch: 1
0: :::MLLOG {"namespace": "", "time_ms": 1665639853642, "event_type": "POINT_IN_TIME", "key": "data_file", "value": "/workspace/data_phase2/part_02865_of_04320.hdf5", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1569}}
0: :::MLLOG {"namespace": "", "time_ms": 1665639941854, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3760645389556885, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 150080}}
0: {'global_steps': 335, 'eval_loss': 4.083630561828613, 'eval_mlm_accuracy': 0.3760645389556885}
0: :::MLLOG {"namespace": "", "time_ms": 1665640029273, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4052121043205261, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 300384}}
0: {'global_steps': 670, 'eval_loss': 3.833164930343628, 'eval_mlm_accuracy': 0.4052121043205261}
0: :::MLLOG {"namespace": "", "time_ms": 1665640118246, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.43712449073791504, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 450464}}
0: {'global_steps': 1005, 'eval_loss': 3.5489487648010254, 'eval_mlm_accuracy': 0.43712449073791504}
0: :::MLLOG {"namespace": "", "time_ms": 1665640207289, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4864642024040222, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 600768}}
0: {'global_steps': 1340, 'eval_loss': 3.1183929443359375, 'eval_mlm_accuracy': 0.4864642024040222}
0: :::MLLOG {"namespace": "", "time_ms": 1665640290367, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.592982828617096, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 750848}}
0: {'global_steps': 1675, 'eval_loss': 2.23684024810791, 'eval_mlm_accuracy': 0.592982828617096}
0: :::MLLOG {"namespace": "", "time_ms": 1665640375472, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.695902943611145, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 900704}}
0: {'global_steps': 2009, 'eval_loss': 1.4574054479599, 'eval_mlm_accuracy': 0.695902943611145}
0: :::MLLOG {"namespace": "", "time_ms": 1665640467058, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7078940272331238, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1050784}}
0: {'global_steps': 2344, 'eval_loss': 1.378274917602539, 'eval_mlm_accuracy': 0.7078940272331238}
0: :::MLLOG {"namespace": "", "time_ms": 1665640558944, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7111048698425293, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1201088}}
0: {'global_steps': 2679, 'eval_loss': 1.359239935874939, 'eval_mlm_accuracy': 0.7111048698425293}
0: :::MLLOG {"namespace": "", "time_ms": 1665640647605, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7130080461502075, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1351168}}
0: {'global_steps': 3014, 'eval_loss': 1.3485316038131714, 'eval_mlm_accuracy': 0.7130080461502075}
0: :::MLLOG {"namespace": "", "time_ms": 1665640734993, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7146590352058411, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1501472}}
0: {'global_steps': 3349, 'eval_loss': 1.3377931118011475, 'eval_mlm_accuracy': 0.7146590352058411}
0: :::MLLOG {"namespace": "", "time_ms": 1665640817174, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7151026725769043, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1651552}}
0: {'global_steps': 3684, 'eval_loss': 1.3327655792236328, 'eval_mlm_accuracy': 0.7151026725769043}
0: :::MLLOG {"namespace": "", "time_ms": 1665640901067, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7164500951766968, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1801408}}
0: {'global_steps': 4018, 'eval_loss': 1.3268311023712158, 'eval_mlm_accuracy': 0.7164500951766968}
0: :::MLLOG {"namespace": "", "time_ms": 1665640985638, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7172276973724365, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1951488}}
0: {'global_steps': 4353, 'eval_loss': 1.3230215311050415, 'eval_mlm_accuracy': 0.7172276973724365}
0: :::MLLOG {"namespace": "", "time_ms": 1665641071507, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7179025411605835, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2101792}}
0: {'global_steps': 4688, 'eval_loss': 1.3171210289001465, 'eval_mlm_accuracy': 0.7179025411605835}
0: :::MLLOG {"namespace": "", "time_ms": 1665641157799, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7187198400497437, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2251872}}
0: {'global_steps': 5023, 'eval_loss': 1.3118559122085571, 'eval_mlm_accuracy': 0.7187198400497437}
0: :::MLLOG {"namespace": "", "time_ms": 1665641241661, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7191798686981201, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2402176}}
0: {'global_steps': 5358, 'eval_loss': 1.30767023563385, 'eval_mlm_accuracy': 0.7191798686981201}
0: :::MLLOG {"namespace": "", "time_ms": 1665641321451, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7196142077445984, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2551808}}
0: {'global_steps': 5692, 'eval_loss': 1.3067814111709595, 'eval_mlm_accuracy': 0.7196142077445984}
0: :::MLLOG {"namespace": "", "time_ms": 1665641408919, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7203264832496643, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2702112}}
0: {'global_steps': 6027, 'eval_loss': 1.3023234605789185, 'eval_mlm_accuracy': 0.7203264832496643}
0: 0.720326 > 0.720000, Target MLM Accuracy reached at 6027
0: (1, 6031.5) {'final_loss': 0.0}
0: :::MLLOG {"namespace": "", "time_ms": 1665641408996, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1850, "first_epoch_num": 1}}
0: :::MLLOG {"namespace": "", "time_ms": 1665641408997, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1853, "epoch_num": 2702112}}
0: :::MLLOG {"namespace": "", "time_ms": 1665641408997, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 2702112, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1861}}
0: :::MLLOG {"namespace": "", "time_ms": 1665641408997, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1864}}
0: :::MLLOG {"namespace": "", "time_ms": 1665641408998, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1867, "status": "success"}}
0: {'e2e_time': 1563.3983931541443, 'training_sequences_per_second': 1927.4809691902776, 'final_loss': 0.0, 'raw_train_time': 1557.2656996250153}
2: + set +x
2: ENDING TIMING RUN AT 2022-10-13 01:10:09 AM
2: RESULT,bert,27448,1567,root,2022-10-13 12:44:02 AM
3: + set +x
3: ENDING TIMING RUN AT 2022-10-13 01:10:09 AM
3: RESULT,bert,20747,1567,root,2022-10-13 12:44:02 AM
7: + set +x
7: ENDING TIMING RUN AT 2022-10-13 01:10:09 AM
7: RESULT,bert,2152,1566,root,2022-10-13 12:44:03 AM
1: + set +x
1: ENDING TIMING RUN AT 2022-10-13 01:10:09 AM
1: RESULT,bert,7410,1567,root,2022-10-13 12:44:02 AM
5: + set +x
5: ENDING TIMING RUN AT 2022-10-13 01:10:09 AM
5: RESULT,bert,1302,1566,root,2022-10-13 12:44:03 AM
6: + set +x
6: ENDING TIMING RUN AT 2022-10-13 01:10:09 AM
6: RESULT,bert,9546,1567,root,2022-10-13 12:44:02 AM
0: + set +x
0: ENDING TIMING RUN AT 2022-10-13 01:10:10 AM
0: RESULT,bert,13191,1568,root,2022-10-13 12:44:02 AM
4: + set +x
4: ENDING TIMING RUN AT 2022-10-13 01:10:10 AM
4: RESULT,bert,14812,1568,root,2022-10-13 12:44:02 AM
