Beginning trial 09 of 10
:::DLPAL /mnt/data/bert_20221004.sif 2508 16 node[022-023,027-040]
hosts=node022 node023 node027 node028 node029 node030 node031 node032 node033 node034 node035 node036 node037 node038 node039 node040 
Clearing cache on node022
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667459797, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node023
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667464591, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node027
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667469221, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node028
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667473833, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node029
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667478446, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node030
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667483106, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node031
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667487738, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node032
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667492370, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node033
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667496953, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node034
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667501535, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node035
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667506124, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node036
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667510738, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node037
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667515476, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node038
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667520071, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node039
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667524792, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
Clearing cache on node040
vm.drop_caches = 3
:::MLLOG {"namespace": "", "time_ms": 1665667529416, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
SLURM_JOB_NUM_NODES_DGXNGPU=64
 1: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 0: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 2: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 3: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
57: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 8: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
24: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
48: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
29: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
41: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
32: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
44: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
16: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
20: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
52: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
58: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
59: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
56: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 9: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
10: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
11: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 4: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
25: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
50: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
26: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
51: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
27: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
49: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
30: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
42: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
28: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
43: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
31: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
40: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
35: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
33: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
34: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
21: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
22: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
23: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
17: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
19: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
18: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
46: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
47: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
45: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
36: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
53: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
54: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
55: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
15: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 6: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 7: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 5: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
38: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
39: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
37: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
12: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
13: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
14: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
61: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
62: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
60: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
63: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 0: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 0: ++ export BATCHSIZE=48
 0: ++ BATCHSIZE=48
 0: ++ export GRADIENT_STEPS=1
 0: ++ GRADIENT_STEPS=1
 0: ++ export LR=0.0020992
 0: ++ LR=0.0020992
 0: ++ export MAX_SAMPLES_TERMINATION=4500000
 0: ++ MAX_SAMPLES_TERMINATION=4500000
 0: ++ export MAX_STEPS=1059
 0: ++ MAX_STEPS=1059
 0: ++ export OPT_LAMB_BETA_1=0.60466
 0: ++ OPT_LAMB_BETA_1=0.60466
 0: ++ export OPT_LAMB_BETA_2=0.85437
 0: ++ OPT_LAMB_BETA_2=0.85437
 0: ++ export START_WARMUP_STEP=0
 0: ++ START_WARMUP_STEP=0
 0: ++ export WARMUP_PROPORTION=0.0
 0: ++ WARMUP_PROPORTION=0.0
 0: ++ export WEIGHT_DECAY_RATE=0.1
 0: ++ WEIGHT_DECAY_RATE=0.1
 0: ++ export INIT_LOSS_SCALE=4096.0
 0: ++ INIT_LOSS_SCALE=4096.0
 0: ++ export SBATCH_NETWORK=sharp
 0: ++ SBATCH_NETWORK=sharp
 0: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 0: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 0: ++ export PHASE=2
 0: ++ PHASE=2
 0: ++ export EVAL_ITER_START_SAMPLES=175000
 0: ++ EVAL_ITER_START_SAMPLES=175000
 0: ++ export EVAL_ITER_SAMPLES=175000
 0: ++ EVAL_ITER_SAMPLES=175000
 0: ++ export DGXNNODES=16
 0: ++ DGXNNODES=16
 0: +++ sed 's/^config_//'
 0: +++ sed 's/\.sh$//'
 0: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 0: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 0: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 0: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 0: ++ export WALLTIME_MINUTES=15
 0: ++ WALLTIME_MINUTES=15
 0: ++ export WALLTIME=20
 0: ++ WALLTIME=20
 0: ++ export DGXNGPU=4
 0: ++ DGXNGPU=4
 0: ++ export DGXSOCKETCORES=64
 0: ++ DGXSOCKETCORES=64
 0: ++ export DGXNSOCKET=2
 0: ++ DGXNSOCKET=2
 0: ++ export DGXHT=1
 0: ++ DGXHT=1
 0: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 0: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 0: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 0: ++ export MLPERF_SUBMISSION_ORG=Dell
 0: ++ MLPERF_SUBMISSION_ORG=Dell
 0: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 0: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 0: ++ export OMP_NUM_THREADS=8
 0: ++ OMP_NUM_THREADS=8
 0: + ulimit -Sn 100000
 0: + '[' '' = 1 ']'
 0: + : 48
 0: + : 1
 0: + : 0.0020992
 0: + : 1059
 0: + : 2
 0: + : 0
 0: + : ''
 0: + : ''\'''\'''
 0: + : 20189
 0: + : 2508
 0: + : 0
 0: + : 4
 0: + : ''
 0: + : 0
 0: + : 175000
 0: + : 175000
 0: + : 4500000
 0: + : 0.60466
 0: + : 0.85437
 0: + : 0
 0: + : 0.720
 0: + : 0
 0: + : 0.0
 0: + : 0.0
 0: + : 0.1
 0: + : 0
 0: + : 0
 0: + : 0
 0: + : 0
 0: + : 0
 0: + : 0
 0: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
 0: Run vars: id 2508 gpus 4 mparams ''
 0: ++ date +%s
 0: + START=1665667532
 0: ++ date '+%Y-%m-%d %r'
 0: + START_FMT='2022-10-13 08:25:32 AM'
 0: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
 0: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
 0: + '[' '!' -z '' ']'
 0: + '[' 0 -gt 0 ']'
 0: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 0: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 0: + PHASES=("$PHASE1" "$PHASE2")
 0: + export RANK=0
 0: + RANK=0
 0: + export WORLD_SIZE=64
 0: + WORLD_SIZE=64
 0: WORLD_SIZE=64
 0: + echo WORLD_SIZE=64
 0: ++ cut -d - -f1
 0: ++ cut -d - -f2 -
 0: ++ tr -d '['
 0: ++ echo 'node[022-023,027-040]'
 0: + export MASTER_ADDR=node022
 0: + MASTER_ADDR=node022
 0: MASTER_ADDR=node022
 0: + echo MASTER_ADDR=node022
 0: + export MASTER_PORT=19002
 0: + MASTER_PORT=19002
 0: HOSTNAME=node022
 0: + echo HOSTNAME=node022
 0: + declare -a CMD
 0: + [[ -n 0 ]]
 0: + [[ 64 -gt 16 ]]
 0: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 0: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 0: + '[' -n 0 ']'
 0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 0: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
 0: + [[ 0 != 1 ]]
 0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 0: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 0: + [[ '' -ge 1 ]]
 0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 0: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 0: + [[ 0 != 0 ]]
 0: + '[' '' = apiLog.sh ']'
 0: + '[' '' = 1 ']'
 0: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
 0:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=20189'
 0: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 0: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=20189
 2: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 2: ++ export BATCHSIZE=48
 2: ++ BATCHSIZE=48
 2: ++ export GRADIENT_STEPS=1
 2: ++ GRADIENT_STEPS=1
 2: ++ export LR=0.0020992
 2: ++ LR=0.0020992
 2: ++ export MAX_SAMPLES_TERMINATION=4500000
 2: ++ MAX_SAMPLES_TERMINATION=4500000
 2: ++ export MAX_STEPS=1059
 2: ++ MAX_STEPS=1059
 2: ++ export OPT_LAMB_BETA_1=0.60466
 2: ++ OPT_LAMB_BETA_1=0.60466
 2: ++ export OPT_LAMB_BETA_2=0.85437
 2: ++ OPT_LAMB_BETA_2=0.85437
 2: ++ export START_WARMUP_STEP=0
 2: ++ START_WARMUP_STEP=0
 2: ++ export WARMUP_PROPORTION=0.0
 2: ++ WARMUP_PROPORTION=0.0
 2: ++ export WEIGHT_DECAY_RATE=0.1
 2: ++ WEIGHT_DECAY_RATE=0.1
 2: ++ export INIT_LOSS_SCALE=4096.0
 2: ++ INIT_LOSS_SCALE=4096.0
 2: ++ export SBATCH_NETWORK=sharp
 2: ++ SBATCH_NETWORK=sharp
 2: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 2: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 2: ++ export PHASE=2
 2: ++ PHASE=2
 2: ++ export EVAL_ITER_START_SAMPLES=175000
 2: ++ EVAL_ITER_START_SAMPLES=175000
 2: ++ export EVAL_ITER_SAMPLES=175000
 2: ++ EVAL_ITER_SAMPLES=175000
 2: ++ export DGXNNODES=16
 2: ++ DGXNNODES=16
 2: +++ sed 's/^config_//'
 2: +++ sed 's/\.sh$//'
 2: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 2: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 2: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 2: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 2: ++ export WALLTIME_MINUTES=15
 2: ++ WALLTIME_MINUTES=15
 2: ++ export WALLTIME=20
 2: ++ WALLTIME=20
 2: ++ export DGXNGPU=4
 2: ++ DGXNGPU=4
 2: ++ export DGXSOCKETCORES=64
 2: ++ DGXSOCKETCORES=64
 2: ++ export DGXNSOCKET=2
 2: ++ DGXNSOCKET=2
 2: ++ export DGXHT=1
 2: ++ DGXHT=1
 2: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 2: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 2: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 2: ++ export MLPERF_SUBMISSION_ORG=Dell
 2: ++ MLPERF_SUBMISSION_ORG=Dell
 2: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 2: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 2: ++ export OMP_NUM_THREADS=8
 2: ++ OMP_NUM_THREADS=8
 2: + ulimit -Sn 100000
 2: + '[' '' = 1 ']'
 2: + : 48
 2: + : 1
 2: + : 0.0020992
 2: + : 1059
 2: + : 2
 2: + : 2
 2: + : ''
 2: + : ''\'''\'''
 2: + : 6609
 2: + : 2508
 2: + : 0
 2: + : 4
 2: + : ''
 2: + : 0
 2: + : 175000
 2: + : 175000
 2: + : 4500000
 2: + : 0.60466
 2: + : 0.85437
 2: + : 0
 2: + : 0.720
 2: + : 0
 2: + : 0.0
 2: + : 0.0
 2: + : 0.1
 2: + : 0
 2: + : 0
 2: + : 0
 2: + : 0
 2: + : 0
 2: + : 0
 2: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
 2: Run vars: id 2508 gpus 4 mparams ''
 2: ++ date +%s
 2: + START=1665667532
 2: ++ date '+%Y-%m-%d %r'
 2: + START_FMT='2022-10-13 08:25:32 AM'
 2: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
 2: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
 2: + '[' '!' -z '' ']'
 2: + '[' 0 -gt 0 ']'
 2: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 2: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 2: + PHASES=("$PHASE1" "$PHASE2")
 2: + export RANK=2
 2: + RANK=2
 2: + export WORLD_SIZE=64
 2: + WORLD_SIZE=64
 2: WORLD_SIZE=64
 2: + echo WORLD_SIZE=64
 2: ++ cut -d - -f1
 2: ++ cut -d - -f2 -
 2: ++ tr -d '['
 2: ++ echo 'node[022-023,027-040]'
 2: + export MASTER_ADDR=node022
 2: + MASTER_ADDR=node022
 2: MASTER_ADDR=node022
 2: + echo MASTER_ADDR=node022
 2: + export MASTER_PORT=19002
 2: + MASTER_PORT=19002
 2: + echo HOSTNAME=node022
 2: HOSTNAME=node022
 2: + declare -a CMD
 2: + [[ -n 2 ]]
 2: + [[ 64 -gt 16 ]]
 2: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 2: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 2: + '[' -n 2 ']'
 2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 2: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
 2: + [[ 0 != 1 ]]
 2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 2: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 2: + [[ '' -ge 1 ]]
 2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 2: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 2: + [[ 0 != 0 ]]
 2: + '[' '' = apiLog.sh ']'
 2: + '[' '' = 1 ']'
 2: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
 2:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=6609'
 2: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 2: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=6609
 1: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 1: ++ export BATCHSIZE=48
 1: ++ BATCHSIZE=48
 1: ++ export GRADIENT_STEPS=1
 1: ++ GRADIENT_STEPS=1
 1: ++ export LR=0.0020992
 1: ++ LR=0.0020992
 1: ++ export MAX_SAMPLES_TERMINATION=4500000
 1: ++ MAX_SAMPLES_TERMINATION=4500000
 1: ++ export MAX_STEPS=1059
 1: ++ MAX_STEPS=1059
 1: ++ export OPT_LAMB_BETA_1=0.60466
 1: ++ OPT_LAMB_BETA_1=0.60466
 1: ++ export OPT_LAMB_BETA_2=0.85437
 1: ++ OPT_LAMB_BETA_2=0.85437
 1: ++ export START_WARMUP_STEP=0
 1: ++ START_WARMUP_STEP=0
 1: ++ export WARMUP_PROPORTION=0.0
 1: ++ WARMUP_PROPORTION=0.0
 1: ++ export WEIGHT_DECAY_RATE=0.1
 1: ++ WEIGHT_DECAY_RATE=0.1
 1: ++ export INIT_LOSS_SCALE=4096.0
 1: ++ INIT_LOSS_SCALE=4096.0
 1: ++ export SBATCH_NETWORK=sharp
 1: ++ SBATCH_NETWORK=sharp
 1: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 1: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 1: ++ export PHASE=2
 1: ++ PHASE=2
 1: ++ export EVAL_ITER_START_SAMPLES=175000
 1: ++ EVAL_ITER_START_SAMPLES=175000
 1: ++ export EVAL_ITER_SAMPLES=175000
 1: ++ EVAL_ITER_SAMPLES=175000
 1: ++ export DGXNNODES=16
 1: ++ DGXNNODES=16
 1: +++ sed 's/^config_//'
 1: +++ sed 's/\.sh$//'
 1: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 1: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 1: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 1: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 1: ++ export WALLTIME_MINUTES=15
 1: ++ WALLTIME_MINUTES=15
 1: ++ export WALLTIME=20
 1: ++ WALLTIME=20
 1: ++ export DGXNGPU=4
 1: ++ DGXNGPU=4
 1: ++ export DGXSOCKETCORES=64
 1: ++ DGXSOCKETCORES=64
 1: ++ export DGXNSOCKET=2
 1: ++ DGXNSOCKET=2
 1: ++ export DGXHT=1
 1: ++ DGXHT=1
 1: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 1: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 1: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 1: ++ export MLPERF_SUBMISSION_ORG=Dell
 1: ++ MLPERF_SUBMISSION_ORG=Dell
 1: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 1: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 1: ++ export OMP_NUM_THREADS=8
 1: ++ OMP_NUM_THREADS=8
 1: + ulimit -Sn 100000
 1: + '[' '' = 1 ']'
 1: + : 48
 1: + : 1
 1: + : 0.0020992
 1: + : 1059
 1: + : 2
 1: + : 1
 1: + : ''
 1: + : ''\'''\'''
 1: + : 12433
 1: + : 2508
 1: + : 0
 1: + : 4
 1: + : ''
 1: + : 0
 1: + : 175000
 1: + : 175000
 1: + : 4500000
 1: + : 0.60466
 1: + : 0.85437
 1: + : 0
 1: + : 0.720
 1: + : 0
 1: + : 0.0
 1: + : 0.0
 1: + : 0.1
 1: + : 0
 1: + : 0
 1: + : 0
 1: + : 0
 1: + : 0
 1: + : 0
 1: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
 1: Run vars: id 2508 gpus 4 mparams ''
 1: ++ date +%s
 1: + START=1665667532
 1: ++ date '+%Y-%m-%d %r'
 1: + START_FMT='2022-10-13 08:25:32 AM'
 1: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
 1: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
 1: + '[' '!' -z '' ']'
 1: + '[' 0 -gt 0 ']'
 1: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 1: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 1: + PHASES=("$PHASE1" "$PHASE2")
 1: + export RANK=1
 1: + RANK=1
 1: + export WORLD_SIZE=64
 1: + WORLD_SIZE=64
 1: + echo WORLD_SIZE=64
 1: WORLD_SIZE=64
 1: ++ cut -d - -f1
 1: ++ cut -d - -f2 -
 1: ++ tr -d '['
 1: ++ echo 'node[022-023,027-040]'
 1: + export MASTER_ADDR=node022
 1: + MASTER_ADDR=node022
 1: MASTER_ADDR=node022
 1: + echo MASTER_ADDR=node022
 1: + export MASTER_PORT=19002
 1: + MASTER_PORT=19002
 1: HOSTNAME=node022
 1: + echo HOSTNAME=node022
 1: + declare -a CMD
 1: + [[ -n 1 ]]
 1: + [[ 64 -gt 16 ]]
 1: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 1: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 1: + '[' -n 1 ']'
 1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 1: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
 1: + [[ 0 != 1 ]]
 1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 1: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 1: + [[ '' -ge 1 ]]
 1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 1: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 1: + [[ 0 != 0 ]]
 1: + '[' '' = apiLog.sh ']'
 1: + '[' '' = 1 ']'
 1: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
 1:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=12433'
 1: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 1: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=12433
 3: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 3: ++ export BATCHSIZE=48
 3: ++ BATCHSIZE=48
 3: ++ export GRADIENT_STEPS=1
 3: ++ GRADIENT_STEPS=1
 3: ++ export LR=0.0020992
 3: ++ LR=0.0020992
 3: ++ export MAX_SAMPLES_TERMINATION=4500000
 3: ++ MAX_SAMPLES_TERMINATION=4500000
 3: ++ export MAX_STEPS=1059
 3: ++ MAX_STEPS=1059
 3: ++ export OPT_LAMB_BETA_1=0.60466
 3: ++ OPT_LAMB_BETA_1=0.60466
 3: ++ export OPT_LAMB_BETA_2=0.85437
 3: ++ OPT_LAMB_BETA_2=0.85437
 3: ++ export START_WARMUP_STEP=0
 3: ++ START_WARMUP_STEP=0
 3: ++ export WARMUP_PROPORTION=0.0
 3: ++ WARMUP_PROPORTION=0.0
 3: ++ export WEIGHT_DECAY_RATE=0.1
 3: ++ WEIGHT_DECAY_RATE=0.1
 3: ++ export INIT_LOSS_SCALE=4096.0
 3: ++ INIT_LOSS_SCALE=4096.0
 3: ++ export SBATCH_NETWORK=sharp
 3: ++ SBATCH_NETWORK=sharp
 3: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 3: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 3: ++ export PHASE=2
 3: ++ PHASE=2
 3: ++ export EVAL_ITER_START_SAMPLES=175000
 3: ++ EVAL_ITER_START_SAMPLES=175000
 3: ++ export EVAL_ITER_SAMPLES=175000
 3: ++ EVAL_ITER_SAMPLES=175000
 3: ++ export DGXNNODES=16
 3: ++ DGXNNODES=16
 3: +++ sed 's/^config_//'
 3: +++ sed 's/\.sh$//'
 3: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 3: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 3: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 3: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 3: ++ export WALLTIME_MINUTES=15
 3: ++ WALLTIME_MINUTES=15
 3: ++ export WALLTIME=20
 3: ++ WALLTIME=20
 3: ++ export DGXNGPU=4
 3: ++ DGXNGPU=4
 3: ++ export DGXSOCKETCORES=64
 3: ++ DGXSOCKETCORES=64
 3: ++ export DGXNSOCKET=2
 3: ++ DGXNSOCKET=2
 3: ++ export DGXHT=1
 3: ++ DGXHT=1
 3: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 3: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 3: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 3: ++ export MLPERF_SUBMISSION_ORG=Dell
 3: ++ MLPERF_SUBMISSION_ORG=Dell
 3: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 3: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 3: ++ export OMP_NUM_THREADS=8
 3: ++ OMP_NUM_THREADS=8
 3: + ulimit -Sn 100000
 3: + '[' '' = 1 ']'
 3: + : 48
 3: + : 1
 3: + : 0.0020992
 3: + : 1059
 3: + : 2
 3: + : 3
 3: + : ''
 3: + : ''\'''\'''
 3: + : 11897
 3: + : 2508
 3: + : 0
 3: + : 4
 3: + : ''
 3: + : 0
 3: + : 175000
 3: + : 175000
 3: + : 4500000
 3: + : 0.60466
 3: + : 0.85437
 3: + : 0
 3: + : 0.720
 3: + : 0
 3: + : 0.0
 3: + : 0.0
 3: + : 0.1
 3: + : 0
 3: + : 0
 3: + : 0
 3: + : 0
 3: + : 0
 3: + : 0
 3: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
 3: Run vars: id 2508 gpus 4 mparams ''
 3: ++ date +%s
 3: + START=1665667532
 3: ++ date '+%Y-%m-%d %r'
 3: + START_FMT='2022-10-13 08:25:32 AM'
 3: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
 3: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
 3: + '[' '!' -z '' ']'
 3: + '[' 0 -gt 0 ']'
 3: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 3: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 3: + PHASES=("$PHASE1" "$PHASE2")
 3: + export RANK=3
 3: + RANK=3
 3: + export WORLD_SIZE=64
 3: + WORLD_SIZE=64
 3: + echo WORLD_SIZE=64
 3: WORLD_SIZE=64
 3: ++ cut -d - -f1
 3: ++ cut -d - -f2 -
 3: ++ echo 'node[022-023,027-040]'
 3: ++ tr -d '['
 3: + export MASTER_ADDR=node022
 3: + MASTER_ADDR=node022
 3: MASTER_ADDR=node022
 3: + echo MASTER_ADDR=node022
 3: + export MASTER_PORT=19002
 3: + MASTER_PORT=19002
 3: HOSTNAME=node022
 3: + echo HOSTNAME=node022
 3: + declare -a CMD
 3: + [[ -n 3 ]]
 3: + [[ 64 -gt 16 ]]
 3: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 3: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 3: + '[' -n 3 ']'
 3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 3: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
 3: + [[ 0 != 1 ]]
 3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 3: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 3: + [[ '' -ge 1 ]]
 3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 3: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 3: + [[ 0 != 0 ]]
 3: + '[' '' = apiLog.sh ']'
 3: + '[' '' = 1 ']'
 3: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
 3:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=11897'
 3: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 3: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=11897
10: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
10: ++ export BATCHSIZE=48
10: ++ BATCHSIZE=48
10: ++ export GRADIENT_STEPS=1
10: ++ GRADIENT_STEPS=1
10: ++ export LR=0.0020992
10: ++ LR=0.0020992
10: ++ export MAX_SAMPLES_TERMINATION=4500000
10: ++ MAX_SAMPLES_TERMINATION=4500000
10: ++ export MAX_STEPS=1059
10: ++ MAX_STEPS=1059
10: ++ export OPT_LAMB_BETA_1=0.60466
10: ++ OPT_LAMB_BETA_1=0.60466
10: ++ export OPT_LAMB_BETA_2=0.85437
10: ++ OPT_LAMB_BETA_2=0.85437
10: ++ export START_WARMUP_STEP=0
10: ++ START_WARMUP_STEP=0
10: ++ export WARMUP_PROPORTION=0.0
10: ++ WARMUP_PROPORTION=0.0
10: ++ export WEIGHT_DECAY_RATE=0.1
10: ++ WEIGHT_DECAY_RATE=0.1
10: ++ export INIT_LOSS_SCALE=4096.0
10: ++ INIT_LOSS_SCALE=4096.0
10: ++ export SBATCH_NETWORK=sharp
10: ++ SBATCH_NETWORK=sharp
10: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
10: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
10: ++ export PHASE=2
10: ++ PHASE=2
10: ++ export EVAL_ITER_START_SAMPLES=175000
10: ++ EVAL_ITER_START_SAMPLES=175000
10: ++ export EVAL_ITER_SAMPLES=175000
10: ++ EVAL_ITER_SAMPLES=175000
10: ++ export DGXNNODES=16
10: ++ DGXNNODES=16
10: +++ sed 's/^config_//'
10: +++ sed 's/\.sh$//'
10: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
10: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
10: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
10: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
10: ++ export WALLTIME_MINUTES=15
10: ++ WALLTIME_MINUTES=15
10: ++ export WALLTIME=20
10: ++ WALLTIME=20
10: ++ export DGXNGPU=4
10: ++ DGXNGPU=4
10: ++ export DGXSOCKETCORES=64
10: ++ DGXSOCKETCORES=64
10: ++ export DGXNSOCKET=2
10: ++ DGXNSOCKET=2
10: ++ export DGXHT=1
10: ++ DGXHT=1
10: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
10: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
10: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
10: ++ export MLPERF_SUBMISSION_ORG=Dell
10: ++ MLPERF_SUBMISSION_ORG=Dell
10: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
10: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
10: ++ export OMP_NUM_THREADS=8
10: ++ OMP_NUM_THREADS=8
10: + ulimit -Sn 100000
10: + '[' '' = 1 ']'
10: + : 48
10: + : 1
10: + : 0.0020992
10: + : 1059
10: + : 2
10: + : 2
10: + : ''
10: + : ''\'''\'''
10: + : 12599
10: + : 2508
10: + : 2
10: + : 4
10: + : ''
10: + : 0
10: + : 175000
10: + : 175000
10: + : 4500000
10: + : 0.60466
10: + : 0.85437
10: + : 0
10: + : 0.720
10: + : 0
10: + : 0.0
10: + : 0.0
10: + : 0.1
10: + : 0
10: + : 0
10: + : 0
10: + : 0
10: + : 0
10: + : 0
10: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
10: Run vars: id 2508 gpus 4 mparams ''
10: ++ date +%s
10: + START=1665667532
10: ++ date '+%Y-%m-%d %r'
10: + START_FMT='2022-10-13 08:25:32 AM'
10: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
10: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
10: + '[' '!' -z '' ']'
10: + '[' 0 -gt 0 ']'
10: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
10: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
10: + PHASES=("$PHASE1" "$PHASE2")
10: + export RANK=10
10: + RANK=10
10: + export WORLD_SIZE=64
10: + WORLD_SIZE=64
10: WORLD_SIZE=64
10: + echo WORLD_SIZE=64
10: ++ cut -d - -f1
10: ++ cut -d - -f2 -
10: ++ tr -d '['
10: ++ echo 'node[022-023,027-040]'
10: + export MASTER_ADDR=node022
10: + MASTER_ADDR=node022
10: + echo MASTER_ADDR=node022
10: MASTER_ADDR=node022
10: + export MASTER_PORT=19002
10: + MASTER_PORT=19002
10: HOSTNAME=node022
10: + echo HOSTNAME=node022
10: + declare -a CMD
10: + [[ -n 2 ]]
10: + [[ 64 -gt 16 ]]
10: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
10: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
10: =0     --bert_config_path=/workspace/phase1/bert_config.json '
10: + '[' -n 2 ']'
10: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
10: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
10: + [[ 0 != 1 ]]
10: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
10: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
10: + [[ '' -ge 1 ]]
10: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
10: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
10: + [[ 0 != 0 ]]
10: + '[' '' = apiLog.sh ']'
10: + '[' '' = 1 ']'
10: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
10:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=12599'
10: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
10: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=12599
57: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
57: ++ export BATCHSIZE=48
57: ++ BATCHSIZE=48
57: ++ export GRADIENT_STEPS=1
57: ++ GRADIENT_STEPS=1
57: ++ export LR=0.0020992
57: ++ LR=0.0020992
57: ++ export MAX_SAMPLES_TERMINATION=4500000
57: ++ MAX_SAMPLES_TERMINATION=4500000
57: ++ export MAX_STEPS=1059
57: ++ MAX_STEPS=1059
57: ++ export OPT_LAMB_BETA_1=0.60466
57: ++ OPT_LAMB_BETA_1=0.60466
57: ++ export OPT_LAMB_BETA_2=0.85437
57: ++ OPT_LAMB_BETA_2=0.85437
57: ++ export START_WARMUP_STEP=0
57: ++ START_WARMUP_STEP=0
57: ++ export WARMUP_PROPORTION=0.0
57: ++ WARMUP_PROPORTION=0.0
57: ++ export WEIGHT_DECAY_RATE=0.1
57: ++ WEIGHT_DECAY_RATE=0.1
57: ++ export INIT_LOSS_SCALE=4096.0
57: ++ INIT_LOSS_SCALE=4096.0
57: ++ export SBATCH_NETWORK=sharp
57: ++ SBATCH_NETWORK=sharp
57: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
57: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
57: ++ export PHASE=2
57: ++ PHASE=2
57: ++ export EVAL_ITER_START_SAMPLES=175000
57: ++ EVAL_ITER_START_SAMPLES=175000
57: ++ export EVAL_ITER_SAMPLES=175000
57: ++ EVAL_ITER_SAMPLES=175000
57: ++ export DGXNNODES=16
57: ++ DGXNNODES=16
57: +++ sed 's/^config_//'
57: +++ sed 's/\.sh$//'
57: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
57: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
57: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
57: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
57: ++ export WALLTIME_MINUTES=15
57: ++ WALLTIME_MINUTES=15
57: ++ export WALLTIME=20
57: ++ WALLTIME=20
57: ++ export DGXNGPU=4
57: ++ DGXNGPU=4
57: ++ export DGXSOCKETCORES=64
57: ++ DGXSOCKETCORES=64
57: ++ export DGXNSOCKET=2
57: ++ DGXNSOCKET=2
57: ++ export DGXHT=1
57: ++ DGXHT=1
57: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
57: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
57: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
57: ++ export MLPERF_SUBMISSION_ORG=Dell
57: ++ MLPERF_SUBMISSION_ORG=Dell
57: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
57: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
57: ++ export OMP_NUM_THREADS=8
57: ++ OMP_NUM_THREADS=8
57: + ulimit -Sn 100000
57: + '[' '' = 1 ']'
57: + : 48
57: + : 1
57: + : 0.0020992
57: + : 1059
57: + : 2
57: + : 1
57: + : ''
57: + : ''\'''\'''
57: + : 16398
57: + : 2508
57: + : 14
57: + : 4
57: + : ''
57: + : 0
57: + : 175000
57: + : 175000
57: + : 4500000
57: + : 0.60466
57: + : 0.85437
57: + : 0
57: + : 0.720
57: + : 0
57: + : 0.0
57: + : 0.0
57: + : 0.1
57: + : 0
57: + : 0
57: + : 0
57: + : 0
57: + : 0
57: + : 0
57: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
57: Run vars: id 2508 gpus 4 mparams ''
57: ++ date +%s
57: + START=1665667532
57: ++ date '+%Y-%m-%d %r'
57: + START_FMT='2022-10-13 08:25:32 AM'
57: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
57: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
57: + '[' '!' -z '' ']'
57: + '[' 0 -gt 0 ']'
57: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
57: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
57: + PHASES=("$PHASE1" "$PHASE2")
57: + export RANK=57
57: + RANK=57
57: + export WORLD_SIZE=64
57: + WORLD_SIZE=64
57: WORLD_SIZE=64
57: + echo WORLD_SIZE=64
57: ++ cut -d - -f1
57: ++ cut -d - -f2 -
57: ++ tr -d '['
57: ++ echo 'node[022-023,027-040]'
56: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
57: + export MASTER_ADDR=node022
57: + MASTER_ADDR=node022
57: MASTER_ADDR=node022
57: + echo MASTER_ADDR=node022
57: + export MASTER_PORT=19002
57: + MASTER_PORT=19002
57: HOSTNAME=node022
57: + echo HOSTNAME=node022
57: + declare -a CMD
56: ++ export BATCHSIZE=48
56: ++ BATCHSIZE=48
56: ++ export GRADIENT_STEPS=1
56: ++ GRADIENT_STEPS=1
56: ++ export LR=0.0020992
56: ++ LR=0.0020992
57: + [[ -n 1 ]]
56: ++ export MAX_SAMPLES_TERMINATION=4500000
56: ++ MAX_SAMPLES_TERMINATION=4500000
56: ++ export MAX_STEPS=1059
57: + [[ 64 -gt 16 ]]
57: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
56: ++ MAX_STEPS=1059
56: ++ export OPT_LAMB_BETA_1=0.60466
56: ++ OPT_LAMB_BETA_1=0.60466
56: ++ export OPT_LAMB_BETA_2=0.85437
56: ++ OPT_LAMB_BETA_2=0.85437
56: ++ export START_WARMUP_STEP=0
56: ++ START_WARMUP_STEP=0
56: ++ export WARMUP_PROPORTION=0.0
56: ++ WARMUP_PROPORTION=0.0
56: ++ export WEIGHT_DECAY_RATE=0.1
56: ++ WEIGHT_DECAY_RATE=0.1
56: ++ export INIT_LOSS_SCALE=4096.0
56: ++ INIT_LOSS_SCALE=4096.0
56: ++ export SBATCH_NETWORK=sharp
56: ++ SBATCH_NETWORK=sharp
56: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
56: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
56: ++ export PHASE=2
56: ++ PHASE=2
56: ++ export EVAL_ITER_START_SAMPLES=175000
56: ++ EVAL_ITER_START_SAMPLES=175000
56: ++ export EVAL_ITER_SAMPLES=175000
56: ++ EVAL_ITER_SAMPLES=175000
56: ++ export DGXNNODES=16
56: ++ DGXNNODES=16
57: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
57: =0     --bert_config_path=/workspace/phase1/bert_config.json '
57: + '[' -n 1 ']'
57: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
57: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
57: + [[ 0 != 1 ]]
57: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
57: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
57: + [[ '' -ge 1 ]]
57: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
57: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
57: + [[ 0 != 0 ]]
57: + '[' '' = apiLog.sh ']'
57: + '[' '' = 1 ']'
57: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
57:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=16398'
57: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
57: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=16398
56: +++ sed 's/^config_//'
56: +++ sed 's/\.sh$//'
56: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
28: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
28: ++ export BATCHSIZE=48
28: ++ BATCHSIZE=48
28: ++ export GRADIENT_STEPS=1
28: ++ GRADIENT_STEPS=1
28: ++ export LR=0.0020992
28: ++ LR=0.0020992
28: ++ export MAX_SAMPLES_TERMINATION=4500000
28: ++ MAX_SAMPLES_TERMINATION=4500000
28: ++ export MAX_STEPS=1059
28: ++ MAX_STEPS=1059
28: ++ export OPT_LAMB_BETA_1=0.60466
28: ++ OPT_LAMB_BETA_1=0.60466
28: ++ export OPT_LAMB_BETA_2=0.85437
28: ++ OPT_LAMB_BETA_2=0.85437
28: ++ export START_WARMUP_STEP=0
28: ++ START_WARMUP_STEP=0
28: ++ export WARMUP_PROPORTION=0.0
28: ++ WARMUP_PROPORTION=0.0
28: ++ export WEIGHT_DECAY_RATE=0.1
28: ++ WEIGHT_DECAY_RATE=0.1
28: ++ export INIT_LOSS_SCALE=4096.0
28: ++ INIT_LOSS_SCALE=4096.0
28: ++ export SBATCH_NETWORK=sharp
28: ++ SBATCH_NETWORK=sharp
28: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
28: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
28: ++ export PHASE=2
28: ++ PHASE=2
28: ++ export EVAL_ITER_START_SAMPLES=175000
28: ++ EVAL_ITER_START_SAMPLES=175000
28: ++ export EVAL_ITER_SAMPLES=175000
28: ++ EVAL_ITER_SAMPLES=175000
28: ++ export DGXNNODES=16
28: ++ DGXNNODES=16
28: +++ sed 's/^config_//'
28: +++ sed 's/\.sh$//'
28: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
56: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 8: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 8: ++ export BATCHSIZE=48
 8: ++ BATCHSIZE=48
 8: ++ export GRADIENT_STEPS=1
 8: ++ GRADIENT_STEPS=1
 8: ++ export LR=0.0020992
 8: ++ LR=0.0020992
 8: ++ export MAX_SAMPLES_TERMINATION=4500000
 8: ++ MAX_SAMPLES_TERMINATION=4500000
 8: ++ export MAX_STEPS=1059
 8: ++ MAX_STEPS=1059
 8: ++ export OPT_LAMB_BETA_1=0.60466
 8: ++ OPT_LAMB_BETA_1=0.60466
 8: ++ export OPT_LAMB_BETA_2=0.85437
 8: ++ OPT_LAMB_BETA_2=0.85437
 8: ++ export START_WARMUP_STEP=0
 8: ++ START_WARMUP_STEP=0
 8: ++ export WARMUP_PROPORTION=0.0
 8: ++ WARMUP_PROPORTION=0.0
 8: ++ export WEIGHT_DECAY_RATE=0.1
 8: ++ WEIGHT_DECAY_RATE=0.1
 8: ++ export INIT_LOSS_SCALE=4096.0
 8: ++ INIT_LOSS_SCALE=4096.0
 8: ++ export SBATCH_NETWORK=sharp
 8: ++ SBATCH_NETWORK=sharp
 8: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 8: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 8: ++ export PHASE=2
 8: ++ PHASE=2
 8: ++ export EVAL_ITER_START_SAMPLES=175000
 8: ++ EVAL_ITER_START_SAMPLES=175000
 8: ++ export EVAL_ITER_SAMPLES=175000
 8: ++ EVAL_ITER_SAMPLES=175000
 8: ++ export DGXNNODES=16
 8: ++ DGXNNODES=16
 8: +++ sed 's/^config_//'
 8: +++ sed 's/\.sh$//'
 8: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
28: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
56: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
56: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
56: ++ export WALLTIME_MINUTES=15
56: ++ WALLTIME_MINUTES=15
56: ++ export WALLTIME=20
56: ++ WALLTIME=20
56: ++ export DGXNGPU=4
56: ++ DGXNGPU=4
56: ++ export DGXSOCKETCORES=64
56: ++ DGXSOCKETCORES=64
56: ++ export DGXNSOCKET=2
56: ++ DGXNSOCKET=2
56: ++ export DGXHT=1
56: ++ DGXHT=1
56: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
56: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
56: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
24: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
56: ++ export MLPERF_SUBMISSION_ORG=Dell
56: ++ MLPERF_SUBMISSION_ORG=Dell
56: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
56: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
56: ++ export OMP_NUM_THREADS=8
56: ++ OMP_NUM_THREADS=8
56: + ulimit -Sn 100000
56: + '[' '' = 1 ']'
56: + : 48
56: + : 1
56: + : 0.0020992
56: + : 1059
56: + : 2
56: + : 0
56: + : ''
56: + : ''\'''\'''
56: + : 4603
56: + : 2508
56: + : 14
56: + : 4
56: + : ''
56: + : 0
56: + : 175000
56: + : 175000
56: + : 4500000
56: + : 0.60466
56: + : 0.85437
56: + : 0
56: + : 0.720
56: + : 0
56: + : 0.0
56: + : 0.0
56: + : 0.1
56: + : 0
56: + : 0
56: + : 0
56: + : 0
56: + : 0
56: + : 0
56: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
56: Run vars: id 2508 gpus 4 mparams ''
24: ++ export BATCHSIZE=48
24: ++ BATCHSIZE=48
56: ++ date +%s
24: ++ export GRADIENT_STEPS=1
24: ++ GRADIENT_STEPS=1
24: ++ export LR=0.0020992
24: ++ LR=0.0020992
24: ++ export MAX_SAMPLES_TERMINATION=4500000
24: ++ MAX_SAMPLES_TERMINATION=4500000
24: ++ export MAX_STEPS=1059
24: ++ MAX_STEPS=1059
24: ++ export OPT_LAMB_BETA_1=0.60466
24: ++ OPT_LAMB_BETA_1=0.60466
24: ++ export OPT_LAMB_BETA_2=0.85437
24: ++ OPT_LAMB_BETA_2=0.85437
24: ++ export START_WARMUP_STEP=0
24: ++ START_WARMUP_STEP=0
24: ++ export WARMUP_PROPORTION=0.0
24: ++ WARMUP_PROPORTION=0.0
24: ++ export WEIGHT_DECAY_RATE=0.1
24: ++ WEIGHT_DECAY_RATE=0.1
24: ++ export INIT_LOSS_SCALE=4096.0
24: ++ INIT_LOSS_SCALE=4096.0
24: ++ export SBATCH_NETWORK=sharp
24: ++ SBATCH_NETWORK=sharp
24: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
24: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
24: ++ export PHASE=2
24: ++ PHASE=2
24: ++ export EVAL_ITER_START_SAMPLES=175000
24: ++ EVAL_ITER_START_SAMPLES=175000
24: ++ export EVAL_ITER_SAMPLES=175000
24: ++ EVAL_ITER_SAMPLES=175000
24: ++ export DGXNNODES=16
24: ++ DGXNNODES=16
 8: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
24: +++ sed 's/^config_//'
24: +++ sed 's/\.sh$//'
24: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
28: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
28: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
28: ++ export WALLTIME_MINUTES=15
28: ++ WALLTIME_MINUTES=15
28: ++ export WALLTIME=20
28: ++ WALLTIME=20
28: ++ export DGXNGPU=4
28: ++ DGXNGPU=4
28: ++ export DGXSOCKETCORES=64
28: ++ DGXSOCKETCORES=64
28: ++ export DGXNSOCKET=2
28: ++ DGXNSOCKET=2
56: + START=1665667532
28: ++ export DGXHT=1
28: ++ DGXHT=1
28: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
28: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
28: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
28: ++ export MLPERF_SUBMISSION_ORG=Dell
28: ++ MLPERF_SUBMISSION_ORG=Dell
28: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
28: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
28: ++ export OMP_NUM_THREADS=8
28: ++ OMP_NUM_THREADS=8
28: + ulimit -Sn 100000
28: + '[' '' = 1 ']'
28: + : 48
28: + : 1
28: + : 0.0020992
28: + : 1059
28: + : 2
28: + : 0
56: ++ date '+%Y-%m-%d %r'
28: + : ''
28: + : ''\'''\'''
28: + : 150
28: + : 2508
28: + : 7
28: + : 4
28: + : ''
28: + : 0
28: + : 175000
28: + : 175000
28: + : 4500000
28: + : 0.60466
28: + : 0.85437
28: + : 0
28: + : 0.720
28: + : 0
28: + : 0.0
28: + : 0.0
28: + : 0.1
28: + : 0
28: + : 0
28: + : 0
28: + : 0
28: + : 0
28: + : 0
28: Run vars: id 2508 gpus 4 mparams ''
28: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
28: ++ date +%s
 8: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 8: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 8: ++ export WALLTIME_MINUTES=15
 8: ++ WALLTIME_MINUTES=15
 8: ++ export WALLTIME=20
 8: ++ WALLTIME=20
 8: ++ export DGXNGPU=4
 8: ++ DGXNGPU=4
 8: ++ export DGXSOCKETCORES=64
 8: ++ DGXSOCKETCORES=64
 8: ++ export DGXNSOCKET=2
 8: ++ DGXNSOCKET=2
 8: ++ export DGXHT=1
 8: ++ DGXHT=1
56: + START_FMT='2022-10-13 08:25:32 AM'
 8: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 8: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 8: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 8: ++ export MLPERF_SUBMISSION_ORG=Dell
 8: ++ MLPERF_SUBMISSION_ORG=Dell
 8: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 8: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 8: ++ export OMP_NUM_THREADS=8
 8: ++ OMP_NUM_THREADS=8
 8: + ulimit -Sn 100000
 8: + '[' '' = 1 ']'
 8: + : 48
 8: + : 1
56: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
 8: + : 0.0020992
 8: + : 1059
56: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
 8: + : 2
56: + '[' '!' -z '' ']'
 8: + : 0
56: + '[' 0 -gt 0 ']'
 8: + : ''
 8: + : ''\'''\'''
 8: + : 28765
 8: + : 2508
 8: + : 2
 8: + : 4
 8: + : ''
 8: + : 0
 8: + : 175000
 8: + : 175000
56: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 8: + : 4500000
56: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 8: + : 0.60466
 8: + : 0.85437
56: + PHASES=("$PHASE1" "$PHASE2")
 8: + : 0
 8: + : 0.720
 8: + : 0
 8: + : 0.0
 8: + : 0.0
 8: + : 0.1
 8: + : 0
 8: + : 0
 8: Run vars: id 2508 gpus 4 mparams ''
 8: + : 0
56: WORLD_SIZE=64
 8: + : 0
 8: + : 0
 8: + : 0
56: + export RANK=56
56: + RANK=56
56: + export WORLD_SIZE=64
56: + WORLD_SIZE=64
 8: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
56: + echo WORLD_SIZE=64
24: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 8: ++ date +%s
56: ++ cut -d - -f1
56: ++ cut -d - -f2 -
56: ++ tr -d '['
56: ++ echo 'node[022-023,027-040]'
28: + START=1665667532
32: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
28: ++ date '+%Y-%m-%d %r'
32: ++ export BATCHSIZE=48
32: ++ BATCHSIZE=48
 8: + START=1665667532
32: ++ export GRADIENT_STEPS=1
32: ++ GRADIENT_STEPS=1
32: ++ export LR=0.0020992
32: ++ LR=0.0020992
32: ++ export MAX_SAMPLES_TERMINATION=4500000
32: ++ MAX_SAMPLES_TERMINATION=4500000
32: ++ export MAX_STEPS=1059
32: ++ MAX_STEPS=1059
28: + START_FMT='2022-10-13 08:25:32 AM'
32: ++ export OPT_LAMB_BETA_1=0.60466
32: ++ OPT_LAMB_BETA_1=0.60466
32: ++ export OPT_LAMB_BETA_2=0.85437
32: ++ OPT_LAMB_BETA_2=0.85437
32: ++ export START_WARMUP_STEP=0
32: ++ START_WARMUP_STEP=0
32: ++ export WARMUP_PROPORTION=0.0
32: ++ WARMUP_PROPORTION=0.0
32: ++ export WEIGHT_DECAY_RATE=0.1
32: ++ WEIGHT_DECAY_RATE=0.1
32: ++ export INIT_LOSS_SCALE=4096.0
32: ++ INIT_LOSS_SCALE=4096.0
28: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
32: ++ export SBATCH_NETWORK=sharp
32: ++ SBATCH_NETWORK=sharp
28: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
32: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
32: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
28: + '[' '!' -z '' ']'
32: ++ export PHASE=2
32: ++ PHASE=2
32: ++ export EVAL_ITER_START_SAMPLES=175000
32: ++ EVAL_ITER_START_SAMPLES=175000
32: ++ export EVAL_ITER_SAMPLES=175000
32: ++ EVAL_ITER_SAMPLES=175000
32: ++ export DGXNNODES=16
32: ++ DGXNNODES=16
 8: ++ date '+%Y-%m-%d %r'
28: + '[' 0 -gt 0 ']'
28: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
56: + export MASTER_ADDR=node022
56: + MASTER_ADDR=node022
28: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
28: + PHASES=("$PHASE1" "$PHASE2")
28: + export RANK=28
28: + RANK=28
28: + export WORLD_SIZE=64
28: + WORLD_SIZE=64
28: WORLD_SIZE=64
28: + echo WORLD_SIZE=64
56: MASTER_ADDR=node022
24: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
24: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
56: + echo MASTER_ADDR=node022
56: + export MASTER_PORT=19002
56: + MASTER_PORT=19002
56: HOSTNAME=node022
56: + echo HOSTNAME=node022
56: + declare -a CMD
56: + [[ -n 0 ]]
56: + [[ 64 -gt 16 ]]
24: ++ export WALLTIME_MINUTES=15
24: ++ WALLTIME_MINUTES=15
56: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
24: ++ export WALLTIME=20
24: ++ WALLTIME=20
24: ++ export DGXNGPU=4
24: ++ DGXNGPU=4
24: ++ export DGXSOCKETCORES=64
24: ++ DGXSOCKETCORES=64
24: ++ export DGXNSOCKET=2
24: ++ DGXNSOCKET=2
24: ++ export DGXHT=1
24: ++ DGXHT=1
24: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
24: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
24: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
56: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
24: ++ export MLPERF_SUBMISSION_ORG=Dell
24: ++ MLPERF_SUBMISSION_ORG=Dell
24: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
24: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
24: ++ export OMP_NUM_THREADS=8
32: +++ sed 's/^config_//'
24: ++ OMP_NUM_THREADS=8
24: + ulimit -Sn 100000
24: + '[' '' = 1 ']'
24: + : 48
24: + : 1
24: + : 0.0020992
24: + : 1059
24: + : 2
24: + : 0
24: + : ''
56: =0     --bert_config_path=/workspace/phase1/bert_config.json '
24: + : ''\'''\'''
56: + '[' -n 0 ']'
56: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
32: +++ sed 's/\.sh$//'
56: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
32: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
56: + [[ 0 != 1 ]]
28: ++ cut -d - -f1
56: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
24: + : 24998
56: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
24: + : 2508
56: + [[ '' -ge 1 ]]
24: + : 6
24: + : 4
24: + : ''
24: + : 0
24: + : 175000
24: + : 175000
24: + : 4500000
24: + : 0.60466
56: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
24: + : 0.85437
56: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
24: + : 0
28: ++ cut -d - -f2 -
56: + [[ 0 != 0 ]]
24: + : 0.720
56: + '[' '' = apiLog.sh ']'
24: + : 0
56: + '[' '' = 1 ']'
24: + : 0.0
24: Run vars: id 2508 gpus 4 mparams ''
24: + : 0.0
24: + : 0.1
24: + : 0
24: + : 0
24: + : 0
 8: + START_FMT='2022-10-13 08:25:32 AM'
24: + : 0
24: + : 0
24: + : 0
28: ++ tr -d '['
24: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
56: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
56:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=4603'
 8: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
 8: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
 8: + '[' '!' -z '' ']'
56: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
56: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=4603
 8: + '[' 0 -gt 0 ']'
 8: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 8: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
24: ++ date +%s
 8: + PHASES=("$PHASE1" "$PHASE2")
 8: + export RANK=8
 8: + RANK=8
 8: + export WORLD_SIZE=64
 8: + WORLD_SIZE=64
 8: WORLD_SIZE=64
 8: + echo WORLD_SIZE=64
28: ++ echo 'node[022-023,027-040]'
 8: ++ cut -d - -f1
 8: ++ echo 'node[022-023,027-040]'
 8: ++ cut -d - -f2 -
 8: ++ tr -d '['
32: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
28: + export MASTER_ADDR=node022
28: + MASTER_ADDR=node022
28: + echo MASTER_ADDR=node022
28: MASTER_ADDR=node022
24: + START=1665667532
28: + export MASTER_PORT=19002
28: + MASTER_PORT=19002
28: HOSTNAME=node022
28: + echo HOSTNAME=node022
28: + declare -a CMD
28: + [[ -n 0 ]]
28: + [[ 64 -gt 16 ]]
28: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
28: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
24: ++ date '+%Y-%m-%d %r'
28: =0     --bert_config_path=/workspace/phase1/bert_config.json '
28: + '[' -n 0 ']'
28: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
28: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
28: + [[ 0 != 1 ]]
28: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
28: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
28: + [[ '' -ge 1 ]]
28: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
28: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
28: + [[ 0 != 0 ]]
28: + '[' '' = apiLog.sh ']'
28: + '[' '' = 1 ']'
28: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
28:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=150'
 8: + export MASTER_ADDR=node022
 8: + MASTER_ADDR=node022
 8: MASTER_ADDR=node022
28: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 8: + echo MASTER_ADDR=node022
28: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=150
 8: HOSTNAME=node022
 8: + export MASTER_PORT=19002
 8: + MASTER_PORT=19002
 8: + echo HOSTNAME=node022
 8: + declare -a CMD
 8: + [[ -n 0 ]]
 8: + [[ 64 -gt 16 ]]
 8: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 8: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 8: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 8: + '[' -n 0 ']'
 8: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 8: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
 8: + [[ 0 != 1 ]]
 8: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 8: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 8: + [[ '' -ge 1 ]]
 8: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 8: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 8: + [[ 0 != 0 ]]
 8: + '[' '' = apiLog.sh ']'
 8: + '[' '' = 1 ']'
 8: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
31: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 8:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=28765'
24: + START_FMT='2022-10-13 08:25:32 AM'
 8: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
24: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
24: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
 8: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=28765
24: + '[' '!' -z '' ']'
24: + '[' 0 -gt 0 ']'
31: ++ export BATCHSIZE=48
31: ++ BATCHSIZE=48
24: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
24: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
24: + PHASES=("$PHASE1" "$PHASE2")
31: ++ export GRADIENT_STEPS=1
31: ++ GRADIENT_STEPS=1
31: ++ export LR=0.0020992
31: ++ LR=0.0020992
31: ++ export MAX_SAMPLES_TERMINATION=4500000
31: ++ MAX_SAMPLES_TERMINATION=4500000
31: ++ export MAX_STEPS=1059
31: ++ MAX_STEPS=1059
31: ++ export OPT_LAMB_BETA_1=0.60466
31: ++ OPT_LAMB_BETA_1=0.60466
31: ++ export OPT_LAMB_BETA_2=0.85437
31: ++ OPT_LAMB_BETA_2=0.85437
31: ++ export START_WARMUP_STEP=0
31: ++ START_WARMUP_STEP=0
31: ++ export WARMUP_PROPORTION=0.0
24: + export RANK=24
24: + RANK=24
31: ++ WARMUP_PROPORTION=0.0
24: + export WORLD_SIZE=64
24: + WORLD_SIZE=64
24: WORLD_SIZE=64
31: ++ export WEIGHT_DECAY_RATE=0.1
31: ++ WEIGHT_DECAY_RATE=0.1
24: + echo WORLD_SIZE=64
31: ++ export INIT_LOSS_SCALE=4096.0
31: ++ INIT_LOSS_SCALE=4096.0
31: ++ export SBATCH_NETWORK=sharp
31: ++ SBATCH_NETWORK=sharp
31: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
31: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
31: ++ export PHASE=2
31: ++ PHASE=2
31: ++ export EVAL_ITER_START_SAMPLES=175000
31: ++ EVAL_ITER_START_SAMPLES=175000
31: ++ export EVAL_ITER_SAMPLES=175000
31: ++ EVAL_ITER_SAMPLES=175000
31: ++ export DGXNNODES=16
31: ++ DGXNNODES=16
31: +++ sed 's/^config_//'
31: +++ sed 's/\.sh$//'
24: ++ cut -d - -f1
31: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
24: ++ cut -d - -f2 -
24: ++ tr -d '['
32: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
32: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
32: ++ export WALLTIME_MINUTES=15
32: ++ WALLTIME_MINUTES=15
32: ++ export WALLTIME=20
32: ++ WALLTIME=20
32: ++ export DGXNGPU=4
32: ++ DGXNGPU=4
32: ++ export DGXSOCKETCORES=64
32: ++ DGXSOCKETCORES=64
32: ++ export DGXNSOCKET=2
32: ++ DGXNSOCKET=2
32: ++ export DGXHT=1
32: ++ DGXHT=1
32: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
32: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
32: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
32: ++ export MLPERF_SUBMISSION_ORG=Dell
32: ++ MLPERF_SUBMISSION_ORG=Dell
32: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
32: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
32: ++ export OMP_NUM_THREADS=8
32: ++ OMP_NUM_THREADS=8
32: + ulimit -Sn 100000
32: + '[' '' = 1 ']'
32: + : 48
32: + : 1
32: + : 0.0020992
32: + : 1059
32: + : 2
32: + : 0
32: + : ''
32: + : ''\'''\'''
32: + : 21354
32: + : 2508
32: + : 8
32: + : 4
32: + : ''
32: + : 0
32: + : 175000
24: ++ echo 'node[022-023,027-040]'
32: + : 175000
32: + : 4500000
32: + : 0.60466
32: + : 0.85437
32: + : 0
32: + : 0.720
32: + : 0
32: + : 0.0
32: + : 0.0
32: + : 0.1
32: + : 0
32: + : 0
32: + : 0
32: + : 0
32: + : 0
32: + : 0
32: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
32: Run vars: id 2508 gpus 4 mparams ''
32: ++ date +%s
31: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
24: + export MASTER_ADDR=node022
24: + MASTER_ADDR=node022
24: MASTER_ADDR=node022
24: + echo MASTER_ADDR=node022
24: + export MASTER_PORT=19002
24: + MASTER_PORT=19002
24: HOSTNAME=node022
24: + echo HOSTNAME=node022
24: + declare -a CMD
24: + [[ -n 0 ]]
24: + [[ 64 -gt 16 ]]
24: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
24: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
24: =0     --bert_config_path=/workspace/phase1/bert_config.json '
24: + '[' -n 0 ']'
24: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
32: + START=1665667532
24: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
24: + [[ 0 != 1 ]]
24: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
24: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
24: + [[ '' -ge 1 ]]
24: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
24: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
24: + [[ 0 != 0 ]]
24: + '[' '' = apiLog.sh ']'
24: + '[' '' = 1 ']'
32: ++ date '+%Y-%m-%d %r'
24: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
24:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=24998'
24: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
24: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=24998
32: + START_FMT='2022-10-13 08:25:32 AM'
32: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
32: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
32: + '[' '!' -z '' ']'
32: + '[' 0 -gt 0 ']'
32: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
32: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
32: + PHASES=("$PHASE1" "$PHASE2")
32: + export RANK=32
32: + RANK=32
32: + export WORLD_SIZE=64
32: + WORLD_SIZE=64
32: WORLD_SIZE=64
32: + echo WORLD_SIZE=64
31: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
31: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
31: ++ export WALLTIME_MINUTES=15
31: ++ WALLTIME_MINUTES=15
31: ++ export WALLTIME=20
31: ++ WALLTIME=20
31: ++ export DGXNGPU=4
31: ++ DGXNGPU=4
31: ++ export DGXSOCKETCORES=64
31: ++ DGXSOCKETCORES=64
31: ++ export DGXNSOCKET=2
31: ++ DGXNSOCKET=2
31: ++ export DGXHT=1
31: ++ DGXHT=1
31: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
31: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
31: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
31: ++ export MLPERF_SUBMISSION_ORG=Dell
31: ++ MLPERF_SUBMISSION_ORG=Dell
31: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
31: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
31: ++ export OMP_NUM_THREADS=8
31: ++ OMP_NUM_THREADS=8
31: + ulimit -Sn 100000
31: + '[' '' = 1 ']'
31: + : 48
31: + : 1
31: + : 0.0020992
31: + : 1059
31: + : 2
31: + : 3
31: + : ''
31: + : ''\'''\'''
31: + : 11478
31: + : 2508
31: + : 7
31: + : 4
31: + : ''
31: + : 0
31: + : 175000
31: + : 175000
31: + : 4500000
31: + : 0.60466
31: + : 0.85437
31: + : 0
32: ++ cut -d - -f1
31: + : 0.720
31: + : 0
31: + : 0.0
31: + : 0.0
31: + : 0.1
31: + : 0
31: + : 0
31: + : 0
31: + : 0
31: + : 0
31: + : 0
31: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
31: Run vars: id 2508 gpus 4 mparams ''
32: ++ cut -d - -f2 -
32: ++ tr -d '['
31: ++ date +%s
32: ++ echo 'node[022-023,027-040]'
31: + START=1665667532
31: ++ date '+%Y-%m-%d %r'
32: + export MASTER_ADDR=node022
32: + MASTER_ADDR=node022
32: + echo MASTER_ADDR=node022
32: MASTER_ADDR=node022
32: + export MASTER_PORT=19002
32: + MASTER_PORT=19002
32: HOSTNAME=node022
32: + echo HOSTNAME=node022
32: + declare -a CMD
32: + [[ -n 0 ]]
32: + [[ 64 -gt 16 ]]
32: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
32: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
32: =0     --bert_config_path=/workspace/phase1/bert_config.json '
32: + '[' -n 0 ']'
32: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
32: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
32: + [[ 0 != 1 ]]
32: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
32: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
32: + [[ '' -ge 1 ]]
32: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
32: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
32: + [[ 0 != 0 ]]
32: + '[' '' = apiLog.sh ']'
32: + '[' '' = 1 ']'
32: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
32:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=21354'
32: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
32: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=21354
31: + START_FMT='2022-10-13 08:25:32 AM'
31: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
31: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
31: + '[' '!' -z '' ']'
31: + '[' 0 -gt 0 ']'
31: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
31: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
31: + PHASES=("$PHASE1" "$PHASE2")
31: + export RANK=31
31: + RANK=31
31: + export WORLD_SIZE=64
31: + WORLD_SIZE=64
31: WORLD_SIZE=64
31: + echo WORLD_SIZE=64
34: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
34: ++ export BATCHSIZE=48
34: ++ BATCHSIZE=48
34: ++ export GRADIENT_STEPS=1
31: ++ cut -d - -f1
34: ++ GRADIENT_STEPS=1
34: ++ export LR=0.0020992
34: ++ LR=0.0020992
34: ++ export MAX_SAMPLES_TERMINATION=4500000
34: ++ MAX_SAMPLES_TERMINATION=4500000
34: ++ export MAX_STEPS=1059
34: ++ MAX_STEPS=1059
34: ++ export OPT_LAMB_BETA_1=0.60466
34: ++ OPT_LAMB_BETA_1=0.60466
34: ++ export OPT_LAMB_BETA_2=0.85437
34: ++ OPT_LAMB_BETA_2=0.85437
34: ++ export START_WARMUP_STEP=0
34: ++ START_WARMUP_STEP=0
34: ++ export WARMUP_PROPORTION=0.0
34: ++ WARMUP_PROPORTION=0.0
31: ++ cut -d - -f2 -
34: ++ export WEIGHT_DECAY_RATE=0.1
34: ++ WEIGHT_DECAY_RATE=0.1
31: ++ tr -d '['
34: ++ export INIT_LOSS_SCALE=4096.0
34: ++ INIT_LOSS_SCALE=4096.0
31: ++ echo 'node[022-023,027-040]'
34: ++ export SBATCH_NETWORK=sharp
34: ++ SBATCH_NETWORK=sharp
34: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
34: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
34: ++ export PHASE=2
34: ++ PHASE=2
34: ++ export EVAL_ITER_START_SAMPLES=175000
34: ++ EVAL_ITER_START_SAMPLES=175000
34: ++ export EVAL_ITER_SAMPLES=175000
34: ++ EVAL_ITER_SAMPLES=175000
34: ++ export DGXNNODES=16
34: ++ DGXNNODES=16
34: +++ sed 's/^config_//'
34: +++ sed 's/\.sh$//'
34: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
31: + export MASTER_ADDR=node022
31: + MASTER_ADDR=node022
31: MASTER_ADDR=node022
31: + echo MASTER_ADDR=node022
31: + export MASTER_PORT=19002
31: + MASTER_PORT=19002
31: HOSTNAME=node022
31: + echo HOSTNAME=node022
31: + declare -a CMD
31: + [[ -n 3 ]]
31: + [[ 64 -gt 16 ]]
31: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 4: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
31: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
31: =0     --bert_config_path=/workspace/phase1/bert_config.json '
31: + '[' -n 3 ']'
31: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
31: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
31: + [[ 0 != 1 ]]
31: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
31: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
31: + [[ '' -ge 1 ]]
34: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
31: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
31: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
31: + [[ 0 != 0 ]]
31: + '[' '' = apiLog.sh ']'
31: + '[' '' = 1 ']'
31: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
31:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=11478'
31: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 4: ++ export BATCHSIZE=48
 4: ++ BATCHSIZE=48
31: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=11478
 4: ++ export GRADIENT_STEPS=1
 4: ++ GRADIENT_STEPS=1
 4: ++ export LR=0.0020992
 4: ++ LR=0.0020992
 4: ++ export MAX_SAMPLES_TERMINATION=4500000
 4: ++ MAX_SAMPLES_TERMINATION=4500000
 4: ++ export MAX_STEPS=1059
 4: ++ MAX_STEPS=1059
 4: ++ export OPT_LAMB_BETA_1=0.60466
 4: ++ OPT_LAMB_BETA_1=0.60466
 4: ++ export OPT_LAMB_BETA_2=0.85437
 4: ++ OPT_LAMB_BETA_2=0.85437
 4: ++ export START_WARMUP_STEP=0
11: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 4: ++ START_WARMUP_STEP=0
 4: ++ export WARMUP_PROPORTION=0.0
 4: ++ WARMUP_PROPORTION=0.0
 4: ++ export WEIGHT_DECAY_RATE=0.1
 4: ++ WEIGHT_DECAY_RATE=0.1
 4: ++ export INIT_LOSS_SCALE=4096.0
 4: ++ INIT_LOSS_SCALE=4096.0
 4: ++ export SBATCH_NETWORK=sharp
 4: ++ SBATCH_NETWORK=sharp
 4: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 4: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 4: ++ export PHASE=2
 4: ++ PHASE=2
 4: ++ export EVAL_ITER_START_SAMPLES=175000
 4: ++ EVAL_ITER_START_SAMPLES=175000
 4: ++ export EVAL_ITER_SAMPLES=175000
 4: ++ EVAL_ITER_SAMPLES=175000
 4: ++ export DGXNNODES=16
 4: ++ DGXNNODES=16
11: ++ export BATCHSIZE=48
11: ++ BATCHSIZE=48
11: ++ export GRADIENT_STEPS=1
11: ++ GRADIENT_STEPS=1
11: ++ export LR=0.0020992
11: ++ LR=0.0020992
11: ++ export MAX_SAMPLES_TERMINATION=4500000
11: ++ MAX_SAMPLES_TERMINATION=4500000
11: ++ export MAX_STEPS=1059
11: ++ MAX_STEPS=1059
11: ++ export OPT_LAMB_BETA_1=0.60466
11: ++ OPT_LAMB_BETA_1=0.60466
11: ++ export OPT_LAMB_BETA_2=0.85437
11: ++ OPT_LAMB_BETA_2=0.85437
11: ++ export START_WARMUP_STEP=0
11: ++ START_WARMUP_STEP=0
11: ++ export WARMUP_PROPORTION=0.0
11: ++ WARMUP_PROPORTION=0.0
11: ++ export WEIGHT_DECAY_RATE=0.1
11: ++ WEIGHT_DECAY_RATE=0.1
11: ++ export INIT_LOSS_SCALE=4096.0
11: ++ INIT_LOSS_SCALE=4096.0
11: ++ export SBATCH_NETWORK=sharp
11: ++ SBATCH_NETWORK=sharp
11: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
11: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
11: ++ export PHASE=2
11: ++ PHASE=2
11: ++ export EVAL_ITER_START_SAMPLES=175000
11: ++ EVAL_ITER_START_SAMPLES=175000
11: ++ export EVAL_ITER_SAMPLES=175000
11: ++ EVAL_ITER_SAMPLES=175000
11: ++ export DGXNNODES=16
11: ++ DGXNNODES=16
11: +++ sed 's/^config_//'
 4: +++ sed 's/^config_//'
11: +++ sed 's/\.sh$//'
11: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 4: +++ sed 's/\.sh$//'
 4: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
34: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
34: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
34: ++ export WALLTIME_MINUTES=15
34: ++ WALLTIME_MINUTES=15
34: ++ export WALLTIME=20
34: ++ WALLTIME=20
34: ++ export DGXNGPU=4
34: ++ DGXNGPU=4
34: ++ export DGXSOCKETCORES=64
34: ++ DGXSOCKETCORES=64
34: ++ export DGXNSOCKET=2
34: ++ DGXNSOCKET=2
34: ++ export DGXHT=1
34: ++ DGXHT=1
34: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
34: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
34: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
34: ++ export MLPERF_SUBMISSION_ORG=Dell
34: ++ MLPERF_SUBMISSION_ORG=Dell
34: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
34: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
34: ++ export OMP_NUM_THREADS=8
34: ++ OMP_NUM_THREADS=8
34: + ulimit -Sn 100000
34: + '[' '' = 1 ']'
34: + : 48
34: + : 1
34: + : 0.0020992
34: + : 1059
34: + : 2
34: + : 2
34: + : ''
34: + : ''\'''\'''
34: + : 6334
34: + : 2508
34: + : 8
34: + : 4
34: + : ''
34: + : 0
34: + : 175000
34: + : 175000
34: + : 4500000
34: + : 0.60466
34: + : 0.85437
34: + : 0
34: + : 0.720
34: + : 0
34: + : 0.0
34: + : 0.0
34: + : 0.1
34: + : 0
34: + : 0
34: + : 0
34: + : 0
34: + : 0
34: + : 0
34: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
34: Run vars: id 2508 gpus 4 mparams ''
34: ++ date +%s
11: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 4: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
34: + START=1665667532
34: ++ date '+%Y-%m-%d %r'
11: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
11: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
11: ++ export WALLTIME_MINUTES=15
11: ++ WALLTIME_MINUTES=15
11: ++ export WALLTIME=20
11: ++ WALLTIME=20
11: ++ export DGXNGPU=4
11: ++ DGXNGPU=4
11: ++ export DGXSOCKETCORES=64
11: ++ DGXSOCKETCORES=64
11: ++ export DGXNSOCKET=2
11: ++ DGXNSOCKET=2
11: ++ export DGXHT=1
11: ++ DGXHT=1
11: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
11: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
11: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
11: ++ export MLPERF_SUBMISSION_ORG=Dell
11: ++ MLPERF_SUBMISSION_ORG=Dell
11: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
11: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
11: ++ export OMP_NUM_THREADS=8
11: ++ OMP_NUM_THREADS=8
11: + ulimit -Sn 100000
11: + '[' '' = 1 ']'
11: + : 48
11: + : 1
11: + : 0.0020992
11: + : 1059
11: + : 2
11: + : 3
11: + : ''
50: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
11: + : ''\'''\'''
11: + : 4557
11: + : 2508
11: + : 2
11: + : 4
11: + : ''
11: + : 0
11: + : 175000
11: + : 175000
11: + : 4500000
11: + : 0.60466
11: + : 0.85437
11: + : 0
11: + : 0.720
11: + : 0
11: + : 0.0
11: + : 0.0
11: + : 0.1
11: + : 0
11: + : 0
11: + : 0
11: + : 0
11: + : 0
11: + : 0
11: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
11: Run vars: id 2508 gpus 4 mparams ''
34: + START_FMT='2022-10-13 08:25:32 AM'
 4: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 4: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
34: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
34: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
34: + '[' '!' -z '' ']'
58: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 4: ++ export WALLTIME_MINUTES=15
 4: ++ WALLTIME_MINUTES=15
 4: ++ export WALLTIME=20
 4: ++ WALLTIME=20
34: + '[' 0 -gt 0 ']'
 4: ++ export DGXNGPU=4
 4: ++ DGXNGPU=4
34: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 4: ++ export DGXSOCKETCORES=64
 4: ++ DGXSOCKETCORES=64
 4: ++ export DGXNSOCKET=2
 4: ++ DGXNSOCKET=2
58: ++ export BATCHSIZE=48
58: ++ BATCHSIZE=48
 4: ++ export DGXHT=1
 4: ++ DGXHT=1
 4: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 4: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 4: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
34: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 4: ++ export MLPERF_SUBMISSION_ORG=Dell
 4: ++ MLPERF_SUBMISSION_ORG=Dell
34: + PHASES=("$PHASE1" "$PHASE2")
11: ++ date +%s
 4: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 4: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
34: + export RANK=34
34: + RANK=34
 4: ++ export OMP_NUM_THREADS=8
 4: ++ OMP_NUM_THREADS=8
 4: + ulimit -Sn 100000
 4: + '[' '' = 1 ']'
 4: + : 48
 4: + : 1
 4: + : 0.0020992
34: WORLD_SIZE=64
34: + export WORLD_SIZE=64
34: + WORLD_SIZE=64
58: ++ export GRADIENT_STEPS=1
58: ++ GRADIENT_STEPS=1
 4: + : 1059
58: ++ export LR=0.0020992
58: ++ LR=0.0020992
 4: + : 2
34: + echo WORLD_SIZE=64
58: ++ export MAX_SAMPLES_TERMINATION=4500000
58: ++ MAX_SAMPLES_TERMINATION=4500000
58: ++ export MAX_STEPS=1059
58: ++ MAX_STEPS=1059
58: ++ export OPT_LAMB_BETA_1=0.60466
58: ++ OPT_LAMB_BETA_1=0.60466
58: ++ export OPT_LAMB_BETA_2=0.85437
58: ++ OPT_LAMB_BETA_2=0.85437
 4: + : 0
58: ++ export START_WARMUP_STEP=0
58: ++ START_WARMUP_STEP=0
 4: + : ''
58: ++ export WARMUP_PROPORTION=0.0
58: ++ WARMUP_PROPORTION=0.0
 4: + : ''\'''\'''
 4: + : 16599
 4: + : 2508
 4: + : 1
 4: + : 4
 4: + : ''
58: ++ export WEIGHT_DECAY_RATE=0.1
58: ++ WEIGHT_DECAY_RATE=0.1
58: ++ export INIT_LOSS_SCALE=4096.0
58: ++ INIT_LOSS_SCALE=4096.0
58: ++ export SBATCH_NETWORK=sharp
58: ++ SBATCH_NETWORK=sharp
 4: + : 0
58: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
58: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
50: ++ export BATCHSIZE=48
50: ++ BATCHSIZE=48
 4: + : 175000
58: ++ export PHASE=2
 4: + : 175000
58: ++ PHASE=2
 4: + : 4500000
58: ++ export EVAL_ITER_START_SAMPLES=175000
 4: + : 0.60466
58: ++ EVAL_ITER_START_SAMPLES=175000
 4: + : 0.85437
58: ++ export EVAL_ITER_SAMPLES=175000
 4: + : 0
58: ++ EVAL_ITER_SAMPLES=175000
 4: + : 0.720
58: ++ export DGXNNODES=16
58: ++ DGXNNODES=16
 4: + : 0
 4: + : 0.0
 4: Run vars: id 2508 gpus 4 mparams ''
 4: + : 0.0
 4: + : 0.1
 4: + : 0
50: ++ export GRADIENT_STEPS=1
50: ++ GRADIENT_STEPS=1
50: ++ export LR=0.0020992
50: ++ LR=0.0020992
 4: + : 0
50: ++ export MAX_SAMPLES_TERMINATION=4500000
50: ++ MAX_SAMPLES_TERMINATION=4500000
50: ++ export MAX_STEPS=1059
50: ++ MAX_STEPS=1059
 4: + : 0
50: ++ export OPT_LAMB_BETA_1=0.60466
50: ++ OPT_LAMB_BETA_1=0.60466
 4: + : 0
50: ++ export OPT_LAMB_BETA_2=0.85437
50: ++ OPT_LAMB_BETA_2=0.85437
 4: + : 0
50: ++ export START_WARMUP_STEP=0
50: ++ START_WARMUP_STEP=0
 4: + : 0
50: ++ export WARMUP_PROPORTION=0.0
50: ++ WARMUP_PROPORTION=0.0
50: ++ export WEIGHT_DECAY_RATE=0.1
50: ++ WEIGHT_DECAY_RATE=0.1
50: ++ export INIT_LOSS_SCALE=4096.0
50: ++ INIT_LOSS_SCALE=4096.0
50: ++ export SBATCH_NETWORK=sharp
50: ++ SBATCH_NETWORK=sharp
 4: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
50: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
50: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
50: ++ export PHASE=2
50: ++ PHASE=2
50: ++ export EVAL_ITER_START_SAMPLES=175000
50: ++ EVAL_ITER_START_SAMPLES=175000
50: ++ export EVAL_ITER_SAMPLES=175000
50: ++ EVAL_ITER_SAMPLES=175000
50: ++ export DGXNNODES=16
50: ++ DGXNNODES=16
30: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 4: ++ date +%s
34: ++ cut -d - -f1
58: +++ sed 's/^config_//'
34: ++ cut -d - -f2 -
30: ++ export BATCHSIZE=48
30: ++ BATCHSIZE=48
34: ++ tr -d '['
34: ++ echo 'node[022-023,027-040]'
58: +++ sed 's/\.sh$//'
30: ++ export GRADIENT_STEPS=1
30: ++ GRADIENT_STEPS=1
30: ++ export LR=0.0020992
30: ++ LR=0.0020992
30: ++ export MAX_SAMPLES_TERMINATION=4500000
30: ++ MAX_SAMPLES_TERMINATION=4500000
30: ++ export MAX_STEPS=1059
30: ++ MAX_STEPS=1059
30: ++ export OPT_LAMB_BETA_1=0.60466
30: ++ OPT_LAMB_BETA_1=0.60466
30: ++ export OPT_LAMB_BETA_2=0.85437
30: ++ OPT_LAMB_BETA_2=0.85437
30: ++ export START_WARMUP_STEP=0
30: ++ START_WARMUP_STEP=0
58: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
30: ++ export WARMUP_PROPORTION=0.0
30: ++ WARMUP_PROPORTION=0.0
30: ++ export WEIGHT_DECAY_RATE=0.1
30: ++ WEIGHT_DECAY_RATE=0.1
30: ++ export INIT_LOSS_SCALE=4096.0
30: ++ INIT_LOSS_SCALE=4096.0
30: ++ export SBATCH_NETWORK=sharp
30: ++ SBATCH_NETWORK=sharp
30: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
30: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
30: ++ export PHASE=2
30: ++ PHASE=2
30: ++ export EVAL_ITER_START_SAMPLES=175000
30: ++ EVAL_ITER_START_SAMPLES=175000
30: ++ export EVAL_ITER_SAMPLES=175000
30: ++ EVAL_ITER_SAMPLES=175000
30: ++ export DGXNNODES=16
30: ++ DGXNNODES=16
50: +++ sed 's/^config_//'
50: +++ sed 's/\.sh$//'
50: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
44: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
30: +++ sed 's/^config_//'
30: +++ sed 's/\.sh$//'
30: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
44: ++ export BATCHSIZE=48
44: ++ BATCHSIZE=48
44: ++ export GRADIENT_STEPS=1
44: ++ GRADIENT_STEPS=1
11: + START=1665667532
44: ++ export LR=0.0020992
44: ++ LR=0.0020992
44: ++ export MAX_SAMPLES_TERMINATION=4500000
44: ++ MAX_SAMPLES_TERMINATION=4500000
44: ++ export MAX_STEPS=1059
44: ++ MAX_STEPS=1059
44: ++ export OPT_LAMB_BETA_1=0.60466
44: ++ OPT_LAMB_BETA_1=0.60466
44: ++ export OPT_LAMB_BETA_2=0.85437
44: ++ OPT_LAMB_BETA_2=0.85437
44: ++ export START_WARMUP_STEP=0
44: ++ START_WARMUP_STEP=0
44: ++ export WARMUP_PROPORTION=0.0
44: ++ WARMUP_PROPORTION=0.0
44: ++ export WEIGHT_DECAY_RATE=0.1
44: ++ WEIGHT_DECAY_RATE=0.1
44: ++ export INIT_LOSS_SCALE=4096.0
44: ++ INIT_LOSS_SCALE=4096.0
44: ++ export SBATCH_NETWORK=sharp
44: ++ SBATCH_NETWORK=sharp
44: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
44: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
44: ++ export PHASE=2
44: ++ PHASE=2
44: ++ export EVAL_ITER_START_SAMPLES=175000
44: ++ EVAL_ITER_START_SAMPLES=175000
44: ++ export EVAL_ITER_SAMPLES=175000
44: ++ EVAL_ITER_SAMPLES=175000
44: ++ export DGXNNODES=16
44: ++ DGXNNODES=16
11: ++ date '+%Y-%m-%d %r'
44: +++ sed 's/^config_//'
44: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
44: +++ sed 's/\.sh$//'
 4: + START=1665667532
58: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 4: ++ date '+%Y-%m-%d %r'
34: + export MASTER_ADDR=node022
11: + START_FMT='2022-10-13 08:25:32 AM'
11: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
34: + MASTER_ADDR=node022
34: MASTER_ADDR=node022
11: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
34: + echo MASTER_ADDR=node022
11: + '[' '!' -z '' ']'
34: + export MASTER_PORT=19002
34: HOSTNAME=node022
11: + '[' 0 -gt 0 ']'
34: + MASTER_PORT=19002
34: + echo HOSTNAME=node022
34: + declare -a CMD
34: + [[ -n 2 ]]
11: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
34: + [[ 64 -gt 16 ]]
11: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
34: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
11: + PHASES=("$PHASE1" "$PHASE2")
11: + export RANK=11
11: + RANK=11
11: + export WORLD_SIZE=64
11: + WORLD_SIZE=64
11: WORLD_SIZE=64
11: + echo WORLD_SIZE=64
34: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
50: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
19: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
34: =0     --bert_config_path=/workspace/phase1/bert_config.json '
34: + '[' -n 2 ']'
30: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
34: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
34: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
34: + [[ 0 != 1 ]]
34: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
34: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
34: + [[ '' -ge 1 ]]
34: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
34: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
34: + [[ 0 != 0 ]]
34: + '[' '' = apiLog.sh ']'
34: + '[' '' = 1 ']'
34: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
34:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=6334'
 4: + START_FMT='2022-10-13 08:25:32 AM'
 4: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
 4: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
34: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 4: + '[' '!' -z '' ']'
34: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=6334
11: ++ cut -d - -f1
 4: + '[' 0 -gt 0 ']'
19: ++ export BATCHSIZE=48
19: ++ BATCHSIZE=48
 4: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
11: ++ cut -d - -f2 -
 4: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 4: + PHASES=("$PHASE1" "$PHASE2")
 4: + export RANK=4
 4: + RANK=4
19: ++ export GRADIENT_STEPS=1
 4: + export WORLD_SIZE=64
 4: + WORLD_SIZE=64
11: ++ tr -d '['
19: ++ GRADIENT_STEPS=1
19: ++ export LR=0.0020992
19: ++ LR=0.0020992
19: ++ export MAX_SAMPLES_TERMINATION=4500000
19: ++ MAX_SAMPLES_TERMINATION=4500000
19: ++ export MAX_STEPS=1059
19: ++ MAX_STEPS=1059
19: ++ export OPT_LAMB_BETA_1=0.60466
19: ++ OPT_LAMB_BETA_1=0.60466
19: ++ export OPT_LAMB_BETA_2=0.85437
19: ++ OPT_LAMB_BETA_2=0.85437
 4: WORLD_SIZE=64
19: ++ export START_WARMUP_STEP=0
19: ++ START_WARMUP_STEP=0
19: ++ export WARMUP_PROPORTION=0.0
19: ++ WARMUP_PROPORTION=0.0
19: ++ export WEIGHT_DECAY_RATE=0.1
19: ++ WEIGHT_DECAY_RATE=0.1
19: ++ export INIT_LOSS_SCALE=4096.0
 4: + echo WORLD_SIZE=64
19: ++ INIT_LOSS_SCALE=4096.0
19: ++ export SBATCH_NETWORK=sharp
19: ++ SBATCH_NETWORK=sharp
11: ++ echo 'node[022-023,027-040]'
19: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
19: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
19: ++ export PHASE=2
19: ++ PHASE=2
19: ++ export EVAL_ITER_START_SAMPLES=175000
19: ++ EVAL_ITER_START_SAMPLES=175000
19: ++ export EVAL_ITER_SAMPLES=175000
19: ++ EVAL_ITER_SAMPLES=175000
19: ++ export DGXNNODES=16
19: ++ DGXNNODES=16
19: +++ sed 's/^config_//'
 4: ++ cut -d - -f1
 4: ++ cut -d - -f2 -
19: +++ sed 's/\.sh$//'
 4: ++ tr -d '['
19: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
58: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
44: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
58: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
58: ++ export WALLTIME_MINUTES=15
58: ++ WALLTIME_MINUTES=15
58: ++ export WALLTIME=20
58: ++ WALLTIME=20
58: ++ export DGXNGPU=4
58: ++ DGXNGPU=4
58: ++ export DGXSOCKETCORES=64
58: ++ DGXSOCKETCORES=64
58: ++ export DGXNSOCKET=2
58: ++ DGXNSOCKET=2
58: ++ export DGXHT=1
58: ++ DGXHT=1
58: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
58: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
58: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
58: ++ export MLPERF_SUBMISSION_ORG=Dell
58: ++ MLPERF_SUBMISSION_ORG=Dell
58: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
58: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
58: ++ export OMP_NUM_THREADS=8
58: ++ OMP_NUM_THREADS=8
58: + ulimit -Sn 100000
58: + '[' '' = 1 ']'
58: + : 48
58: + : 1
58: + : 0.0020992
58: + : 1059
58: + : 2
58: + : 2
58: + : ''
58: + : ''\'''\'''
58: + : 23659
58: + : 2508
58: + : 14
58: + : 4
58: + : ''
58: + : 0
58: + : 175000
58: + : 175000
58: + : 4500000
58: + : 0.60466
58: + : 0.85437
58: + : 0
58: + : 0.720
58: + : 0
58: + : 0.0
58: + : 0.0
58: + : 0.1
58: + : 0
58: + : 0
58: + : 0
58: + : 0
58: + : 0
58: + : 0
58: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
58: Run vars: id 2508 gpus 4 mparams ''
 4: ++ echo 'node[022-023,027-040]'
58: ++ date +%s
30: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
30: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
50: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
30: ++ export WALLTIME_MINUTES=15
30: ++ WALLTIME_MINUTES=15
50: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
30: ++ export WALLTIME=20
30: ++ WALLTIME=20
50: ++ export WALLTIME_MINUTES=15
50: ++ WALLTIME_MINUTES=15
30: ++ export DGXNGPU=4
50: ++ export WALLTIME=20
50: ++ WALLTIME=20
30: ++ DGXNGPU=4
50: ++ export DGXNGPU=4
50: ++ DGXNGPU=4
30: ++ export DGXSOCKETCORES=64
30: ++ DGXSOCKETCORES=64
50: ++ export DGXSOCKETCORES=64
50: ++ DGXSOCKETCORES=64
30: ++ export DGXNSOCKET=2
50: ++ export DGXNSOCKET=2
50: ++ DGXNSOCKET=2
30: ++ DGXNSOCKET=2
50: ++ export DGXHT=1
50: ++ DGXHT=1
30: ++ export DGXHT=1
30: ++ DGXHT=1
30: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
30: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
30: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
50: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
50: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
30: ++ export MLPERF_SUBMISSION_ORG=Dell
30: ++ MLPERF_SUBMISSION_ORG=Dell
50: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
30: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
30: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
50: ++ export MLPERF_SUBMISSION_ORG=Dell
50: ++ MLPERF_SUBMISSION_ORG=Dell
30: ++ export OMP_NUM_THREADS=8
50: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
50: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
30: ++ OMP_NUM_THREADS=8
50: ++ export OMP_NUM_THREADS=8
50: ++ OMP_NUM_THREADS=8
30: + ulimit -Sn 100000
50: + ulimit -Sn 100000
30: + '[' '' = 1 ']'
30: + : 48
30: + : 1
50: + '[' '' = 1 ']'
30: + : 0.0020992
50: + : 48
30: + : 1059
50: + : 1
30: + : 2
50: + : 0.0020992
11: + export MASTER_ADDR=node022
11: + MASTER_ADDR=node022
30: + : 2
50: + : 1059
30: + : ''
50: + : 2
30: + : ''\'''\'''
50: + : 2
30: + : 2484
50: + : ''
30: + : 2508
30: + : 7
50: + : ''\'''\'''
30: + : 4
50: + : 2968
30: + : ''
11: MASTER_ADDR=node022
50: + : 2508
30: + : 0
50: + : 12
11: HOSTNAME=node022
30: + : 175000
50: + : 4
30: + : 175000
50: + : ''
11: + echo MASTER_ADDR=node022
30: + : 4500000
50: + : 0
11: + export MASTER_PORT=19002
11: + MASTER_PORT=19002
30: + : 0.60466
50: + : 175000
30: + : 0.85437
50: + : 175000
11: + echo HOSTNAME=node022
30: + : 0
11: + declare -a CMD
30: + : 0.720
11: + [[ -n 3 ]]
11: + [[ 64 -gt 16 ]]
50: + : 4500000
30: + : 0
50: + : 0.60466
30: + : 0.0
50: + : 0.85437
30: + : 0.0
50: + : 0
30: Run vars: id 2508 gpus 4 mparams ''
30: + : 0.1
50: + : 0.720
11: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
30: + : 0
50: Run vars: id 2508 gpus 4 mparams ''
50: + : 0
30: + : 0
50: + : 0.0
30: + : 0
50: + : 0.0
30: + : 0
50: + : 0.1
30: + : 0
50: + : 0
30: + : 0
50: + : 0
30: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
50: + : 0
50: + : 0
50: + : 0
50: + : 0
50: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
11: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
11: =0     --bert_config_path=/workspace/phase1/bert_config.json '
11: + '[' -n 3 ']'
11: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
11: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
11: + [[ 0 != 1 ]]
11: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
11: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
11: + [[ '' -ge 1 ]]
11: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
11: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
30: ++ date +%s
11: + [[ 0 != 0 ]]
11: + '[' '' = apiLog.sh ']'
50: ++ date +%s
11: + '[' '' = 1 ']'
11: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
11:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=4557'
11: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
11: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=4557
19: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 4: + export MASTER_ADDR=node022
 4: + MASTER_ADDR=node022
58: + START=1665667532
 4: + echo MASTER_ADDR=node022
 4: MASTER_ADDR=node022
 4: + export MASTER_PORT=19002
 4: + MASTER_PORT=19002
 4: HOSTNAME=node022
 4: + echo HOSTNAME=node022
 4: + declare -a CMD
58: ++ date '+%Y-%m-%d %r'
 4: + [[ -n 0 ]]
 4: + [[ 64 -gt 16 ]]
 4: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
39: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
44: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
44: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
44: ++ export WALLTIME_MINUTES=15
44: ++ WALLTIME_MINUTES=15
44: ++ export WALLTIME=20
44: ++ WALLTIME=20
44: ++ export DGXNGPU=4
44: ++ DGXNGPU=4
44: ++ export DGXSOCKETCORES=64
44: ++ DGXSOCKETCORES=64
44: ++ export DGXNSOCKET=2
44: ++ DGXNSOCKET=2
44: ++ export DGXHT=1
44: ++ DGXHT=1
 4: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 4: + '[' -n 0 ']'
 4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
44: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
44: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 4: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
44: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 4: + [[ 0 != 1 ]]
44: ++ export MLPERF_SUBMISSION_ORG=Dell
 4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
44: ++ MLPERF_SUBMISSION_ORG=Dell
 4: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
44: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
44: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 4: + [[ '' -ge 1 ]]
44: ++ export OMP_NUM_THREADS=8
44: ++ OMP_NUM_THREADS=8
44: + ulimit -Sn 100000
44: + '[' '' = 1 ']'
44: + : 48
44: + : 1
 4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
44: + : 0.0020992
 4: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
44: + : 1059
 4: + [[ 0 != 0 ]]
44: + : 2
 4: + '[' '' = apiLog.sh ']'
44: + : 0
 4: + '[' '' = 1 ']'
44: + : ''
44: + : ''\'''\'''
44: + : 24819
44: + : 2508
44: + : 11
44: + : 4
44: + : ''
44: + : 0
39: ++ export BATCHSIZE=48
39: ++ BATCHSIZE=48
44: + : 175000
 4: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
44: + : 175000
 4:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=16599'
44: + : 4500000
44: + : 0.60466
44: + : 0.85437
44: + : 0
44: + : 0.720
44: + : 0
44: + : 0.0
44: + : 0.0
44: + : 0.1
44: + : 0
44: + : 0
44: + : 0
44: + : 0
44: Run vars: id 2508 gpus 4 mparams ''
44: + : 0
44: + : 0
44: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
 4: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
58: + START_FMT='2022-10-13 08:25:32 AM'
39: ++ export GRADIENT_STEPS=1
39: ++ GRADIENT_STEPS=1
 4: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=16599
39: ++ export LR=0.0020992
39: ++ LR=0.0020992
39: ++ export MAX_SAMPLES_TERMINATION=4500000
39: ++ MAX_SAMPLES_TERMINATION=4500000
39: ++ export MAX_STEPS=1059
39: ++ MAX_STEPS=1059
39: ++ export OPT_LAMB_BETA_1=0.60466
39: ++ OPT_LAMB_BETA_1=0.60466
39: ++ export OPT_LAMB_BETA_2=0.85437
39: ++ OPT_LAMB_BETA_2=0.85437
39: ++ export START_WARMUP_STEP=0
39: ++ START_WARMUP_STEP=0
39: ++ export WARMUP_PROPORTION=0.0
39: ++ WARMUP_PROPORTION=0.0
39: ++ export WEIGHT_DECAY_RATE=0.1
39: ++ WEIGHT_DECAY_RATE=0.1
39: ++ export INIT_LOSS_SCALE=4096.0
39: ++ INIT_LOSS_SCALE=4096.0
58: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
39: ++ export SBATCH_NETWORK=sharp
58: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
39: ++ SBATCH_NETWORK=sharp
58: + '[' '!' -z '' ']'
39: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
39: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
58: + '[' 0 -gt 0 ']'
39: ++ export PHASE=2
39: ++ PHASE=2
39: ++ export EVAL_ITER_START_SAMPLES=175000
39: ++ EVAL_ITER_START_SAMPLES=175000
39: ++ export EVAL_ITER_SAMPLES=175000
39: ++ EVAL_ITER_SAMPLES=175000
39: ++ export DGXNNODES=16
39: ++ DGXNNODES=16
58: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
44: ++ date +%s
58: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
58: + PHASES=("$PHASE1" "$PHASE2")
58: + export RANK=58
58: + RANK=58
58: + export WORLD_SIZE=64
58: + WORLD_SIZE=64
58: + echo WORLD_SIZE=64
58: WORLD_SIZE=64
30: + START=1665667532
30: ++ date '+%Y-%m-%d %r'
39: +++ sed 's/^config_//'
58: ++ cut -d - -f1
39: +++ sed 's/\.sh$//'
58: ++ cut -d - -f2 -
39: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
58: ++ echo 'node[022-023,027-040]'
58: ++ tr -d '['
50: + START=1665667532
50: ++ date '+%Y-%m-%d %r'
30: + START_FMT='2022-10-13 08:25:32 AM'
43: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
30: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
30: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
30: + '[' '!' -z '' ']'
30: + '[' 0 -gt 0 ']'
30: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
30: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
30: + PHASES=("$PHASE1" "$PHASE2")
30: + export RANK=30
30: + RANK=30
30: + export WORLD_SIZE=64
30: + WORLD_SIZE=64
30: WORLD_SIZE=64
30: + echo WORLD_SIZE=64
19: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
19: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
19: ++ export WALLTIME_MINUTES=15
19: ++ WALLTIME_MINUTES=15
19: ++ export WALLTIME=20
19: ++ WALLTIME=20
19: ++ export DGXNGPU=4
19: ++ DGXNGPU=4
19: ++ export DGXSOCKETCORES=64
19: ++ DGXSOCKETCORES=64
19: ++ export DGXNSOCKET=2
19: ++ DGXNSOCKET=2
43: ++ export BATCHSIZE=48
43: ++ BATCHSIZE=48
19: ++ export DGXHT=1
19: ++ DGXHT=1
19: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
19: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
19: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
19: ++ export MLPERF_SUBMISSION_ORG=Dell
19: ++ MLPERF_SUBMISSION_ORG=Dell
19: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
19: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
19: ++ export OMP_NUM_THREADS=8
19: ++ OMP_NUM_THREADS=8
19: + ulimit -Sn 100000
19: + '[' '' = 1 ']'
19: + : 48
19: + : 1
43: ++ export GRADIENT_STEPS=1
43: ++ GRADIENT_STEPS=1
19: + : 0.0020992
43: ++ export LR=0.0020992
43: ++ LR=0.0020992
43: ++ export MAX_SAMPLES_TERMINATION=4500000
19: + : 1059
30: ++ cut -d - -f1
43: ++ MAX_SAMPLES_TERMINATION=4500000
43: ++ export MAX_STEPS=1059
43: ++ MAX_STEPS=1059
50: + START_FMT='2022-10-13 08:25:32 AM'
43: ++ export OPT_LAMB_BETA_1=0.60466
43: ++ OPT_LAMB_BETA_1=0.60466
43: ++ export OPT_LAMB_BETA_2=0.85437
43: ++ OPT_LAMB_BETA_2=0.85437
19: + : 2
43: ++ export START_WARMUP_STEP=0
19: + : 3
50: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
43: ++ START_WARMUP_STEP=0
19: + : ''
43: ++ export WARMUP_PROPORTION=0.0
19: + : ''\'''\'''
43: ++ WARMUP_PROPORTION=0.0
19: + : 11593
43: ++ export WEIGHT_DECAY_RATE=0.1
43: ++ WEIGHT_DECAY_RATE=0.1
19: + : 2508
43: ++ export INIT_LOSS_SCALE=4096.0
43: ++ INIT_LOSS_SCALE=4096.0
19: + : 4
43: ++ export SBATCH_NETWORK=sharp
43: ++ SBATCH_NETWORK=sharp
19: + : 4
43: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
43: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
30: ++ cut -d - -f2 -
43: ++ export PHASE=2
43: ++ PHASE=2
50: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
30: ++ echo 'node[022-023,027-040]'
30: ++ tr -d '['
43: ++ export EVAL_ITER_START_SAMPLES=175000
43: ++ EVAL_ITER_START_SAMPLES=175000
50: + '[' '!' -z '' ']'
43: ++ export EVAL_ITER_SAMPLES=175000
19: + : ''
50: + '[' 0 -gt 0 ']'
43: ++ EVAL_ITER_SAMPLES=175000
19: + : 0
43: ++ export DGXNNODES=16
43: ++ DGXNNODES=16
19: + : 175000
19: + : 175000
19: Run vars: id 2508 gpus 4 mparams ''
19: + : 4500000
19: + : 0.60466
19: + : 0.85437
50: WORLD_SIZE=64
19: + : 0
19: + : 0.720
50: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
19: + : 0
19: + : 0.0
19: + : 0.0
19: + : 0.1
19: + : 0
19: + : 0
19: + : 0
19: + : 0
19: + : 0
19: + : 0
19: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
50: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
50: + PHASES=("$PHASE1" "$PHASE2")
50: + export RANK=50
50: + RANK=50
50: + export WORLD_SIZE=64
50: + WORLD_SIZE=64
50: + echo WORLD_SIZE=64
19: ++ date +%s
44: + START=1665667532
50: ++ cut -d - -f1
58: + export MASTER_ADDR=node022
58: + MASTER_ADDR=node022
50: ++ cut -d - -f2 -
58: MASTER_ADDR=node022
44: ++ date '+%Y-%m-%d %r'
58: + echo MASTER_ADDR=node022
58: + export MASTER_PORT=19002
58: + MASTER_PORT=19002
50: ++ tr -d '['
58: HOSTNAME=node022
58: + echo HOSTNAME=node022
58: + declare -a CMD
58: + [[ -n 2 ]]
58: + [[ 64 -gt 16 ]]
58: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
58: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
43: +++ sed 's/^config_//'
39: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
58: =0     --bert_config_path=/workspace/phase1/bert_config.json '
43: +++ sed 's/\.sh$//'
58: + '[' -n 2 ']'
43: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
58: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
58: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
58: + [[ 0 != 1 ]]
58: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
58: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
58: + [[ '' -ge 1 ]]
58: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
58: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
58: + [[ 0 != 0 ]]
58: + '[' '' = apiLog.sh ']'
58: + '[' '' = 1 ']'
58: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
58:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=23659'
58: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
58: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=23659
50: ++ echo 'node[022-023,027-040]'
44: + START_FMT='2022-10-13 08:25:32 AM'
44: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
44: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
44: + '[' '!' -z '' ']'
44: + '[' 0 -gt 0 ']'
44: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
44: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
44: + PHASES=("$PHASE1" "$PHASE2")
44: + export RANK=44
44: + RANK=44
44: + export WORLD_SIZE=64
44: + WORLD_SIZE=64
44: + echo WORLD_SIZE=64
44: WORLD_SIZE=64
23: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
44: ++ cut -d - -f1
44: ++ cut -d - -f2 -
30: + export MASTER_ADDR=node022
30: + MASTER_ADDR=node022
44: ++ tr -d '['
23: ++ export BATCHSIZE=48
23: ++ BATCHSIZE=48
30: + echo MASTER_ADDR=node022
30: MASTER_ADDR=node022
30: + export MASTER_PORT=19002
30: + MASTER_PORT=19002
30: HOSTNAME=node022
30: + echo HOSTNAME=node022
30: + declare -a CMD
23: ++ export GRADIENT_STEPS=1
23: ++ GRADIENT_STEPS=1
23: ++ export LR=0.0020992
23: ++ LR=0.0020992
23: ++ export MAX_SAMPLES_TERMINATION=4500000
23: ++ MAX_SAMPLES_TERMINATION=4500000
23: ++ export MAX_STEPS=1059
23: ++ MAX_STEPS=1059
30: + [[ -n 2 ]]
23: ++ export OPT_LAMB_BETA_1=0.60466
23: ++ OPT_LAMB_BETA_1=0.60466
30: + [[ 64 -gt 16 ]]
23: ++ export OPT_LAMB_BETA_2=0.85437
23: ++ OPT_LAMB_BETA_2=0.85437
30: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
23: ++ export START_WARMUP_STEP=0
23: ++ START_WARMUP_STEP=0
23: ++ export WARMUP_PROPORTION=0.0
23: ++ WARMUP_PROPORTION=0.0
23: ++ export WEIGHT_DECAY_RATE=0.1
23: ++ WEIGHT_DECAY_RATE=0.1
23: ++ export INIT_LOSS_SCALE=4096.0
23: ++ INIT_LOSS_SCALE=4096.0
23: ++ export SBATCH_NETWORK=sharp
23: ++ SBATCH_NETWORK=sharp
23: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
23: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
23: ++ export PHASE=2
23: ++ PHASE=2
23: ++ export EVAL_ITER_START_SAMPLES=175000
23: ++ EVAL_ITER_START_SAMPLES=175000
23: ++ export EVAL_ITER_SAMPLES=175000
23: ++ EVAL_ITER_SAMPLES=175000
30: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
23: ++ export DGXNNODES=16
23: ++ DGXNNODES=16
30: =0     --bert_config_path=/workspace/phase1/bert_config.json '
30: + '[' -n 2 ']'
30: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
30: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
30: + [[ 0 != 1 ]]
30: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
30: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
30: + [[ '' -ge 1 ]]
19: + START=1665667532
30: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
30: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
30: + [[ 0 != 0 ]]
30: + '[' '' = apiLog.sh ']'
30: + '[' '' = 1 ']'
30: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
30:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=2484'
44: ++ echo 'node[022-023,027-040]'
30: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
19: ++ date '+%Y-%m-%d %r'
30: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=2484
23: +++ sed 's/^config_//'
50: + export MASTER_ADDR=node022
50: + MASTER_ADDR=node022
43: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
39: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
39: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
50: MASTER_ADDR=node022
50: + echo MASTER_ADDR=node022
23: +++ sed 's/\.sh$//'
50: HOSTNAME=node022
50: + export MASTER_PORT=19002
50: + MASTER_PORT=19002
50: + echo HOSTNAME=node022
50: + declare -a CMD
50: + [[ -n 2 ]]
50: + [[ 64 -gt 16 ]]
39: ++ export WALLTIME_MINUTES=15
39: ++ WALLTIME_MINUTES=15
50: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
23: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
39: ++ export WALLTIME=20
39: ++ WALLTIME=20
39: ++ export DGXNGPU=4
39: ++ DGXNGPU=4
39: ++ export DGXSOCKETCORES=64
39: ++ DGXSOCKETCORES=64
39: ++ export DGXNSOCKET=2
39: ++ DGXNSOCKET=2
39: ++ export DGXHT=1
39: ++ DGXHT=1
39: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
39: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
39: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
39: ++ export MLPERF_SUBMISSION_ORG=Dell
39: ++ MLPERF_SUBMISSION_ORG=Dell
39: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
39: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
39: ++ export OMP_NUM_THREADS=8
39: ++ OMP_NUM_THREADS=8
39: + ulimit -Sn 100000
39: + '[' '' = 1 ']'
39: + : 48
50: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
39: + : 1
39: + : 0.0020992
39: + : 1059
39: + : 2
39: + : 3
39: + : ''
39: + : ''\'''\'''
39: + : 19665
39: + : 2508
39: + : 9
39: + : 4
39: + : ''
39: + : 0
39: + : 175000
50: =0     --bert_config_path=/workspace/phase1/bert_config.json '
50: + '[' -n 2 ']'
50: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
50: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
50: + [[ 0 != 1 ]]
50: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
50: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
39: + : 175000
50: + [[ '' -ge 1 ]]
39: + : 4500000
39: + : 0.60466
39: + : 0.85437
39: + : 0
39: + : 0.720
39: + : 0
39: + : 0.0
39: + : 0.0
39: + : 0.1
39: + : 0
39: + : 0
39: + : 0
39: + : 0
19: + START_FMT='2022-10-13 08:25:32 AM'
50: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
39: + : 0
39: Run vars: id 2508 gpus 4 mparams ''
50: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
39: + : 0
50: + [[ 0 != 0 ]]
39: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
50: + '[' '' = apiLog.sh ']'
50: + '[' '' = 1 ']'
19: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
19: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
19: + '[' '!' -z '' ']'
27: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
50: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
50:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=2968'
19: + '[' 0 -gt 0 ']'
19: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
39: ++ date +%s
50: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
50: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=2968
27: ++ export BATCHSIZE=48
27: ++ BATCHSIZE=48
19: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
19: + PHASES=("$PHASE1" "$PHASE2")
19: + export RANK=19
19: + RANK=19
19: + export WORLD_SIZE=64
19: + WORLD_SIZE=64
19: WORLD_SIZE=64
19: + echo WORLD_SIZE=64
27: ++ export GRADIENT_STEPS=1
27: ++ GRADIENT_STEPS=1
27: ++ export LR=0.0020992
27: ++ LR=0.0020992
27: ++ export MAX_SAMPLES_TERMINATION=4500000
27: ++ MAX_SAMPLES_TERMINATION=4500000
27: ++ export MAX_STEPS=1059
27: ++ MAX_STEPS=1059
27: ++ export OPT_LAMB_BETA_1=0.60466
27: ++ OPT_LAMB_BETA_1=0.60466
27: ++ export OPT_LAMB_BETA_2=0.85437
27: ++ OPT_LAMB_BETA_2=0.85437
27: ++ export START_WARMUP_STEP=0
27: ++ START_WARMUP_STEP=0
27: ++ export WARMUP_PROPORTION=0.0
27: ++ WARMUP_PROPORTION=0.0
27: ++ export WEIGHT_DECAY_RATE=0.1
27: ++ WEIGHT_DECAY_RATE=0.1
27: ++ export INIT_LOSS_SCALE=4096.0
27: ++ INIT_LOSS_SCALE=4096.0
27: ++ export SBATCH_NETWORK=sharp
27: ++ SBATCH_NETWORK=sharp
27: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
27: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
27: ++ export PHASE=2
27: ++ PHASE=2
27: ++ export EVAL_ITER_START_SAMPLES=175000
27: ++ EVAL_ITER_START_SAMPLES=175000
27: ++ export EVAL_ITER_SAMPLES=175000
27: ++ EVAL_ITER_SAMPLES=175000
27: ++ export DGXNNODES=16
27: ++ DGXNNODES=16
19: ++ cut -d - -f1
27: +++ sed 's/^config_//'
19: ++ cut -d - -f2 -
44: + export MASTER_ADDR=node022
44: + MASTER_ADDR=node022
27: +++ sed 's/\.sh$//'
19: ++ tr -d '['
27: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
44: + echo MASTER_ADDR=node022
44: MASTER_ADDR=node022
44: + export MASTER_PORT=19002
44: + MASTER_PORT=19002
44: HOSTNAME=node022
44: + echo HOSTNAME=node022
44: + declare -a CMD
44: + [[ -n 0 ]]
44: + [[ 64 -gt 16 ]]
44: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
44: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
44: =0     --bert_config_path=/workspace/phase1/bert_config.json '
44: + '[' -n 0 ']'
44: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
44: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
44: + [[ 0 != 1 ]]
44: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
44: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
44: + [[ '' -ge 1 ]]
44: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
44: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
44: + [[ 0 != 0 ]]
44: + '[' '' = apiLog.sh ']'
44: + '[' '' = 1 ']'
44: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
44:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=24819'
19: ++ echo 'node[022-023,027-040]'
44: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
44: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=24819
23: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
43: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
43: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
43: ++ export WALLTIME_MINUTES=15
43: ++ WALLTIME_MINUTES=15
43: ++ export WALLTIME=20
43: ++ WALLTIME=20
43: ++ export DGXNGPU=4
43: ++ DGXNGPU=4
43: ++ export DGXSOCKETCORES=64
43: ++ DGXSOCKETCORES=64
43: ++ export DGXNSOCKET=2
43: ++ DGXNSOCKET=2
43: ++ export DGXHT=1
43: ++ DGXHT=1
43: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
43: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
43: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
43: ++ export MLPERF_SUBMISSION_ORG=Dell
43: ++ MLPERF_SUBMISSION_ORG=Dell
43: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
43: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
43: ++ export OMP_NUM_THREADS=8
43: ++ OMP_NUM_THREADS=8
43: + ulimit -Sn 100000
43: + '[' '' = 1 ']'
43: + : 48
43: + : 1
43: + : 0.0020992
43: + : 1059
43: + : 2
43: + : 3
43: + : ''
43: + : ''\'''\'''
43: + : 28056
43: + : 2508
43: + : 10
43: + : 4
43: + : ''
43: + : 0
39: + START=1665667532
43: + : 175000
43: + : 175000
43: + : 4500000
43: + : 0.60466
43: + : 0.85437
43: + : 0
43: + : 0.720
43: + : 0
43: + : 0.0
43: + : 0.0
43: + : 0.1
43: + : 0
43: + : 0
43: + : 0
43: + : 0
43: + : 0
43: + : 0
43: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
43: Run vars: id 2508 gpus 4 mparams ''
39: ++ date '+%Y-%m-%d %r'
43: ++ date +%s
27: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
39: + START_FMT='2022-10-13 08:25:32 AM'
19: + export MASTER_ADDR=node022
19: + MASTER_ADDR=node022
39: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
39: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
39: + '[' '!' -z '' ']'
39: + '[' 0 -gt 0 ']'
19: MASTER_ADDR=node022
19: + echo MASTER_ADDR=node022
39: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
19: HOSTNAME=node022
19: + export MASTER_PORT=19002
19: + MASTER_PORT=19002
19: + echo HOSTNAME=node022
19: + declare -a CMD
19: + [[ -n 3 ]]
19: + [[ 64 -gt 16 ]]
19: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
39: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
39: + PHASES=("$PHASE1" "$PHASE2")
39: + export RANK=39
39: + RANK=39
39: + export WORLD_SIZE=64
39: + WORLD_SIZE=64
39: WORLD_SIZE=64
39: + echo WORLD_SIZE=64
19: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
19: =0     --bert_config_path=/workspace/phase1/bert_config.json '
19: + '[' -n 3 ']'
19: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
19: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
19: + [[ 0 != 1 ]]
19: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
19: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
19: + [[ '' -ge 1 ]]
19: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
19: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
19: + [[ 0 != 0 ]]
19: + '[' '' = apiLog.sh ']'
19: + '[' '' = 1 ']'
19: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
19:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=11593'
19: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
19: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=11593
39: ++ cut -d - -f1
39: ++ cut -d - -f2 -
39: ++ tr -d '['
23: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
23: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
23: ++ export WALLTIME_MINUTES=15
23: ++ WALLTIME_MINUTES=15
23: ++ export WALLTIME=20
23: ++ WALLTIME=20
23: ++ export DGXNGPU=4
23: ++ DGXNGPU=4
23: ++ export DGXSOCKETCORES=64
23: ++ DGXSOCKETCORES=64
23: ++ export DGXNSOCKET=2
23: ++ DGXNSOCKET=2
23: ++ export DGXHT=1
23: ++ DGXHT=1
23: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
23: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
23: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
23: ++ export MLPERF_SUBMISSION_ORG=Dell
23: ++ MLPERF_SUBMISSION_ORG=Dell
23: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
23: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
23: ++ export OMP_NUM_THREADS=8
23: ++ OMP_NUM_THREADS=8
23: + ulimit -Sn 100000
23: + '[' '' = 1 ']'
23: + : 48
23: + : 1
23: + : 0.0020992
23: + : 1059
23: + : 2
23: + : 3
23: + : ''
23: + : ''\'''\'''
23: + : 31002
23: + : 2508
23: + : 5
23: + : 4
23: + : ''
23: + : 0
23: + : 175000
23: + : 175000
23: + : 4500000
23: + : 0.60466
23: + : 0.85437
23: + : 0
23: + : 0.720
23: + : 0
23: + : 0.0
39: ++ echo 'node[022-023,027-040]'
23: + : 0.0
23: + : 0.1
23: + : 0
23: + : 0
23: + : 0
23: + : 0
23: + : 0
23: + : 0
23: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
23: Run vars: id 2508 gpus 4 mparams ''
23: ++ date +%s
27: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
27: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
43: + START=1665667532
27: ++ export WALLTIME_MINUTES=15
27: ++ WALLTIME_MINUTES=15
27: ++ export WALLTIME=20
27: ++ WALLTIME=20
27: ++ export DGXNGPU=4
27: ++ DGXNGPU=4
27: ++ export DGXSOCKETCORES=64
27: ++ DGXSOCKETCORES=64
27: ++ export DGXNSOCKET=2
27: ++ DGXNSOCKET=2
27: ++ export DGXHT=1
27: ++ DGXHT=1
27: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
27: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
27: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
27: ++ export MLPERF_SUBMISSION_ORG=Dell
27: ++ MLPERF_SUBMISSION_ORG=Dell
27: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
27: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
27: ++ export OMP_NUM_THREADS=8
27: ++ OMP_NUM_THREADS=8
27: + ulimit -Sn 100000
27: + '[' '' = 1 ']'
27: + : 48
27: + : 1
27: + : 0.0020992
27: + : 1059
27: + : 2
27: + : 3
27: + : ''
27: + : ''\'''\'''
27: + : 9153
27: + : 2508
27: + : 6
27: + : 4
27: + : ''
27: + : 0
27: + : 175000
27: + : 175000
27: + : 4500000
43: ++ date '+%Y-%m-%d %r'
27: + : 0.60466
27: + : 0.85437
27: + : 0
27: + : 0.720
27: + : 0
27: + : 0.0
27: + : 0.0
27: + : 0.1
27: + : 0
27: + : 0
27: + : 0
27: + : 0
27: + : 0
27: + : 0
27: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
27: Run vars: id 2508 gpus 4 mparams ''
27: ++ date +%s
39: + export MASTER_ADDR=node022
39: + MASTER_ADDR=node022
43: + START_FMT='2022-10-13 08:25:32 AM'
43: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
39: MASTER_ADDR=node022
43: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
39: + echo MASTER_ADDR=node022
43: + '[' '!' -z '' ']'
39: HOSTNAME=node022
39: + export MASTER_PORT=19002
39: + MASTER_PORT=19002
43: + '[' 0 -gt 0 ']'
39: + echo HOSTNAME=node022
39: + declare -a CMD
39: + [[ -n 3 ]]
39: + [[ 64 -gt 16 ]]
39: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
43: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
43: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
39: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
43: + PHASES=("$PHASE1" "$PHASE2")
43: + export RANK=43
43: + RANK=43
43: + export WORLD_SIZE=64
43: + WORLD_SIZE=64
43: WORLD_SIZE=64
43: + echo WORLD_SIZE=64
39: =0     --bert_config_path=/workspace/phase1/bert_config.json '
39: + '[' -n 3 ']'
39: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
39: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
39: + [[ 0 != 1 ]]
39: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
39: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
39: + [[ '' -ge 1 ]]
39: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
39: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
39: + [[ 0 != 0 ]]
39: + '[' '' = apiLog.sh ']'
39: + '[' '' = 1 ']'
39: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
39:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=19665'
39: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
39: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=19665
43: ++ cut -d - -f1
43: ++ cut -d - -f2 -
43: ++ tr -d '['
23: + START=1665667532
27: + START=1665667532
27: ++ date '+%Y-%m-%d %r'
23: ++ date '+%Y-%m-%d %r'
43: ++ echo 'node[022-023,027-040]'
27: + START_FMT='2022-10-13 08:25:32 AM'
27: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
27: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
27: + '[' '!' -z '' ']'
27: + '[' 0 -gt 0 ']'
27: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
27: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
27: + PHASES=("$PHASE1" "$PHASE2")
27: + export RANK=27
27: + RANK=27
27: + export WORLD_SIZE=64
27: + WORLD_SIZE=64
27: WORLD_SIZE=64
27: + echo WORLD_SIZE=64
23: + START_FMT='2022-10-13 08:25:32 AM'
23: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
23: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
23: + '[' '!' -z '' ']'
23: + '[' 0 -gt 0 ']'
23: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
23: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
23: + PHASES=("$PHASE1" "$PHASE2")
23: + export RANK=23
23: + RANK=23
23: + export WORLD_SIZE=64
23: + WORLD_SIZE=64
23: + echo WORLD_SIZE=64
23: WORLD_SIZE=64
27: ++ cut -d - -f1
27: ++ cut -d - -f2 -
27: ++ echo 'node[022-023,027-040]'
27: ++ tr -d '['
23: ++ cut -d - -f1
48: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
23: ++ cut -d - -f2 -
48: ++ export BATCHSIZE=48
48: ++ BATCHSIZE=48
43: + export MASTER_ADDR=node022
43: + MASTER_ADDR=node022
23: ++ tr -d '['
43: MASTER_ADDR=node022
48: ++ export GRADIENT_STEPS=1
48: ++ GRADIENT_STEPS=1
43: + echo MASTER_ADDR=node022
43: + export MASTER_PORT=19002
43: + MASTER_PORT=19002
43: + echo HOSTNAME=node022
43: HOSTNAME=node022
48: ++ export LR=0.0020992
48: ++ LR=0.0020992
48: ++ export MAX_SAMPLES_TERMINATION=4500000
48: ++ MAX_SAMPLES_TERMINATION=4500000
43: + declare -a CMD
48: ++ export MAX_STEPS=1059
43: + [[ -n 3 ]]
48: ++ MAX_STEPS=1059
43: + [[ 64 -gt 16 ]]
48: ++ export OPT_LAMB_BETA_1=0.60466
43: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
48: ++ OPT_LAMB_BETA_1=0.60466
48: ++ export OPT_LAMB_BETA_2=0.85437
48: ++ OPT_LAMB_BETA_2=0.85437
48: ++ export START_WARMUP_STEP=0
48: ++ START_WARMUP_STEP=0
48: ++ export WARMUP_PROPORTION=0.0
48: ++ WARMUP_PROPORTION=0.0
48: ++ export WEIGHT_DECAY_RATE=0.1
48: ++ WEIGHT_DECAY_RATE=0.1
48: ++ export INIT_LOSS_SCALE=4096.0
48: ++ INIT_LOSS_SCALE=4096.0
48: ++ export SBATCH_NETWORK=sharp
48: ++ SBATCH_NETWORK=sharp
48: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
48: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
48: ++ export PHASE=2
48: ++ PHASE=2
48: ++ export EVAL_ITER_START_SAMPLES=175000
48: ++ EVAL_ITER_START_SAMPLES=175000
48: ++ export EVAL_ITER_SAMPLES=175000
48: ++ EVAL_ITER_SAMPLES=175000
48: ++ export DGXNNODES=16
48: ++ DGXNNODES=16
43: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
43: =0     --bert_config_path=/workspace/phase1/bert_config.json '
43: + '[' -n 3 ']'
43: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
43: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
43: + [[ 0 != 1 ]]
43: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
43: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
43: + [[ '' -ge 1 ]]
43: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
43: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
43: + [[ 0 != 0 ]]
43: + '[' '' = apiLog.sh ']'
43: + '[' '' = 1 ']'
43: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
43:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=28056'
43: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
43: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=28056
23: ++ echo 'node[022-023,027-040]'
48: +++ sed 's/^config_//'
48: +++ sed 's/\.sh$//'
48: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
35: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
35: ++ export BATCHSIZE=48
35: ++ BATCHSIZE=48
35: ++ export GRADIENT_STEPS=1
35: ++ GRADIENT_STEPS=1
35: ++ export LR=0.0020992
35: ++ LR=0.0020992
35: ++ export MAX_SAMPLES_TERMINATION=4500000
35: ++ MAX_SAMPLES_TERMINATION=4500000
35: ++ export MAX_STEPS=1059
35: ++ MAX_STEPS=1059
35: ++ export OPT_LAMB_BETA_1=0.60466
35: ++ OPT_LAMB_BETA_1=0.60466
35: ++ export OPT_LAMB_BETA_2=0.85437
35: ++ OPT_LAMB_BETA_2=0.85437
35: ++ export START_WARMUP_STEP=0
35: ++ START_WARMUP_STEP=0
35: ++ export WARMUP_PROPORTION=0.0
35: ++ WARMUP_PROPORTION=0.0
35: ++ export WEIGHT_DECAY_RATE=0.1
35: ++ WEIGHT_DECAY_RATE=0.1
35: ++ export INIT_LOSS_SCALE=4096.0
35: ++ INIT_LOSS_SCALE=4096.0
35: ++ export SBATCH_NETWORK=sharp
35: ++ SBATCH_NETWORK=sharp
35: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
35: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
35: ++ export PHASE=2
35: ++ PHASE=2
35: ++ export EVAL_ITER_START_SAMPLES=175000
35: ++ EVAL_ITER_START_SAMPLES=175000
35: ++ export EVAL_ITER_SAMPLES=175000
35: ++ EVAL_ITER_SAMPLES=175000
35: ++ export DGXNNODES=16
35: ++ DGXNNODES=16
35: +++ sed 's/^config_//'
27: + export MASTER_ADDR=node022
27: + MASTER_ADDR=node022
35: +++ sed 's/\.sh$//'
27: MASTER_ADDR=node022
27: + echo MASTER_ADDR=node022
27: + export MASTER_PORT=19002
27: + MASTER_PORT=19002
27: HOSTNAME=node022
27: + echo HOSTNAME=node022
27: + declare -a CMD
27: + [[ -n 3 ]]
27: + [[ 64 -gt 16 ]]
35: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
27: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
13: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
27: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
27: =0     --bert_config_path=/workspace/phase1/bert_config.json '
27: + '[' -n 3 ']'
27: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
27: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
27: + [[ 0 != 1 ]]
27: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
27: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
27: + [[ '' -ge 1 ]]
27: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
27: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
27: + [[ 0 != 0 ]]
27: + '[' '' = apiLog.sh ']'
27: + '[' '' = 1 ']'
27: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
27:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=9153'
27: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
23: + export MASTER_ADDR=node022
23: + MASTER_ADDR=node022
27: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=9153
23: MASTER_ADDR=node022
23: + echo MASTER_ADDR=node022
23: + export MASTER_PORT=19002
23: + MASTER_PORT=19002
23: + echo HOSTNAME=node022
23: HOSTNAME=node022
13: ++ export BATCHSIZE=48
13: ++ BATCHSIZE=48
23: + declare -a CMD
23: + [[ -n 3 ]]
23: + [[ 64 -gt 16 ]]
23: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
13: ++ export GRADIENT_STEPS=1
13: ++ GRADIENT_STEPS=1
13: ++ export LR=0.0020992
13: ++ LR=0.0020992
13: ++ export MAX_SAMPLES_TERMINATION=4500000
13: ++ MAX_SAMPLES_TERMINATION=4500000
13: ++ export MAX_STEPS=1059
13: ++ MAX_STEPS=1059
13: ++ export OPT_LAMB_BETA_1=0.60466
13: ++ OPT_LAMB_BETA_1=0.60466
23: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
13: ++ export OPT_LAMB_BETA_2=0.85437
13: ++ OPT_LAMB_BETA_2=0.85437
13: ++ export START_WARMUP_STEP=0
13: ++ START_WARMUP_STEP=0
13: ++ export WARMUP_PROPORTION=0.0
13: ++ WARMUP_PROPORTION=0.0
13: ++ export WEIGHT_DECAY_RATE=0.1
13: ++ WEIGHT_DECAY_RATE=0.1
13: ++ export INIT_LOSS_SCALE=4096.0
13: ++ INIT_LOSS_SCALE=4096.0
13: ++ export SBATCH_NETWORK=sharp
13: ++ SBATCH_NETWORK=sharp
13: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
13: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
48: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
23: =0     --bert_config_path=/workspace/phase1/bert_config.json '
13: ++ export PHASE=2
23: + '[' -n 3 ']'
13: ++ PHASE=2
23: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
13: ++ export EVAL_ITER_START_SAMPLES=175000
23: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
13: ++ EVAL_ITER_START_SAMPLES=175000
23: + [[ 0 != 1 ]]
13: ++ export EVAL_ITER_SAMPLES=175000
13: ++ EVAL_ITER_SAMPLES=175000
23: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
13: ++ export DGXNNODES=16
13: ++ DGXNNODES=16
23: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
23: + [[ '' -ge 1 ]]
41: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
23: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
23: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
23: + [[ 0 != 0 ]]
23: + '[' '' = apiLog.sh ']'
41: ++ export BATCHSIZE=48
41: ++ BATCHSIZE=48
23: + '[' '' = 1 ']'
23: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
23:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=31002'
41: ++ export GRADIENT_STEPS=1
41: ++ GRADIENT_STEPS=1
23: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
41: ++ export LR=0.0020992
41: ++ LR=0.0020992
23: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=31002
41: ++ export MAX_SAMPLES_TERMINATION=4500000
41: ++ MAX_SAMPLES_TERMINATION=4500000
41: ++ export MAX_STEPS=1059
41: ++ MAX_STEPS=1059
41: ++ export OPT_LAMB_BETA_1=0.60466
41: ++ OPT_LAMB_BETA_1=0.60466
41: ++ export OPT_LAMB_BETA_2=0.85437
41: ++ OPT_LAMB_BETA_2=0.85437
41: ++ export START_WARMUP_STEP=0
41: ++ START_WARMUP_STEP=0
41: ++ export WARMUP_PROPORTION=0.0
41: ++ WARMUP_PROPORTION=0.0
41: ++ export WEIGHT_DECAY_RATE=0.1
41: ++ WEIGHT_DECAY_RATE=0.1
41: ++ export INIT_LOSS_SCALE=4096.0
41: ++ INIT_LOSS_SCALE=4096.0
41: ++ export SBATCH_NETWORK=sharp
41: ++ SBATCH_NETWORK=sharp
41: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
41: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
41: ++ export PHASE=2
41: ++ PHASE=2
41: ++ export EVAL_ITER_START_SAMPLES=175000
41: ++ EVAL_ITER_START_SAMPLES=175000
41: ++ export EVAL_ITER_SAMPLES=175000
41: ++ EVAL_ITER_SAMPLES=175000
41: ++ export DGXNNODES=16
41: ++ DGXNNODES=16
13: +++ sed 's/^config_//'
13: +++ sed 's/\.sh$//'
13: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
41: +++ sed 's/^config_//'
41: +++ sed 's/\.sh$//'
41: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
35: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
26: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
26: ++ export BATCHSIZE=48
26: ++ BATCHSIZE=48
26: ++ export GRADIENT_STEPS=1
26: ++ GRADIENT_STEPS=1
26: ++ export LR=0.0020992
26: ++ LR=0.0020992
26: ++ export MAX_SAMPLES_TERMINATION=4500000
26: ++ MAX_SAMPLES_TERMINATION=4500000
26: ++ export MAX_STEPS=1059
26: ++ MAX_STEPS=1059
26: ++ export OPT_LAMB_BETA_1=0.60466
26: ++ OPT_LAMB_BETA_1=0.60466
26: ++ export OPT_LAMB_BETA_2=0.85437
26: ++ OPT_LAMB_BETA_2=0.85437
26: ++ export START_WARMUP_STEP=0
26: ++ START_WARMUP_STEP=0
26: ++ export WARMUP_PROPORTION=0.0
26: ++ WARMUP_PROPORTION=0.0
26: ++ export WEIGHT_DECAY_RATE=0.1
26: ++ WEIGHT_DECAY_RATE=0.1
26: ++ export INIT_LOSS_SCALE=4096.0
26: ++ INIT_LOSS_SCALE=4096.0
26: ++ export SBATCH_NETWORK=sharp
26: ++ SBATCH_NETWORK=sharp
26: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
26: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
26: ++ export PHASE=2
26: ++ PHASE=2
26: ++ export EVAL_ITER_START_SAMPLES=175000
26: ++ EVAL_ITER_START_SAMPLES=175000
26: ++ export EVAL_ITER_SAMPLES=175000
26: ++ EVAL_ITER_SAMPLES=175000
26: ++ export DGXNNODES=16
26: ++ DGXNNODES=16
26: +++ sed 's/^config_//'
26: +++ sed 's/\.sh$//'
48: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
48: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
26: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
48: ++ export WALLTIME_MINUTES=15
48: ++ WALLTIME_MINUTES=15
48: ++ export WALLTIME=20
48: ++ WALLTIME=20
48: ++ export DGXNGPU=4
48: ++ DGXNGPU=4
48: ++ export DGXSOCKETCORES=64
48: ++ DGXSOCKETCORES=64
48: ++ export DGXNSOCKET=2
48: ++ DGXNSOCKET=2
48: ++ export DGXHT=1
48: ++ DGXHT=1
48: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
48: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
48: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
48: ++ export MLPERF_SUBMISSION_ORG=Dell
48: ++ MLPERF_SUBMISSION_ORG=Dell
48: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
48: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
48: ++ export OMP_NUM_THREADS=8
48: ++ OMP_NUM_THREADS=8
48: + ulimit -Sn 100000
48: + '[' '' = 1 ']'
48: + : 48
48: + : 1
48: + : 0.0020992
48: + : 1059
48: + : 2
48: + : 0
48: + : ''
48: + : ''\'''\'''
48: + : 5868
48: + : 2508
48: + : 12
48: + : 4
48: + : ''
48: + : 0
48: + : 175000
48: + : 175000
48: + : 4500000
48: + : 0.60466
48: + : 0.85437
48: + : 0
48: + : 0.720
48: + : 0
48: + : 0.0
48: + : 0.0
48: + : 0.1
48: + : 0
48: + : 0
48: + : 0
48: + : 0
48: + : 0
48: + : 0
48: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
48: Run vars: id 2508 gpus 4 mparams ''
13: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
48: ++ date +%s
41: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
35: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
35: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
35: ++ export WALLTIME_MINUTES=15
35: ++ WALLTIME_MINUTES=15
35: ++ export WALLTIME=20
35: ++ WALLTIME=20
35: ++ export DGXNGPU=4
35: ++ DGXNGPU=4
35: ++ export DGXSOCKETCORES=64
35: ++ DGXSOCKETCORES=64
35: ++ export DGXNSOCKET=2
35: ++ DGXNSOCKET=2
35: ++ export DGXHT=1
35: ++ DGXHT=1
35: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
35: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
35: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
35: ++ export MLPERF_SUBMISSION_ORG=Dell
35: ++ MLPERF_SUBMISSION_ORG=Dell
35: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
35: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
35: ++ export OMP_NUM_THREADS=8
35: ++ OMP_NUM_THREADS=8
35: + ulimit -Sn 100000
35: + '[' '' = 1 ']'
35: + : 48
35: + : 1
35: + : 0.0020992
35: + : 1059
35: + : 2
35: + : 3
35: + : ''
35: + : ''\'''\'''
35: + : 9385
35: + : 2508
35: + : 8
35: + : 4
35: + : ''
35: + : 0
35: + : 175000
35: + : 175000
35: + : 4500000
35: + : 0.60466
35: + : 0.85437
35: + : 0
35: + : 0.720
35: + : 0
35: + : 0.0
35: + : 0.0
35: + : 0.1
35: + : 0
35: + : 0
35: + : 0
35: + : 0
35: + : 0
35: + : 0
35: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
35: Run vars: id 2508 gpus 4 mparams ''
35: ++ date +%s
 7: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
26: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 7: ++ export BATCHSIZE=48
 7: ++ BATCHSIZE=48
 7: ++ export GRADIENT_STEPS=1
 7: ++ GRADIENT_STEPS=1
 7: ++ export LR=0.0020992
 7: ++ LR=0.0020992
 7: ++ export MAX_SAMPLES_TERMINATION=4500000
 7: ++ MAX_SAMPLES_TERMINATION=4500000
 7: ++ export MAX_STEPS=1059
 7: ++ MAX_STEPS=1059
 7: ++ export OPT_LAMB_BETA_1=0.60466
 7: ++ OPT_LAMB_BETA_1=0.60466
 7: ++ export OPT_LAMB_BETA_2=0.85437
 7: ++ OPT_LAMB_BETA_2=0.85437
 7: ++ export START_WARMUP_STEP=0
 7: ++ START_WARMUP_STEP=0
 7: ++ export WARMUP_PROPORTION=0.0
 7: ++ WARMUP_PROPORTION=0.0
 7: ++ export WEIGHT_DECAY_RATE=0.1
 7: ++ WEIGHT_DECAY_RATE=0.1
 7: ++ export INIT_LOSS_SCALE=4096.0
 7: ++ INIT_LOSS_SCALE=4096.0
 7: ++ export SBATCH_NETWORK=sharp
 7: ++ SBATCH_NETWORK=sharp
 7: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 7: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 7: ++ export PHASE=2
 7: ++ PHASE=2
 7: ++ export EVAL_ITER_START_SAMPLES=175000
 7: ++ EVAL_ITER_START_SAMPLES=175000
 7: ++ export EVAL_ITER_SAMPLES=175000
 7: ++ EVAL_ITER_SAMPLES=175000
 7: ++ export DGXNNODES=16
 7: ++ DGXNNODES=16
18: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
18: ++ export BATCHSIZE=48
18: ++ BATCHSIZE=48
48: + START=1665667532
18: ++ export GRADIENT_STEPS=1
18: ++ GRADIENT_STEPS=1
18: ++ export LR=0.0020992
18: ++ LR=0.0020992
18: ++ export MAX_SAMPLES_TERMINATION=4500000
18: ++ MAX_SAMPLES_TERMINATION=4500000
18: ++ export MAX_STEPS=1059
18: ++ MAX_STEPS=1059
18: ++ export OPT_LAMB_BETA_1=0.60466
18: ++ OPT_LAMB_BETA_1=0.60466
18: ++ export OPT_LAMB_BETA_2=0.85437
18: ++ OPT_LAMB_BETA_2=0.85437
18: ++ export START_WARMUP_STEP=0
18: ++ START_WARMUP_STEP=0
18: ++ export WARMUP_PROPORTION=0.0
18: ++ WARMUP_PROPORTION=0.0
18: ++ export WEIGHT_DECAY_RATE=0.1
18: ++ WEIGHT_DECAY_RATE=0.1
18: ++ export INIT_LOSS_SCALE=4096.0
18: ++ INIT_LOSS_SCALE=4096.0
18: ++ export SBATCH_NETWORK=sharp
 7: +++ sed 's/^config_//'
18: ++ SBATCH_NETWORK=sharp
18: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
18: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
18: ++ export PHASE=2
18: ++ PHASE=2
18: ++ export EVAL_ITER_START_SAMPLES=175000
18: ++ EVAL_ITER_START_SAMPLES=175000
18: ++ export EVAL_ITER_SAMPLES=175000
18: ++ EVAL_ITER_SAMPLES=175000
18: ++ export DGXNNODES=16
18: ++ DGXNNODES=16
48: ++ date '+%Y-%m-%d %r'
 7: +++ sed 's/\.sh$//'
13: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
13: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 7: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
13: ++ export WALLTIME_MINUTES=15
13: ++ WALLTIME_MINUTES=15
13: ++ export WALLTIME=20
13: ++ WALLTIME=20
13: ++ export DGXNGPU=4
13: ++ DGXNGPU=4
13: ++ export DGXSOCKETCORES=64
13: ++ DGXSOCKETCORES=64
13: ++ export DGXNSOCKET=2
13: ++ DGXNSOCKET=2
13: ++ export DGXHT=1
13: ++ DGXHT=1
13: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
13: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
13: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
13: ++ export MLPERF_SUBMISSION_ORG=Dell
13: ++ MLPERF_SUBMISSION_ORG=Dell
13: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
13: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
13: ++ export OMP_NUM_THREADS=8
13: ++ OMP_NUM_THREADS=8
41: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
41: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
13: + ulimit -Sn 100000
13: + '[' '' = 1 ']'
13: + : 48
18: +++ sed 's/^config_//'
13: + : 1
13: + : 0.0020992
13: + : 1059
13: + : 2
13: + : 1
13: + : ''
13: + : ''\'''\'''
13: + : 22271
41: ++ export WALLTIME_MINUTES=15
41: ++ WALLTIME_MINUTES=15
13: + : 2508
41: ++ export WALLTIME=20
41: ++ WALLTIME=20
13: + : 3
41: ++ export DGXNGPU=4
13: + : 4
41: ++ DGXNGPU=4
13: + : ''
41: ++ export DGXSOCKETCORES=64
41: ++ DGXSOCKETCORES=64
13: + : 0
41: ++ export DGXNSOCKET=2
13: + : 175000
41: ++ DGXNSOCKET=2
13: + : 175000
41: ++ export DGXHT=1
41: ++ DGXHT=1
13: + : 4500000
41: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
41: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
13: + : 0.60466
41: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
13: + : 0.85437
41: ++ export MLPERF_SUBMISSION_ORG=Dell
41: ++ MLPERF_SUBMISSION_ORG=Dell
13: Run vars: id 2508 gpus 4 mparams ''
18: +++ sed 's/\.sh$//'
13: + : 0
41: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
41: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
13: + : 0.720
41: ++ export OMP_NUM_THREADS=8
41: ++ OMP_NUM_THREADS=8
13: + : 0
41: + ulimit -Sn 100000
13: + : 0.0
41: + '[' '' = 1 ']'
13: + : 0.0
41: + : 48
13: + : 0.1
48: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
41: + : 1
13: + : 0
35: + START=1665667532
41: + : 0.0020992
13: + : 0
41: + : 1059
13: + : 0
41: + : 2
18: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
13: + : 0
41: + : 1
41: Run vars: id 2508 gpus 4 mparams ''
13: + : 0
41: + : ''
13: + : 0
41: + : ''\'''\'''
13: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
41: + : 15141
41: + : 2508
41: + : 10
48: + START_FMT='2022-10-13 08:25:32 AM'
41: + : 4
41: + : ''
41: + : 0
41: + : 175000
41: + : 175000
13: ++ date +%s
41: + : 4500000
41: + : 0.60466
41: + : 0.85437
41: + : 0
48: WORLD_SIZE=64
41: + : 0.720
48: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
41: + : 0
41: + : 0.0
48: + '[' '!' -z '' ']'
41: + : 0.0
48: + '[' 0 -gt 0 ']'
41: + : 0.1
41: + : 0
41: + : 0
41: + : 0
41: + : 0
41: + : 0
41: + : 0
48: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
41: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
35: ++ date '+%Y-%m-%d %r'
48: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
48: + PHASES=("$PHASE1" "$PHASE2")
48: + export RANK=48
48: + RANK=48
41: ++ date +%s
48: + export WORLD_SIZE=64
48: + WORLD_SIZE=64
48: + echo WORLD_SIZE=64
26: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
26: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
26: ++ export WALLTIME_MINUTES=15
26: ++ WALLTIME_MINUTES=15
26: ++ export WALLTIME=20
26: ++ WALLTIME=20
26: ++ export DGXNGPU=4
26: ++ DGXNGPU=4
26: ++ export DGXSOCKETCORES=64
26: ++ DGXSOCKETCORES=64
26: ++ export DGXNSOCKET=2
26: ++ DGXNSOCKET=2
26: ++ export DGXHT=1
26: ++ DGXHT=1
26: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
26: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
26: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
26: ++ export MLPERF_SUBMISSION_ORG=Dell
26: ++ MLPERF_SUBMISSION_ORG=Dell
26: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
26: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
26: ++ export OMP_NUM_THREADS=8
26: ++ OMP_NUM_THREADS=8
26: + ulimit -Sn 100000
26: + '[' '' = 1 ']'
26: + : 48
26: + : 1
26: + : 0.0020992
26: + : 1059
26: + : 2
26: + : 2
26: + : ''
48: ++ cut -d - -f1
26: + : ''\'''\'''
26: + : 22524
26: + : 2508
26: + : 6
26: + : 4
26: + : ''
26: + : 0
26: + : 175000
26: + : 175000
48: ++ cut -d - -f2 -
26: + : 4500000
26: + : 0.60466
26: + : 0.85437
26: + : 0
26: + : 0.720
26: + : 0
26: + : 0.0
26: + : 0.0
26: + : 0.1
26: + : 0
26: + : 0
48: ++ echo 'node[022-023,027-040]'
26: + : 0
26: + : 0
26: + : 0
26: + : 0
26: Run vars: id 2508 gpus 4 mparams ''
26: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
48: ++ tr -d '['
35: + START_FMT='2022-10-13 08:25:32 AM'
35: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
35: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
35: + '[' '!' -z '' ']'
35: + '[' 0 -gt 0 ']'
26: ++ date +%s
35: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
35: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
35: + PHASES=("$PHASE1" "$PHASE2")
35: + export RANK=35
35: + RANK=35
35: + export WORLD_SIZE=64
35: + WORLD_SIZE=64
35: WORLD_SIZE=64
35: + echo WORLD_SIZE=64
 7: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
35: ++ cut -d - -f1
35: ++ cut -d - -f2 -
35: ++ echo 'node[022-023,027-040]'
35: ++ tr -d '['
18: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
41: + START=1665667532
41: ++ date '+%Y-%m-%d %r'
13: + START=1665667532
13: ++ date '+%Y-%m-%d %r'
41: + START_FMT='2022-10-13 08:25:32 AM'
41: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
41: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
41: + '[' '!' -z '' ']'
41: + '[' 0 -gt 0 ']'
41: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
41: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
41: + PHASES=("$PHASE1" "$PHASE2")
41: + export RANK=41
41: + RANK=41
41: + export WORLD_SIZE=64
41: + WORLD_SIZE=64
41: WORLD_SIZE=64
41: + echo WORLD_SIZE=64
26: + START=1665667532
48: + export MASTER_ADDR=node022
48: + MASTER_ADDR=node022
41: ++ cut -d - -f1
48: MASTER_ADDR=node022
48: + echo MASTER_ADDR=node022
48: + export MASTER_PORT=19002
48: + MASTER_PORT=19002
48: + echo HOSTNAME=node022
48: HOSTNAME=node022
48: + declare -a CMD
26: ++ date '+%Y-%m-%d %r'
48: + [[ -n 0 ]]
48: + [[ 64 -gt 16 ]]
48: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
41: ++ cut -d - -f2 -
13: + START_FMT='2022-10-13 08:25:32 AM'
13: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
41: ++ tr -d '['
48: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
13: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
48: =0     --bert_config_path=/workspace/phase1/bert_config.json '
48: + '[' -n 0 ']'
48: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
13: + '[' '!' -z '' ']'
48: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
13: + '[' 0 -gt 0 ']'
41: ++ echo 'node[022-023,027-040]'
48: + [[ 0 != 1 ]]
48: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
48: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
48: + [[ '' -ge 1 ]]
13: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
48: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
48: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
48: + [[ 0 != 0 ]]
48: + '[' '' = apiLog.sh ']'
48: + '[' '' = 1 ']'
13: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
13: + PHASES=("$PHASE1" "$PHASE2")
13: + export RANK=13
13: + RANK=13
13: + export WORLD_SIZE=64
13: + WORLD_SIZE=64
13: WORLD_SIZE=64
13: + echo WORLD_SIZE=64
48: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
48:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=5868'
 7: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
48: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 7: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
48: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=5868
 7: ++ export WALLTIME_MINUTES=15
 7: ++ WALLTIME_MINUTES=15
 7: ++ export WALLTIME=20
 7: ++ WALLTIME=20
 7: ++ export DGXNGPU=4
 7: ++ DGXNGPU=4
 7: ++ export DGXSOCKETCORES=64
 7: ++ DGXSOCKETCORES=64
 7: ++ export DGXNSOCKET=2
 7: ++ DGXNSOCKET=2
26: + START_FMT='2022-10-13 08:25:32 AM'
 7: ++ export DGXHT=1
 7: ++ DGXHT=1
 7: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 7: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 7: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 7: ++ export MLPERF_SUBMISSION_ORG=Dell
 7: ++ MLPERF_SUBMISSION_ORG=Dell
 7: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 7: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 7: ++ export OMP_NUM_THREADS=8
 7: ++ OMP_NUM_THREADS=8
 7: + ulimit -Sn 100000
 7: + '[' '' = 1 ']'
 7: + : 48
26: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
26: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
 7: + : 1
 7: + : 0.0020992
35: + export MASTER_ADDR=node022
35: + MASTER_ADDR=node022
26: + '[' '!' -z '' ']'
 7: + : 1059
26: + '[' 0 -gt 0 ']'
 7: + : 2
 7: + : 3
 7: + : ''
 7: + : ''\'''\'''
 7: + : 6519
 7: + : 2508
 7: + : 1
 7: + : 4
26: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 7: + : ''
 7: + : 0
 7: + : 175000
35: MASTER_ADDR=node022
 7: + : 175000
 7: + : 4500000
35: + echo MASTER_ADDR=node022
35: HOSTNAME=node022
35: + export MASTER_PORT=19002
35: + MASTER_PORT=19002
35: + echo HOSTNAME=node022
35: + declare -a CMD
35: + [[ -n 3 ]]
 7: + : 0.60466
 7: + : 0.85437
 7: + : 0
 7: + : 0.720
 7: + : 0
 7: + : 0.0
26: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 7: + : 0.0
26: + PHASES=("$PHASE1" "$PHASE2")
26: WORLD_SIZE=64
 7: + : 0.1
35: + [[ 64 -gt 16 ]]
26: + export RANK=26
26: + RANK=26
 7: + : 0
35: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
26: + export WORLD_SIZE=64
26: + WORLD_SIZE=64
26: + echo WORLD_SIZE=64
13: ++ cut -d - -f1
 7: + : 0
 7: Run vars: id 2508 gpus 4 mparams ''
 7: + : 0
 7: + : 0
 7: + : 0
 7: + : 0
 7: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
35: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
18: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
18: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
35: =0     --bert_config_path=/workspace/phase1/bert_config.json '
13: ++ cut -d - -f2 -
35: + '[' -n 3 ']'
35: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
18: ++ export WALLTIME_MINUTES=15
35: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
18: ++ WALLTIME_MINUTES=15
35: + [[ 0 != 1 ]]
18: ++ export WALLTIME=20
18: ++ WALLTIME=20
13: ++ tr -d '['
35: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
18: ++ export DGXNGPU=4
18: ++ DGXNGPU=4
35: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
18: ++ export DGXSOCKETCORES=64
35: + [[ '' -ge 1 ]]
18: ++ DGXSOCKETCORES=64
18: ++ export DGXNSOCKET=2
18: ++ DGXNSOCKET=2
18: ++ export DGXHT=1
18: ++ DGXHT=1
18: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
18: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
18: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
18: ++ export MLPERF_SUBMISSION_ORG=Dell
18: ++ MLPERF_SUBMISSION_ORG=Dell
18: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
18: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
18: ++ export OMP_NUM_THREADS=8
18: ++ OMP_NUM_THREADS=8
18: + ulimit -Sn 100000
18: + '[' '' = 1 ']'
18: + : 48
35: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
18: + : 1
35: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
18: + : 0.0020992
35: + [[ 0 != 0 ]]
18: + : 1059
35: + '[' '' = apiLog.sh ']'
35: + '[' '' = 1 ']'
35: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
 7: ++ date +%s
18: + : 2
18: + : 2
18: + : ''
18: + : ''\'''\'''
18: + : 5332
18: + : 2508
35:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=9385'
18: + : 4
18: + : 4
18: + : ''
18: + : 0
18: + : 175000
18: + : 175000
18: + : 4500000
18: + : 0.60466
18: + : 0.85437
18: + : 0
18: + : 0.720
18: + : 0
18: + : 0.0
18: + : 0.0
18: + : 0.1
35: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
18: + : 0
35: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=9385
18: + : 0
18: + : 0
21: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
18: + : 0
18: + : 0
18: Run vars: id 2508 gpus 4 mparams ''
26: ++ cut -d - -f1
18: + : 0
18: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
26: ++ cut -d - -f2 -
21: ++ export BATCHSIZE=48
21: ++ BATCHSIZE=48
13: ++ echo 'node[022-023,027-040]'
26: ++ tr -d '['
21: ++ export GRADIENT_STEPS=1
21: ++ GRADIENT_STEPS=1
26: ++ echo 'node[022-023,027-040]'
18: ++ date +%s
21: ++ export LR=0.0020992
21: ++ LR=0.0020992
21: ++ export MAX_SAMPLES_TERMINATION=4500000
21: ++ MAX_SAMPLES_TERMINATION=4500000
21: ++ export MAX_STEPS=1059
21: ++ MAX_STEPS=1059
21: ++ export OPT_LAMB_BETA_1=0.60466
21: ++ OPT_LAMB_BETA_1=0.60466
21: ++ export OPT_LAMB_BETA_2=0.85437
21: ++ OPT_LAMB_BETA_2=0.85437
21: ++ export START_WARMUP_STEP=0
21: ++ START_WARMUP_STEP=0
21: ++ export WARMUP_PROPORTION=0.0
21: ++ WARMUP_PROPORTION=0.0
21: ++ export WEIGHT_DECAY_RATE=0.1
21: ++ WEIGHT_DECAY_RATE=0.1
21: ++ export INIT_LOSS_SCALE=4096.0
21: ++ INIT_LOSS_SCALE=4096.0
21: ++ export SBATCH_NETWORK=sharp
21: ++ SBATCH_NETWORK=sharp
21: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
21: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
21: ++ export PHASE=2
21: ++ PHASE=2
21: ++ export EVAL_ITER_START_SAMPLES=175000
21: ++ EVAL_ITER_START_SAMPLES=175000
21: ++ export EVAL_ITER_SAMPLES=175000
21: ++ EVAL_ITER_SAMPLES=175000
21: ++ export DGXNNODES=16
21: ++ DGXNNODES=16
41: + export MASTER_ADDR=node022
41: + MASTER_ADDR=node022
41: + echo MASTER_ADDR=node022
41: MASTER_ADDR=node022
21: +++ sed 's/^config_//'
41: + export MASTER_PORT=19002
41: + MASTER_PORT=19002
41: HOSTNAME=node022
41: + echo HOSTNAME=node022
41: + declare -a CMD
41: + [[ -n 1 ]]
21: +++ sed 's/\.sh$//'
41: + [[ 64 -gt 16 ]]
41: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
21: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
41: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
41: =0     --bert_config_path=/workspace/phase1/bert_config.json '
41: + '[' -n 1 ']'
41: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
41: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
41: + [[ 0 != 1 ]]
41: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
41: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
41: + [[ '' -ge 1 ]]
41: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
41: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
41: + [[ 0 != 0 ]]
41: + '[' '' = apiLog.sh ']'
41: + '[' '' = 1 ']'
41: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
41:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=15141'
41: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
41: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=15141
13: + export MASTER_ADDR=node022
13: + MASTER_ADDR=node022
13: MASTER_ADDR=node022
13: + echo MASTER_ADDR=node022
13: + export MASTER_PORT=19002
13: + MASTER_PORT=19002
13: HOSTNAME=node022
13: + echo HOSTNAME=node022
13: + declare -a CMD
13: + [[ -n 1 ]]
13: + [[ 64 -gt 16 ]]
13: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 7: + START=1665667532
18: + START=1665667532
13: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
13: =0     --bert_config_path=/workspace/phase1/bert_config.json '
13: + '[' -n 1 ']'
13: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
13: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
26: + export MASTER_ADDR=node022
26: + MASTER_ADDR=node022
13: + [[ 0 != 1 ]]
13: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
13: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
13: + [[ '' -ge 1 ]]
 7: ++ date '+%Y-%m-%d %r'
18: ++ date '+%Y-%m-%d %r'
13: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
26: MASTER_ADDR=node022
26: + echo MASTER_ADDR=node022
13: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
26: HOSTNAME=node022
13: + [[ 0 != 0 ]]
26: + export MASTER_PORT=19002
26: + MASTER_PORT=19002
13: + '[' '' = apiLog.sh ']'
13: + '[' '' = 1 ']'
26: + echo HOSTNAME=node022
26: + declare -a CMD
26: + [[ -n 2 ]]
26: + [[ 64 -gt 16 ]]
26: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
13: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
13:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=22271'
26: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
13: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
13: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=22271
26: =0     --bert_config_path=/workspace/phase1/bert_config.json '
21: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
26: + '[' -n 2 ']'
26: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
26: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
26: + [[ 0 != 1 ]]
26: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
26: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
26: + [[ '' -ge 1 ]]
26: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
26: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
26: + [[ 0 != 0 ]]
26: + '[' '' = apiLog.sh ']'
26: + '[' '' = 1 ']'
26: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
26:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=22524'
14: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
26: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
14: ++ export BATCHSIZE=48
14: ++ BATCHSIZE=48
26: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=22524
14: ++ export GRADIENT_STEPS=1
14: ++ GRADIENT_STEPS=1
14: ++ export LR=0.0020992
14: ++ LR=0.0020992
14: ++ export MAX_SAMPLES_TERMINATION=4500000
14: ++ MAX_SAMPLES_TERMINATION=4500000
 7: + START_FMT='2022-10-13 08:25:32 AM'
14: ++ export MAX_STEPS=1059
14: ++ MAX_STEPS=1059
14: ++ export OPT_LAMB_BETA_1=0.60466
14: ++ OPT_LAMB_BETA_1=0.60466
14: ++ export OPT_LAMB_BETA_2=0.85437
14: ++ OPT_LAMB_BETA_2=0.85437
14: ++ export START_WARMUP_STEP=0
14: ++ START_WARMUP_STEP=0
14: ++ export WARMUP_PROPORTION=0.0
14: ++ WARMUP_PROPORTION=0.0
14: ++ export WEIGHT_DECAY_RATE=0.1
14: ++ WEIGHT_DECAY_RATE=0.1
14: ++ export INIT_LOSS_SCALE=4096.0
14: ++ INIT_LOSS_SCALE=4096.0
14: ++ export SBATCH_NETWORK=sharp
14: ++ SBATCH_NETWORK=sharp
14: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
14: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
14: ++ export PHASE=2
14: ++ PHASE=2
 7: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
14: ++ export EVAL_ITER_START_SAMPLES=175000
14: ++ EVAL_ITER_START_SAMPLES=175000
14: ++ export EVAL_ITER_SAMPLES=175000
14: ++ EVAL_ITER_SAMPLES=175000
 7: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
14: ++ export DGXNNODES=16
14: ++ DGXNNODES=16
 7: + '[' '!' -z '' ']'
18: + START_FMT='2022-10-13 08:25:32 AM'
 7: + '[' 0 -gt 0 ']'
 7: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
18: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
18: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
18: + '[' '!' -z '' ']'
36: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 7: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 7: + PHASES=("$PHASE1" "$PHASE2")
 7: + export RANK=7
 7: + RANK=7
18: + '[' 0 -gt 0 ']'
 7: + export WORLD_SIZE=64
 7: + WORLD_SIZE=64
18: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 7: WORLD_SIZE=64
 7: + echo WORLD_SIZE=64
36: ++ export BATCHSIZE=48
18: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
18: + PHASES=("$PHASE1" "$PHASE2")
18: + export RANK=18
18: + RANK=18
18: + export WORLD_SIZE=64
18: + WORLD_SIZE=64
18: + echo WORLD_SIZE=64
18: WORLD_SIZE=64
36: ++ BATCHSIZE=48
36: ++ export GRADIENT_STEPS=1
36: ++ GRADIENT_STEPS=1
36: ++ export LR=0.0020992
36: ++ LR=0.0020992
36: ++ export MAX_SAMPLES_TERMINATION=4500000
36: ++ MAX_SAMPLES_TERMINATION=4500000
36: ++ export MAX_STEPS=1059
36: ++ MAX_STEPS=1059
36: ++ export OPT_LAMB_BETA_1=0.60466
36: ++ OPT_LAMB_BETA_1=0.60466
36: ++ export OPT_LAMB_BETA_2=0.85437
36: ++ OPT_LAMB_BETA_2=0.85437
36: ++ export START_WARMUP_STEP=0
36: ++ START_WARMUP_STEP=0
36: ++ export WARMUP_PROPORTION=0.0
36: ++ WARMUP_PROPORTION=0.0
36: ++ export WEIGHT_DECAY_RATE=0.1
36: ++ WEIGHT_DECAY_RATE=0.1
36: ++ export INIT_LOSS_SCALE=4096.0
36: ++ INIT_LOSS_SCALE=4096.0
36: ++ export SBATCH_NETWORK=sharp
36: ++ SBATCH_NETWORK=sharp
36: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
36: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
36: ++ export PHASE=2
36: ++ PHASE=2
36: ++ export EVAL_ITER_START_SAMPLES=175000
36: ++ EVAL_ITER_START_SAMPLES=175000
36: ++ export EVAL_ITER_SAMPLES=175000
36: ++ EVAL_ITER_SAMPLES=175000
36: ++ export DGXNNODES=16
36: ++ DGXNNODES=16
14: +++ sed 's/^config_//'
14: +++ sed 's/\.sh$//'
 7: ++ cut -d - -f1
14: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 7: ++ cut -d - -f2 -
18: ++ cut -d - -f1
 7: ++ tr -d '['
18: ++ cut -d - -f2 -
36: +++ sed 's/^config_//'
 7: ++ echo 'node[022-023,027-040]'
18: ++ tr -d '['
36: +++ sed 's/\.sh$//'
36: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
18: ++ echo 'node[022-023,027-040]'
21: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
21: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
21: ++ export WALLTIME_MINUTES=15
21: ++ WALLTIME_MINUTES=15
21: ++ export WALLTIME=20
21: ++ WALLTIME=20
21: ++ export DGXNGPU=4
21: ++ DGXNGPU=4
21: ++ export DGXSOCKETCORES=64
21: ++ DGXSOCKETCORES=64
21: ++ export DGXNSOCKET=2
21: ++ DGXNSOCKET=2
21: ++ export DGXHT=1
21: ++ DGXHT=1
21: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
21: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
21: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
21: ++ export MLPERF_SUBMISSION_ORG=Dell
21: ++ MLPERF_SUBMISSION_ORG=Dell
21: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
21: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
21: ++ export OMP_NUM_THREADS=8
21: ++ OMP_NUM_THREADS=8
21: + ulimit -Sn 100000
21: + '[' '' = 1 ']'
21: + : 48
21: + : 1
21: + : 0.0020992
21: + : 1059
49: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
21: + : 2
21: + : 1
21: + : ''
21: + : ''\'''\'''
21: + : 2250
21: + : 2508
21: + : 5
21: + : 4
21: + : ''
21: + : 0
21: + : 175000
21: + : 175000
21: + : 4500000
21: + : 0.60466
21: + : 0.85437
21: + : 0
21: + : 0.720
21: + : 0
49: ++ export BATCHSIZE=48
21: + : 0.0
21: + : 0.0
21: + : 0.1
21: + : 0
21: + : 0
21: + : 0
21: + : 0
21: + : 0
21: + : 0
21: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
21: Run vars: id 2508 gpus 4 mparams ''
49: ++ BATCHSIZE=48
49: ++ export GRADIENT_STEPS=1
49: ++ GRADIENT_STEPS=1
49: ++ export LR=0.0020992
49: ++ LR=0.0020992
49: ++ export MAX_SAMPLES_TERMINATION=4500000
49: ++ MAX_SAMPLES_TERMINATION=4500000
49: ++ export MAX_STEPS=1059
49: ++ MAX_STEPS=1059
49: ++ export OPT_LAMB_BETA_1=0.60466
49: ++ OPT_LAMB_BETA_1=0.60466
49: ++ export OPT_LAMB_BETA_2=0.85437
49: ++ OPT_LAMB_BETA_2=0.85437
49: ++ export START_WARMUP_STEP=0
49: ++ START_WARMUP_STEP=0
49: ++ export WARMUP_PROPORTION=0.0
49: ++ WARMUP_PROPORTION=0.0
49: ++ export WEIGHT_DECAY_RATE=0.1
49: ++ WEIGHT_DECAY_RATE=0.1
49: ++ export INIT_LOSS_SCALE=4096.0
49: ++ INIT_LOSS_SCALE=4096.0
49: ++ export SBATCH_NETWORK=sharp
49: ++ SBATCH_NETWORK=sharp
49: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
49: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
49: ++ export PHASE=2
49: ++ PHASE=2
49: ++ export EVAL_ITER_START_SAMPLES=175000
49: ++ EVAL_ITER_START_SAMPLES=175000
49: ++ export EVAL_ITER_SAMPLES=175000
49: ++ EVAL_ITER_SAMPLES=175000
49: ++ export DGXNNODES=16
49: ++ DGXNNODES=16
21: ++ date +%s
49: +++ sed 's/^config_//'
49: +++ sed 's/\.sh$//'
14: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
49: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
36: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 7: + export MASTER_ADDR=node022
 7: + MASTER_ADDR=node022
 7: MASTER_ADDR=node022
18: + export MASTER_ADDR=node022
18: + MASTER_ADDR=node022
 7: + echo MASTER_ADDR=node022
 7: + export MASTER_PORT=19002
 7: + MASTER_PORT=19002
 7: HOSTNAME=node022
 7: + echo HOSTNAME=node022
 7: + declare -a CMD
 7: + [[ -n 3 ]]
 7: + [[ 64 -gt 16 ]]
 7: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
18: MASTER_ADDR=node022
18: + echo MASTER_ADDR=node022
18: + export MASTER_PORT=19002
18: + MASTER_PORT=19002
18: HOSTNAME=node022
18: + echo HOSTNAME=node022
18: + declare -a CMD
18: + [[ -n 2 ]]
 7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
18: + [[ 64 -gt 16 ]]
18: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
46: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 7: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 7: + '[' -n 3 ']'
 7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 7: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
 7: + [[ 0 != 1 ]]
 7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 7: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 7: + [[ '' -ge 1 ]]
18: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
18: =0     --bert_config_path=/workspace/phase1/bert_config.json '
18: + '[' -n 2 ']'
18: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
46: ++ export BATCHSIZE=48
46: ++ BATCHSIZE=48
 7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
18: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
 7: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
18: + [[ 0 != 1 ]]
 7: + [[ 0 != 0 ]]
 7: + '[' '' = apiLog.sh ']'
 7: + '[' '' = 1 ']'
18: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
18: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
18: + [[ '' -ge 1 ]]
18: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
46: ++ export GRADIENT_STEPS=1
46: ++ GRADIENT_STEPS=1
 7: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
18: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
46: ++ export LR=0.0020992
46: ++ LR=0.0020992
 7:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=6519'
18: + [[ 0 != 0 ]]
46: ++ export MAX_SAMPLES_TERMINATION=4500000
18: + '[' '' = apiLog.sh ']'
46: ++ MAX_SAMPLES_TERMINATION=4500000
18: + '[' '' = 1 ']'
46: ++ export MAX_STEPS=1059
46: ++ MAX_STEPS=1059
18: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
46: ++ export OPT_LAMB_BETA_1=0.60466
18:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=5332'
46: ++ OPT_LAMB_BETA_1=0.60466
46: ++ export OPT_LAMB_BETA_2=0.85437
46: ++ OPT_LAMB_BETA_2=0.85437
46: ++ export START_WARMUP_STEP=0
46: ++ START_WARMUP_STEP=0
46: ++ export WARMUP_PROPORTION=0.0
46: ++ WARMUP_PROPORTION=0.0
46: ++ export WEIGHT_DECAY_RATE=0.1
46: ++ WEIGHT_DECAY_RATE=0.1
46: ++ export INIT_LOSS_SCALE=4096.0
46: ++ INIT_LOSS_SCALE=4096.0
 7: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
46: ++ export SBATCH_NETWORK=sharp
 7: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=6519
46: ++ SBATCH_NETWORK=sharp
46: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
46: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
46: ++ export PHASE=2
46: ++ PHASE=2
46: ++ export EVAL_ITER_START_SAMPLES=175000
46: ++ EVAL_ITER_START_SAMPLES=175000
46: ++ export EVAL_ITER_SAMPLES=175000
18: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
46: ++ EVAL_ITER_SAMPLES=175000
46: ++ export DGXNNODES=16
46: ++ DGXNNODES=16
18: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=5332
21: + START=1665667532
52: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
21: ++ date '+%Y-%m-%d %r'
46: +++ sed 's/^config_//'
52: ++ export BATCHSIZE=48
52: ++ BATCHSIZE=48
46: +++ sed 's/\.sh$//'
52: ++ export GRADIENT_STEPS=1
52: ++ GRADIENT_STEPS=1
52: ++ export LR=0.0020992
52: ++ LR=0.0020992
52: ++ export MAX_SAMPLES_TERMINATION=4500000
52: ++ MAX_SAMPLES_TERMINATION=4500000
52: ++ export MAX_STEPS=1059
52: ++ MAX_STEPS=1059
52: ++ export OPT_LAMB_BETA_1=0.60466
52: ++ OPT_LAMB_BETA_1=0.60466
52: ++ export OPT_LAMB_BETA_2=0.85437
52: ++ OPT_LAMB_BETA_2=0.85437
52: ++ export START_WARMUP_STEP=0
52: ++ START_WARMUP_STEP=0
52: ++ export WARMUP_PROPORTION=0.0
52: ++ WARMUP_PROPORTION=0.0
52: ++ export WEIGHT_DECAY_RATE=0.1
52: ++ WEIGHT_DECAY_RATE=0.1
46: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
49: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
52: ++ export INIT_LOSS_SCALE=4096.0
52: ++ INIT_LOSS_SCALE=4096.0
52: ++ export SBATCH_NETWORK=sharp
52: ++ SBATCH_NETWORK=sharp
52: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
52: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
52: ++ export PHASE=2
52: ++ PHASE=2
52: ++ export EVAL_ITER_START_SAMPLES=175000
52: ++ EVAL_ITER_START_SAMPLES=175000
52: ++ export EVAL_ITER_SAMPLES=175000
52: ++ EVAL_ITER_SAMPLES=175000
52: ++ export DGXNNODES=16
52: ++ DGXNNODES=16
21: + START_FMT='2022-10-13 08:25:32 AM'
21: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
21: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
21: + '[' '!' -z '' ']'
21: + '[' 0 -gt 0 ']'
21: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
14: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
14: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
21: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
21: + PHASES=("$PHASE1" "$PHASE2")
21: + export RANK=21
21: + RANK=21
21: + export WORLD_SIZE=64
21: + WORLD_SIZE=64
21: WORLD_SIZE=64
21: + echo WORLD_SIZE=64
14: ++ export WALLTIME_MINUTES=15
14: ++ WALLTIME_MINUTES=15
14: ++ export WALLTIME=20
14: ++ WALLTIME=20
14: ++ export DGXNGPU=4
14: ++ DGXNGPU=4
14: ++ export DGXSOCKETCORES=64
14: ++ DGXSOCKETCORES=64
14: ++ export DGXNSOCKET=2
14: ++ DGXNSOCKET=2
14: ++ export DGXHT=1
14: ++ DGXHT=1
14: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
14: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
14: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
14: ++ export MLPERF_SUBMISSION_ORG=Dell
14: ++ MLPERF_SUBMISSION_ORG=Dell
14: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
14: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
14: ++ export OMP_NUM_THREADS=8
14: ++ OMP_NUM_THREADS=8
14: + ulimit -Sn 100000
14: + '[' '' = 1 ']'
14: + : 48
14: + : 1
52: +++ sed 's/^config_//'
14: + : 0.0020992
36: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
36: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
14: + : 1059
14: + : 2
14: + : 2
14: + : ''
14: + : ''\'''\'''
14: + : 27654
14: + : 2508
14: + : 3
14: + : 4
14: + : ''
14: + : 0
14: + : 175000
14: + : 175000
52: +++ sed 's/\.sh$//'
14: + : 4500000
14: + : 0.60466
14: + : 0.85437
36: ++ export WALLTIME_MINUTES=15
36: ++ WALLTIME_MINUTES=15
14: + : 0
36: ++ export WALLTIME=20
36: ++ WALLTIME=20
14: + : 0.720
36: ++ export DGXNGPU=4
36: ++ DGXNGPU=4
14: + : 0
36: ++ export DGXSOCKETCORES=64
36: ++ DGXSOCKETCORES=64
14: + : 0.0
36: ++ export DGXNSOCKET=2
14: + : 0.0
36: ++ DGXNSOCKET=2
14: + : 0.1
36: ++ export DGXHT=1
14: Run vars: id 2508 gpus 4 mparams ''
14: + : 0
36: ++ DGXHT=1
14: + : 0
36: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
36: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
36: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
14: + : 0
14: + : 0
14: + : 0
14: + : 0
14: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
52: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
36: ++ export MLPERF_SUBMISSION_ORG=Dell
36: ++ MLPERF_SUBMISSION_ORG=Dell
21: ++ cut -d - -f1
36: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
36: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
36: ++ export OMP_NUM_THREADS=8
36: ++ OMP_NUM_THREADS=8
36: + ulimit -Sn 100000
36: + '[' '' = 1 ']'
36: + : 48
36: + : 1
36: + : 0.0020992
21: ++ cut -d - -f2 -
36: + : 1059
21: ++ echo 'node[022-023,027-040]'
21: ++ tr -d '['
36: + : 2
36: + : 0
36: + : ''
36: + : ''\'''\'''
36: + : 9949
36: + : 2508
36: + : 9
36: + : 4
36: + : ''
36: + : 0
36: + : 175000
36: + : 175000
36: + : 4500000
36: + : 0.60466
36: + : 0.85437
36: + : 0
36: + : 0.720
36: + : 0
36: + : 0.0
36: + : 0.0
36: + : 0.1
36: + : 0
36: + : 0
36: + : 0
14: ++ date +%s
36: + : 0
36: + : 0
36: + : 0
36: Run vars: id 2508 gpus 4 mparams ''
36: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
36: ++ date +%s
46: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
49: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
49: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
49: ++ export WALLTIME_MINUTES=15
49: ++ WALLTIME_MINUTES=15
49: ++ export WALLTIME=20
49: ++ WALLTIME=20
49: ++ export DGXNGPU=4
49: ++ DGXNGPU=4
49: ++ export DGXSOCKETCORES=64
49: ++ DGXSOCKETCORES=64
49: ++ export DGXNSOCKET=2
49: ++ DGXNSOCKET=2
49: ++ export DGXHT=1
49: ++ DGXHT=1
49: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
49: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
49: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
49: ++ export MLPERF_SUBMISSION_ORG=Dell
49: ++ MLPERF_SUBMISSION_ORG=Dell
49: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
49: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
49: ++ export OMP_NUM_THREADS=8
49: ++ OMP_NUM_THREADS=8
49: + ulimit -Sn 100000
49: + '[' '' = 1 ']'
49: + : 48
49: + : 1
49: + : 0.0020992
49: + : 1059
49: + : 2
49: + : 1
49: + : ''
49: + : ''\'''\'''
49: + : 7691
49: + : 2508
49: + : 12
49: + : 4
49: + : ''
49: + : 0
49: + : 175000
49: + : 175000
49: + : 4500000
49: + : 0.60466
49: + : 0.85437
49: + : 0
49: + : 0.720
49: + : 0
49: + : 0.0
49: + : 0.0
49: + : 0.1
49: + : 0
49: + : 0
49: + : 0
49: + : 0
49: + : 0
49: + : 0
49: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
49: Run vars: id 2508 gpus 4 mparams ''
14: + START=1665667532
49: ++ date +%s
52: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
14: ++ date '+%Y-%m-%d %r'
36: + START=1665667532
21: + export MASTER_ADDR=node022
21: + MASTER_ADDR=node022
21: MASTER_ADDR=node022
36: ++ date '+%Y-%m-%d %r'
21: + echo MASTER_ADDR=node022
21: + export MASTER_PORT=19002
21: + MASTER_PORT=19002
21: HOSTNAME=node022
21: + echo HOSTNAME=node022
21: + declare -a CMD
21: + [[ -n 1 ]]
21: + [[ 64 -gt 16 ]]
21: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
21: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
21: =0     --bert_config_path=/workspace/phase1/bert_config.json '
21: + '[' -n 1 ']'
21: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
21: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
21: + [[ 0 != 1 ]]
21: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
21: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
21: + [[ '' -ge 1 ]]
21: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
21: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
21: + [[ 0 != 0 ]]
21: + '[' '' = apiLog.sh ']'
21: + '[' '' = 1 ']'
21: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
21:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=2250'
36: + START_FMT='2022-10-13 08:25:32 AM'
21: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
21: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=2250
36: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
36: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
36: + '[' '!' -z '' ']'
36: + '[' 0 -gt 0 ']'
36: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
36: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
36: + PHASES=("$PHASE1" "$PHASE2")
36: + export RANK=36
36: + RANK=36
36: + export WORLD_SIZE=64
36: + WORLD_SIZE=64
36: WORLD_SIZE=64
36: + echo WORLD_SIZE=64
14: + START_FMT='2022-10-13 08:25:32 AM'
46: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
46: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
14: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
14: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
14: + '[' '!' -z '' ']'
14: + '[' 0 -gt 0 ']'
46: ++ export WALLTIME_MINUTES=15
46: ++ WALLTIME_MINUTES=15
46: ++ export WALLTIME=20
46: ++ WALLTIME=20
14: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
46: ++ export DGXNGPU=4
46: ++ DGXNGPU=4
14: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
46: ++ export DGXSOCKETCORES=64
46: ++ DGXSOCKETCORES=64
46: ++ export DGXNSOCKET=2
46: ++ DGXNSOCKET=2
46: ++ export DGXHT=1
46: ++ DGXHT=1
46: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
46: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
46: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
14: + PHASES=("$PHASE1" "$PHASE2")
46: ++ export MLPERF_SUBMISSION_ORG=Dell
46: ++ MLPERF_SUBMISSION_ORG=Dell
14: + export RANK=14
14: + RANK=14
14: WORLD_SIZE=64
46: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
14: + export WORLD_SIZE=64
14: + WORLD_SIZE=64
46: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
46: ++ export OMP_NUM_THREADS=8
46: ++ OMP_NUM_THREADS=8
14: + echo WORLD_SIZE=64
46: + ulimit -Sn 100000
46: + '[' '' = 1 ']'
46: + : 48
46: + : 1
46: + : 0.0020992
46: + : 1059
36: ++ cut -d - -f1
36: ++ cut -d - -f2 -
46: + : 2
46: + : 2
46: + : ''
46: + : ''\'''\'''
46: + : 13123
46: + : 2508
46: + : 11
46: + : 4
46: + : ''
46: + : 0
46: + : 175000
46: + : 175000
36: ++ tr -d '['
36: ++ echo 'node[022-023,027-040]'
46: + : 4500000
46: + : 0.60466
46: + : 0.85437
46: + : 0
46: + : 0.720
46: + : 0
46: + : 0.0
46: + : 0.0
46: + : 0.1
46: + : 0
46: + : 0
46: + : 0
46: + : 0
46: + : 0
46: + : 0
46: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
46: Run vars: id 2508 gpus 4 mparams ''
14: ++ cut -d - -f1
49: + START=1665667532
46: ++ date +%s
14: ++ cut -d - -f2 -
14: ++ tr -d '['
14: ++ echo 'node[022-023,027-040]'
49: ++ date '+%Y-%m-%d %r'
52: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
52: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
52: ++ export WALLTIME_MINUTES=15
52: ++ WALLTIME_MINUTES=15
52: ++ export WALLTIME=20
52: ++ WALLTIME=20
52: ++ export DGXNGPU=4
52: ++ DGXNGPU=4
52: ++ export DGXSOCKETCORES=64
52: ++ DGXSOCKETCORES=64
52: ++ export DGXNSOCKET=2
52: ++ DGXNSOCKET=2
52: ++ export DGXHT=1
52: ++ DGXHT=1
52: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
52: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
52: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
52: ++ export MLPERF_SUBMISSION_ORG=Dell
52: ++ MLPERF_SUBMISSION_ORG=Dell
52: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
52: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
52: ++ export OMP_NUM_THREADS=8
52: ++ OMP_NUM_THREADS=8
52: + ulimit -Sn 100000
52: + '[' '' = 1 ']'
52: + : 48
52: + : 1
52: + : 0.0020992
52: + : 1059
52: + : 2
52: + : 0
52: + : ''
52: + : ''\'''\'''
52: + : 17288
52: + : 2508
52: + : 13
52: + : 4
52: + : ''
52: + : 0
52: + : 175000
52: + : 175000
52: + : 4500000
52: + : 0.60466
52: + : 0.85437
52: + : 0
52: + : 0.720
52: + : 0
52: + : 0.0
52: + : 0.0
52: + : 0.1
52: + : 0
52: + : 0
52: + : 0
52: + : 0
52: + : 0
49: + START_FMT='2022-10-13 08:25:32 AM'
52: + : 0
52: Run vars: id 2508 gpus 4 mparams ''
52: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
49: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
49: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
49: + '[' '!' -z '' ']'
49: + '[' 0 -gt 0 ']'
49: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
49: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
49: + PHASES=("$PHASE1" "$PHASE2")
52: ++ date +%s
49: + export RANK=49
49: + RANK=49
49: + export WORLD_SIZE=64
49: + WORLD_SIZE=64
49: WORLD_SIZE=64
49: + echo WORLD_SIZE=64
49: ++ cut -d - -f1
49: ++ cut -d - -f2 -
49: ++ tr -d '['
49: ++ echo 'node[022-023,027-040]'
22: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
36: + export MASTER_ADDR=node022
36: + MASTER_ADDR=node022
36: MASTER_ADDR=node022
22: ++ export BATCHSIZE=48
22: ++ BATCHSIZE=48
36: + echo MASTER_ADDR=node022
36: + export MASTER_PORT=19002
36: + MASTER_PORT=19002
36: + echo HOSTNAME=node022
36: HOSTNAME=node022
36: + declare -a CMD
36: + [[ -n 0 ]]
36: + [[ 64 -gt 16 ]]
36: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
22: ++ export GRADIENT_STEPS=1
22: ++ GRADIENT_STEPS=1
46: + START=1665667532
22: ++ export LR=0.0020992
22: ++ LR=0.0020992
22: ++ export MAX_SAMPLES_TERMINATION=4500000
22: ++ MAX_SAMPLES_TERMINATION=4500000
22: ++ export MAX_STEPS=1059
22: ++ MAX_STEPS=1059
22: ++ export OPT_LAMB_BETA_1=0.60466
22: ++ OPT_LAMB_BETA_1=0.60466
22: ++ export OPT_LAMB_BETA_2=0.85437
22: ++ OPT_LAMB_BETA_2=0.85437
22: ++ export START_WARMUP_STEP=0
22: ++ START_WARMUP_STEP=0
22: ++ export WARMUP_PROPORTION=0.0
22: ++ WARMUP_PROPORTION=0.0
36: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
22: ++ export WEIGHT_DECAY_RATE=0.1
22: ++ WEIGHT_DECAY_RATE=0.1
22: ++ export INIT_LOSS_SCALE=4096.0
22: ++ INIT_LOSS_SCALE=4096.0
22: ++ export SBATCH_NETWORK=sharp
22: ++ SBATCH_NETWORK=sharp
22: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
22: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
22: ++ export PHASE=2
22: ++ PHASE=2
22: ++ export EVAL_ITER_START_SAMPLES=175000
22: ++ EVAL_ITER_START_SAMPLES=175000
22: ++ export EVAL_ITER_SAMPLES=175000
22: ++ EVAL_ITER_SAMPLES=175000
22: ++ export DGXNNODES=16
22: ++ DGXNNODES=16
36: =0     --bert_config_path=/workspace/phase1/bert_config.json '
36: + '[' -n 0 ']'
36: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
36: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
36: + [[ 0 != 1 ]]
36: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
36: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
36: + [[ '' -ge 1 ]]
36: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
14: + export MASTER_ADDR=node022
14: + MASTER_ADDR=node022
46: ++ date '+%Y-%m-%d %r'
36: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
36: + [[ 0 != 0 ]]
36: + '[' '' = apiLog.sh ']'
36: + '[' '' = 1 ']'
36: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
36:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=9949'
14: MASTER_ADDR=node022
14: + echo MASTER_ADDR=node022
14: + export MASTER_PORT=19002
14: + MASTER_PORT=19002
14: HOSTNAME=node022
14: + echo HOSTNAME=node022
14: + declare -a CMD
36: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
36: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=9949
14: + [[ -n 2 ]]
14: + [[ 64 -gt 16 ]]
14: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
14: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
22: +++ sed 's/^config_//'
22: +++ sed 's/\.sh$//'
22: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
14: =0     --bert_config_path=/workspace/phase1/bert_config.json '
14: + '[' -n 2 ']'
14: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
14: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
14: + [[ 0 != 1 ]]
14: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
14: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
14: + [[ '' -ge 1 ]]
14: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
14: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
14: + [[ 0 != 0 ]]
14: + '[' '' = apiLog.sh ']'
14: + '[' '' = 1 ']'
14: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
14:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=27654'
14: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
14: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=27654
46: + START_FMT='2022-10-13 08:25:32 AM'
46: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
46: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
46: + '[' '!' -z '' ']'
46: + '[' 0 -gt 0 ']'
46: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
52: + START=1665667532
46: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
46: + PHASES=("$PHASE1" "$PHASE2")
46: + export RANK=46
46: + RANK=46
46: + export WORLD_SIZE=64
46: + WORLD_SIZE=64
46: WORLD_SIZE=64
46: + echo WORLD_SIZE=64
52: ++ date '+%Y-%m-%d %r'
49: + export MASTER_ADDR=node022
49: + MASTER_ADDR=node022
46: ++ cut -d - -f1
49: MASTER_ADDR=node022
49: + echo MASTER_ADDR=node022
49: + export MASTER_PORT=19002
49: + MASTER_PORT=19002
49: + echo HOSTNAME=node022
49: HOSTNAME=node022
49: + declare -a CMD
49: + [[ -n 1 ]]
49: + [[ 64 -gt 16 ]]
49: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
46: ++ cut -d - -f2 -
46: ++ echo 'node[022-023,027-040]'
46: ++ tr -d '['
49: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
49: =0     --bert_config_path=/workspace/phase1/bert_config.json '
49: + '[' -n 1 ']'
49: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
49: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
49: + [[ 0 != 1 ]]
49: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
49: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
49: + [[ '' -ge 1 ]]
49: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
49: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
49: + [[ 0 != 0 ]]
49: + '[' '' = apiLog.sh ']'
49: + '[' '' = 1 ']'
52: + START_FMT='2022-10-13 08:25:32 AM'
49: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
49:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=7691'
52: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
52: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
52: + '[' '!' -z '' ']'
49: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
52: + '[' 0 -gt 0 ']'
49: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=7691
52: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
52: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
52: + PHASES=("$PHASE1" "$PHASE2")
52: + export RANK=52
52: + RANK=52
52: + export WORLD_SIZE=64
52: + WORLD_SIZE=64
52: + echo WORLD_SIZE=64
52: WORLD_SIZE=64
22: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
52: ++ cut -d - -f1
52: ++ echo 'node[022-023,027-040]'
52: ++ cut -d - -f2 -
52: ++ tr -d '['
46: + export MASTER_ADDR=node022
46: + MASTER_ADDR=node022
46: MASTER_ADDR=node022
46: + echo MASTER_ADDR=node022
46: + export MASTER_PORT=19002
46: + MASTER_PORT=19002
46: + echo HOSTNAME=node022
46: HOSTNAME=node022
46: + declare -a CMD
46: + [[ -n 2 ]]
46: + [[ 64 -gt 16 ]]
46: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
40: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
46: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
40: ++ export BATCHSIZE=48
40: ++ BATCHSIZE=48
46: =0     --bert_config_path=/workspace/phase1/bert_config.json '
46: + '[' -n 2 ']'
46: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
46: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
46: + [[ 0 != 1 ]]
46: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
46: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
46: + [[ '' -ge 1 ]]
46: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
40: ++ export GRADIENT_STEPS=1
40: ++ GRADIENT_STEPS=1
40: ++ export LR=0.0020992
40: ++ LR=0.0020992
40: ++ export MAX_SAMPLES_TERMINATION=4500000
40: ++ MAX_SAMPLES_TERMINATION=4500000
40: ++ export MAX_STEPS=1059
40: ++ MAX_STEPS=1059
40: ++ export OPT_LAMB_BETA_1=0.60466
40: ++ OPT_LAMB_BETA_1=0.60466
46: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
40: ++ export OPT_LAMB_BETA_2=0.85437
40: ++ OPT_LAMB_BETA_2=0.85437
46: + [[ 0 != 0 ]]
40: ++ export START_WARMUP_STEP=0
40: ++ START_WARMUP_STEP=0
46: + '[' '' = apiLog.sh ']'
40: ++ export WARMUP_PROPORTION=0.0
40: ++ WARMUP_PROPORTION=0.0
46: + '[' '' = 1 ']'
40: ++ export WEIGHT_DECAY_RATE=0.1
40: ++ WEIGHT_DECAY_RATE=0.1
46: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
40: ++ export INIT_LOSS_SCALE=4096.0
40: ++ INIT_LOSS_SCALE=4096.0
46:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=13123'
40: ++ export SBATCH_NETWORK=sharp
40: ++ SBATCH_NETWORK=sharp
40: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
40: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
40: ++ export PHASE=2
40: ++ PHASE=2
40: ++ export EVAL_ITER_START_SAMPLES=175000
40: ++ EVAL_ITER_START_SAMPLES=175000
40: ++ export EVAL_ITER_SAMPLES=175000
40: ++ EVAL_ITER_SAMPLES=175000
46: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
40: ++ export DGXNNODES=16
40: ++ DGXNNODES=16
46: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=13123
22: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
22: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
22: ++ export WALLTIME_MINUTES=15
22: ++ WALLTIME_MINUTES=15
22: ++ export WALLTIME=20
22: ++ WALLTIME=20
22: ++ export DGXNGPU=4
22: ++ DGXNGPU=4
22: ++ export DGXSOCKETCORES=64
22: ++ DGXSOCKETCORES=64
22: ++ export DGXNSOCKET=2
22: ++ DGXNSOCKET=2
22: ++ export DGXHT=1
22: ++ DGXHT=1
22: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
22: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
22: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
22: ++ export MLPERF_SUBMISSION_ORG=Dell
22: ++ MLPERF_SUBMISSION_ORG=Dell
22: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
22: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
22: ++ export OMP_NUM_THREADS=8
22: ++ OMP_NUM_THREADS=8
22: + ulimit -Sn 100000
22: + '[' '' = 1 ']'
22: + : 48
22: + : 1
22: + : 0.0020992
22: + : 1059
22: + : 2
22: + : 2
22: + : ''
22: + : ''\'''\'''
40: +++ sed 's/^config_//'
22: + : 10354
22: + : 2508
22: + : 5
22: + : 4
22: + : ''
22: + : 0
22: + : 175000
22: + : 175000
22: + : 4500000
22: + : 0.60466
22: + : 0.85437
22: + : 0
22: + : 0.720
22: + : 0
22: + : 0.0
22: + : 0.0
22: + : 0.1
22: + : 0
22: + : 0
22: + : 0
22: + : 0
22: + : 0
22: + : 0
22: Run vars: id 2508 gpus 4 mparams ''
22: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
40: +++ sed 's/\.sh$//'
40: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
17: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
22: ++ date +%s
17: ++ export BATCHSIZE=48
17: ++ BATCHSIZE=48
17: ++ export GRADIENT_STEPS=1
17: ++ GRADIENT_STEPS=1
17: ++ export LR=0.0020992
17: ++ LR=0.0020992
17: ++ export MAX_SAMPLES_TERMINATION=4500000
17: ++ MAX_SAMPLES_TERMINATION=4500000
17: ++ export MAX_STEPS=1059
17: ++ MAX_STEPS=1059
17: ++ export OPT_LAMB_BETA_1=0.60466
17: ++ OPT_LAMB_BETA_1=0.60466
17: ++ export OPT_LAMB_BETA_2=0.85437
17: ++ OPT_LAMB_BETA_2=0.85437
17: ++ export START_WARMUP_STEP=0
17: ++ START_WARMUP_STEP=0
17: ++ export WARMUP_PROPORTION=0.0
17: ++ WARMUP_PROPORTION=0.0
17: ++ export WEIGHT_DECAY_RATE=0.1
17: ++ WEIGHT_DECAY_RATE=0.1
17: ++ export INIT_LOSS_SCALE=4096.0
17: ++ INIT_LOSS_SCALE=4096.0
17: ++ export SBATCH_NETWORK=sharp
17: ++ SBATCH_NETWORK=sharp
17: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
17: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
17: ++ export PHASE=2
17: ++ PHASE=2
17: ++ export EVAL_ITER_START_SAMPLES=175000
17: ++ EVAL_ITER_START_SAMPLES=175000
17: ++ export EVAL_ITER_SAMPLES=175000
17: ++ EVAL_ITER_SAMPLES=175000
17: ++ export DGXNNODES=16
17: ++ DGXNNODES=16
 5: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 5: ++ export BATCHSIZE=48
 5: ++ BATCHSIZE=48
 5: ++ export GRADIENT_STEPS=1
 5: ++ GRADIENT_STEPS=1
 5: ++ export LR=0.0020992
 5: ++ LR=0.0020992
 5: ++ export MAX_SAMPLES_TERMINATION=4500000
 5: ++ MAX_SAMPLES_TERMINATION=4500000
 5: ++ export MAX_STEPS=1059
 5: ++ MAX_STEPS=1059
 5: ++ export OPT_LAMB_BETA_1=0.60466
 5: ++ OPT_LAMB_BETA_1=0.60466
 5: ++ export OPT_LAMB_BETA_2=0.85437
 5: ++ OPT_LAMB_BETA_2=0.85437
 5: ++ export START_WARMUP_STEP=0
 5: ++ START_WARMUP_STEP=0
 5: ++ export WARMUP_PROPORTION=0.0
 5: ++ WARMUP_PROPORTION=0.0
 5: ++ export WEIGHT_DECAY_RATE=0.1
 5: ++ WEIGHT_DECAY_RATE=0.1
 5: ++ export INIT_LOSS_SCALE=4096.0
 5: ++ INIT_LOSS_SCALE=4096.0
 5: ++ export SBATCH_NETWORK=sharp
 5: ++ SBATCH_NETWORK=sharp
 5: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 5: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 5: ++ export PHASE=2
 5: ++ PHASE=2
 5: ++ export EVAL_ITER_START_SAMPLES=175000
 5: ++ EVAL_ITER_START_SAMPLES=175000
 5: ++ export EVAL_ITER_SAMPLES=175000
 5: ++ EVAL_ITER_SAMPLES=175000
 5: ++ export DGXNNODES=16
 5: ++ DGXNNODES=16
17: +++ sed 's/^config_//'
17: +++ sed 's/\.sh$//'
52: + export MASTER_ADDR=node022
52: + MASTER_ADDR=node022
17: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
52: MASTER_ADDR=node022
52: + echo MASTER_ADDR=node022
52: + export MASTER_PORT=19002
52: + MASTER_PORT=19002
52: HOSTNAME=node022
52: + echo HOSTNAME=node022
52: + declare -a CMD
52: + [[ -n 0 ]]
52: + [[ 64 -gt 16 ]]
52: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
52: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 5: +++ sed 's/^config_//'
52: =0     --bert_config_path=/workspace/phase1/bert_config.json '
52: + '[' -n 0 ']'
52: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
52: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
52: + [[ 0 != 1 ]]
52: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 5: +++ sed 's/\.sh$//'
52: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
52: + [[ '' -ge 1 ]]
52: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
52: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
52: + [[ 0 != 0 ]]
 5: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
52: + '[' '' = apiLog.sh ']'
52: + '[' '' = 1 ']'
52: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
52:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=17288'
52: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
52: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=17288
22: + START=1665667532
40: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
22: ++ date '+%Y-%m-%d %r'
22: + START_FMT='2022-10-13 08:25:32 AM'
17: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
22: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
22: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
22: + '[' '!' -z '' ']'
22: + '[' 0 -gt 0 ']'
22: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
22: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
22: + PHASES=("$PHASE1" "$PHASE2")
22: + export RANK=22
22: + RANK=22
22: + export WORLD_SIZE=64
22: + WORLD_SIZE=64
22: WORLD_SIZE=64
22: + echo WORLD_SIZE=64
 5: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
22: ++ cut -d - -f1
22: ++ cut -d - -f2 -
22: ++ tr -d '['
22: ++ echo 'node[022-023,027-040]'
47: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
47: ++ export BATCHSIZE=48
47: ++ BATCHSIZE=48
47: ++ export GRADIENT_STEPS=1
47: ++ GRADIENT_STEPS=1
47: ++ export LR=0.0020992
47: ++ LR=0.0020992
47: ++ export MAX_SAMPLES_TERMINATION=4500000
47: ++ MAX_SAMPLES_TERMINATION=4500000
47: ++ export MAX_STEPS=1059
47: ++ MAX_STEPS=1059
47: ++ export OPT_LAMB_BETA_1=0.60466
47: ++ OPT_LAMB_BETA_1=0.60466
47: ++ export OPT_LAMB_BETA_2=0.85437
47: ++ OPT_LAMB_BETA_2=0.85437
47: ++ export START_WARMUP_STEP=0
47: ++ START_WARMUP_STEP=0
47: ++ export WARMUP_PROPORTION=0.0
47: ++ WARMUP_PROPORTION=0.0
47: ++ export WEIGHT_DECAY_RATE=0.1
47: ++ WEIGHT_DECAY_RATE=0.1
47: ++ export INIT_LOSS_SCALE=4096.0
47: ++ INIT_LOSS_SCALE=4096.0
47: ++ export SBATCH_NETWORK=sharp
47: ++ SBATCH_NETWORK=sharp
47: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
47: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
40: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
40: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
47: ++ export PHASE=2
47: ++ PHASE=2
47: ++ export EVAL_ITER_START_SAMPLES=175000
47: ++ EVAL_ITER_START_SAMPLES=175000
47: ++ export EVAL_ITER_SAMPLES=175000
47: ++ EVAL_ITER_SAMPLES=175000
47: ++ export DGXNNODES=16
47: ++ DGXNNODES=16
40: ++ export WALLTIME_MINUTES=15
40: ++ WALLTIME_MINUTES=15
40: ++ export WALLTIME=20
40: ++ WALLTIME=20
40: ++ export DGXNGPU=4
40: ++ DGXNGPU=4
40: ++ export DGXSOCKETCORES=64
40: ++ DGXSOCKETCORES=64
40: ++ export DGXNSOCKET=2
40: ++ DGXNSOCKET=2
40: ++ export DGXHT=1
40: ++ DGXHT=1
40: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
40: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
40: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
40: ++ export MLPERF_SUBMISSION_ORG=Dell
40: ++ MLPERF_SUBMISSION_ORG=Dell
40: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
40: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
40: ++ export OMP_NUM_THREADS=8
40: ++ OMP_NUM_THREADS=8
40: + ulimit -Sn 100000
40: + '[' '' = 1 ']'
40: + : 48
40: + : 1
40: + : 0.0020992
40: + : 1059
40: + : 2
40: + : 0
40: + : ''
40: + : ''\'''\'''
40: + : 16855
40: + : 2508
40: + : 10
40: + : 4
40: + : ''
40: + : 0
40: + : 175000
40: + : 175000
40: + : 4500000
40: + : 0.60466
40: + : 0.85437
40: + : 0
40: + : 0.720
40: + : 0
40: + : 0.0
40: + : 0.0
40: + : 0.1
40: + : 0
40: + : 0
40: + : 0
40: + : 0
40: + : 0
40: + : 0
40: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
40: Run vars: id 2508 gpus 4 mparams ''
47: +++ sed 's/^config_//'
47: +++ sed 's/\.sh$//'
47: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
40: ++ date +%s
17: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
17: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
17: ++ export WALLTIME_MINUTES=15
17: ++ WALLTIME_MINUTES=15
17: ++ export WALLTIME=20
17: ++ WALLTIME=20
17: ++ export DGXNGPU=4
17: ++ DGXNGPU=4
17: ++ export DGXSOCKETCORES=64
17: ++ DGXSOCKETCORES=64
17: ++ export DGXNSOCKET=2
17: ++ DGXNSOCKET=2
17: ++ export DGXHT=1
17: ++ DGXHT=1
17: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
17: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
17: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
17: ++ export MLPERF_SUBMISSION_ORG=Dell
17: ++ MLPERF_SUBMISSION_ORG=Dell
17: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
17: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
17: ++ export OMP_NUM_THREADS=8
17: ++ OMP_NUM_THREADS=8
17: + ulimit -Sn 100000
17: + '[' '' = 1 ']'
17: + : 48
17: + : 1
17: + : 0.0020992
17: + : 1059
17: + : 2
17: + : 1
17: + : ''
17: + : ''\'''\'''
17: + : 29761
17: + : 2508
17: + : 4
17: + : 4
17: + : ''
17: + : 0
17: + : 175000
17: + : 175000
17: + : 4500000
22: + export MASTER_ADDR=node022
22: + MASTER_ADDR=node022
17: + : 0.60466
17: + : 0.85437
17: + : 0
17: + : 0.720
17: + : 0
17: + : 0.0
17: + : 0.0
17: + : 0.1
17: + : 0
17: + : 0
17: + : 0
22: MASTER_ADDR=node022
17: + : 0
17: + : 0
22: + echo MASTER_ADDR=node022
22: HOSTNAME=node022
17: + : 0
17: Run vars: id 2508 gpus 4 mparams ''
22: + export MASTER_PORT=19002
22: + MASTER_PORT=19002
17: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
22: + echo HOSTNAME=node022
22: + declare -a CMD
22: + [[ -n 2 ]]
22: + [[ 64 -gt 16 ]]
22: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
22: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
17: ++ date +%s
22: =0     --bert_config_path=/workspace/phase1/bert_config.json '
22: + '[' -n 2 ']'
 5: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 5: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
22: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
22: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
22: + [[ 0 != 1 ]]
22: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
22: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
22: + [[ '' -ge 1 ]]
 5: ++ export WALLTIME_MINUTES=15
 5: ++ WALLTIME_MINUTES=15
22: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 5: ++ export WALLTIME=20
 5: ++ WALLTIME=20
22: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 5: ++ export DGXNGPU=4
 5: ++ DGXNGPU=4
22: + [[ 0 != 0 ]]
 5: ++ export DGXSOCKETCORES=64
 5: ++ DGXSOCKETCORES=64
22: + '[' '' = apiLog.sh ']'
 5: ++ export DGXNSOCKET=2
 5: ++ DGXNSOCKET=2
22: + '[' '' = 1 ']'
 5: ++ export DGXHT=1
22: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
 5: ++ DGXHT=1
22:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=10354'
 5: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 5: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 5: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 5: ++ export MLPERF_SUBMISSION_ORG=Dell
 5: ++ MLPERF_SUBMISSION_ORG=Dell
 5: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 5: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 5: ++ export OMP_NUM_THREADS=8
 5: ++ OMP_NUM_THREADS=8
 5: + ulimit -Sn 100000
 5: + '[' '' = 1 ']'
 5: + : 48
22: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 5: + : 1
 5: + : 0.0020992
 5: + : 1059
 5: + : 2
 5: + : 1
 5: + : ''
 5: + : ''\'''\'''
 5: + : 22881
22: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=10354
 5: + : 2508
 5: + : 1
 5: + : 4
 5: + : ''
 5: + : 0
 5: + : 175000
 5: + : 175000
 5: + : 4500000
 5: + : 0.60466
 5: + : 0.85437
 5: + : 0
 5: + : 0.720
 5: + : 0
 5: + : 0.0
 5: + : 0.0
 5: + : 0.1
 5: + : 0
 5: + : 0
 5: + : 0
 5: + : 0
 5: + : 0
 5: + : 0
 5: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
 5: Run vars: id 2508 gpus 4 mparams ''
 5: ++ date +%s
47: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
40: + START=1665667532
40: ++ date '+%Y-%m-%d %r'
17: + START=1665667532
17: ++ date '+%Y-%m-%d %r'
40: + START_FMT='2022-10-13 08:25:32 AM'
40: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
40: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
40: + '[' '!' -z '' ']'
40: + '[' 0 -gt 0 ']'
40: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
40: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
40: + PHASES=("$PHASE1" "$PHASE2")
40: + export RANK=40
40: + RANK=40
40: + export WORLD_SIZE=64
40: + WORLD_SIZE=64
40: + echo WORLD_SIZE=64
40: WORLD_SIZE=64
17: + START_FMT='2022-10-13 08:25:32 AM'
17: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
17: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
17: + '[' '!' -z '' ']'
17: + '[' 0 -gt 0 ']'
17: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
17: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
17: + PHASES=("$PHASE1" "$PHASE2")
17: + export RANK=17
17: + RANK=17
17: + export WORLD_SIZE=64
17: + WORLD_SIZE=64
17: WORLD_SIZE=64
17: + echo WORLD_SIZE=64
40: ++ cut -d - -f1
40: ++ cut -d - -f2 -
 5: + START=1665667532
40: ++ echo 'node[022-023,027-040]'
38: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
40: ++ tr -d '['
17: ++ cut -d - -f1
38: ++ export BATCHSIZE=48
38: ++ BATCHSIZE=48
47: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
47: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 5: ++ date '+%Y-%m-%d %r'
17: ++ cut -d - -f2 -
47: ++ export WALLTIME_MINUTES=15
47: ++ WALLTIME_MINUTES=15
38: ++ export GRADIENT_STEPS=1
38: ++ GRADIENT_STEPS=1
47: ++ export WALLTIME=20
47: ++ WALLTIME=20
38: ++ export LR=0.0020992
38: ++ LR=0.0020992
47: ++ export DGXNGPU=4
47: ++ DGXNGPU=4
38: ++ export MAX_SAMPLES_TERMINATION=4500000
38: ++ MAX_SAMPLES_TERMINATION=4500000
17: ++ tr -d '['
47: ++ export DGXSOCKETCORES=64
47: ++ DGXSOCKETCORES=64
38: ++ export MAX_STEPS=1059
17: ++ echo 'node[022-023,027-040]'
47: ++ export DGXNSOCKET=2
47: ++ DGXNSOCKET=2
38: ++ MAX_STEPS=1059
47: ++ export DGXHT=1
38: ++ export OPT_LAMB_BETA_1=0.60466
38: ++ OPT_LAMB_BETA_1=0.60466
47: ++ DGXHT=1
38: ++ export OPT_LAMB_BETA_2=0.85437
38: ++ OPT_LAMB_BETA_2=0.85437
38: ++ export START_WARMUP_STEP=0
38: ++ START_WARMUP_STEP=0
38: ++ export WARMUP_PROPORTION=0.0
38: ++ WARMUP_PROPORTION=0.0
38: ++ export WEIGHT_DECAY_RATE=0.1
38: ++ WEIGHT_DECAY_RATE=0.1
38: ++ export INIT_LOSS_SCALE=4096.0
38: ++ INIT_LOSS_SCALE=4096.0
38: ++ export SBATCH_NETWORK=sharp
38: ++ SBATCH_NETWORK=sharp
38: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
38: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
38: ++ export PHASE=2
38: ++ PHASE=2
47: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
47: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
38: ++ export EVAL_ITER_START_SAMPLES=175000
38: ++ EVAL_ITER_START_SAMPLES=175000
47: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
38: ++ export EVAL_ITER_SAMPLES=175000
38: ++ EVAL_ITER_SAMPLES=175000
47: ++ export MLPERF_SUBMISSION_ORG=Dell
47: ++ MLPERF_SUBMISSION_ORG=Dell
38: ++ export DGXNNODES=16
38: ++ DGXNNODES=16
47: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
47: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
47: ++ export OMP_NUM_THREADS=8
47: ++ OMP_NUM_THREADS=8
47: + ulimit -Sn 100000
47: + '[' '' = 1 ']'
47: + : 48
47: + : 1
47: + : 0.0020992
47: + : 1059
47: + : 2
47: + : 3
47: + : ''
47: + : ''\'''\'''
47: + : 17587
47: + : 2508
47: + : 11
47: + : 4
47: + : ''
47: + : 0
47: + : 175000
47: + : 175000
47: + : 4500000
47: + : 0.60466
47: + : 0.85437
47: + : 0
47: + : 0.720
47: + : 0
47: + : 0.0
47: + : 0.0
47: + : 0.1
47: + : 0
47: + : 0
47: + : 0
47: + : 0
47: + : 0
47: + : 0
47: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
47: Run vars: id 2508 gpus 4 mparams ''
54: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
38: +++ sed 's/^config_//'
38: +++ sed 's/\.sh$//'
54: ++ export BATCHSIZE=48
54: ++ BATCHSIZE=48
38: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
47: ++ date +%s
 5: + START_FMT='2022-10-13 08:25:32 AM'
54: ++ export GRADIENT_STEPS=1
54: ++ GRADIENT_STEPS=1
54: ++ export LR=0.0020992
54: ++ LR=0.0020992
54: ++ export MAX_SAMPLES_TERMINATION=4500000
54: ++ MAX_SAMPLES_TERMINATION=4500000
54: ++ export MAX_STEPS=1059
54: ++ MAX_STEPS=1059
54: ++ export OPT_LAMB_BETA_1=0.60466
54: ++ OPT_LAMB_BETA_1=0.60466
54: ++ export OPT_LAMB_BETA_2=0.85437
54: ++ OPT_LAMB_BETA_2=0.85437
54: ++ export START_WARMUP_STEP=0
54: ++ START_WARMUP_STEP=0
54: ++ export WARMUP_PROPORTION=0.0
54: ++ WARMUP_PROPORTION=0.0
 5: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
54: ++ export WEIGHT_DECAY_RATE=0.1
54: ++ WEIGHT_DECAY_RATE=0.1
54: ++ export INIT_LOSS_SCALE=4096.0
54: ++ INIT_LOSS_SCALE=4096.0
 5: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
54: ++ export SBATCH_NETWORK=sharp
54: ++ SBATCH_NETWORK=sharp
 5: + '[' '!' -z '' ']'
 5: + '[' 0 -gt 0 ']'
54: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
54: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
54: ++ export PHASE=2
54: ++ PHASE=2
54: ++ export EVAL_ITER_START_SAMPLES=175000
54: ++ EVAL_ITER_START_SAMPLES=175000
54: ++ export EVAL_ITER_SAMPLES=175000
54: ++ EVAL_ITER_SAMPLES=175000
54: ++ export DGXNNODES=16
54: ++ DGXNNODES=16
 5: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 5: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 5: + PHASES=("$PHASE1" "$PHASE2")
 5: + export RANK=5
 5: + RANK=5
 5: + export WORLD_SIZE=64
 5: + WORLD_SIZE=64
 5: WORLD_SIZE=64
 5: + echo WORLD_SIZE=64
54: +++ sed 's/^config_//'
54: +++ sed 's/\.sh$//'
54: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 5: ++ cut -d - -f1
 5: ++ cut -d - -f2 -
 5: ++ echo 'node[022-023,027-040]'
 5: ++ tr -d '['
40: + export MASTER_ADDR=node022
40: + MASTER_ADDR=node022
40: MASTER_ADDR=node022
40: + echo MASTER_ADDR=node022
40: + export MASTER_PORT=19002
40: + MASTER_PORT=19002
40: + echo HOSTNAME=node022
40: HOSTNAME=node022
40: + declare -a CMD
40: + [[ -n 0 ]]
40: + [[ 64 -gt 16 ]]
40: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
40: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
40: =0     --bert_config_path=/workspace/phase1/bert_config.json '
40: + '[' -n 0 ']'
40: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
40: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
40: + [[ 0 != 1 ]]
17: + export MASTER_ADDR=node022
17: + MASTER_ADDR=node022
40: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
40: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
40: + [[ '' -ge 1 ]]
40: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
40: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
17: MASTER_ADDR=node022
40: + [[ 0 != 0 ]]
17: + echo MASTER_ADDR=node022
17: + export MASTER_PORT=19002
17: + MASTER_PORT=19002
17: + echo HOSTNAME=node022
17: HOSTNAME=node022
17: + declare -a CMD
17: + [[ -n 1 ]]
17: + [[ 64 -gt 16 ]]
17: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
40: + '[' '' = apiLog.sh ']'
40: + '[' '' = 1 ']'
40: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
40:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=16855'
40: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
17: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
40: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=16855
17: =0     --bert_config_path=/workspace/phase1/bert_config.json '
17: + '[' -n 1 ']'
17: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
17: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
17: + [[ 0 != 1 ]]
17: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
17: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
17: + [[ '' -ge 1 ]]
38: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
17: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
17: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
17: + [[ 0 != 0 ]]
47: + START=1665667532
17: + '[' '' = apiLog.sh ']'
17: + '[' '' = 1 ']'
17: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
17:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=29761'
17: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
17: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=29761
47: ++ date '+%Y-%m-%d %r'
47: + START_FMT='2022-10-13 08:25:32 AM'
47: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
47: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
47: + '[' '!' -z '' ']'
54: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
47: + '[' 0 -gt 0 ']'
47: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
47: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
47: + PHASES=("$PHASE1" "$PHASE2")
 5: + export MASTER_ADDR=node022
 5: + MASTER_ADDR=node022
47: + export RANK=47
47: + RANK=47
47: + export WORLD_SIZE=64
47: + WORLD_SIZE=64
47: WORLD_SIZE=64
47: + echo WORLD_SIZE=64
 5: + echo MASTER_ADDR=node022
 5: MASTER_ADDR=node022
 5: + export MASTER_PORT=19002
 5: + MASTER_PORT=19002
 5: HOSTNAME=node022
 5: + echo HOSTNAME=node022
 5: + declare -a CMD
 5: + [[ -n 1 ]]
 5: + [[ 64 -gt 16 ]]
 5: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 5: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 5: + '[' -n 1 ']'
 5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 5: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
 5: + [[ 0 != 1 ]]
 5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 5: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 5: + [[ '' -ge 1 ]]
 5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 5: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 5: + [[ 0 != 0 ]]
 5: + '[' '' = apiLog.sh ']'
 5: + '[' '' = 1 ']'
 5: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
 5:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=22881'
47: ++ cut -d - -f1
 5: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
47: ++ cut -d - -f2 -
 5: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=22881
47: ++ tr -d '['
47: ++ echo 'node[022-023,027-040]'
38: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
38: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
38: ++ export WALLTIME_MINUTES=15
38: ++ WALLTIME_MINUTES=15
38: ++ export WALLTIME=20
38: ++ WALLTIME=20
38: ++ export DGXNGPU=4
38: ++ DGXNGPU=4
38: ++ export DGXSOCKETCORES=64
38: ++ DGXSOCKETCORES=64
38: ++ export DGXNSOCKET=2
38: ++ DGXNSOCKET=2
38: ++ export DGXHT=1
38: ++ DGXHT=1
38: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
38: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
38: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
38: ++ export MLPERF_SUBMISSION_ORG=Dell
38: ++ MLPERF_SUBMISSION_ORG=Dell
38: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
38: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
38: ++ export OMP_NUM_THREADS=8
38: ++ OMP_NUM_THREADS=8
38: + ulimit -Sn 100000
38: + '[' '' = 1 ']'
38: + : 48
38: + : 1
38: + : 0.0020992
38: + : 1059
38: + : 2
38: + : 2
38: + : ''
38: + : ''\'''\'''
38: + : 26
38: + : 2508
38: + : 9
38: + : 4
38: + : ''
38: + : 0
38: + : 175000
38: + : 175000
38: + : 4500000
38: + : 0.60466
38: + : 0.85437
38: + : 0
38: + : 0.720
38: + : 0
38: + : 0.0
38: + : 0.0
38: + : 0.1
38: + : 0
38: + : 0
38: + : 0
38: + : 0
38: + : 0
38: + : 0
38: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
38: Run vars: id 2508 gpus 4 mparams ''
38: ++ date +%s
54: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
54: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
54: ++ export WALLTIME_MINUTES=15
54: ++ WALLTIME_MINUTES=15
54: ++ export WALLTIME=20
54: ++ WALLTIME=20
54: ++ export DGXNGPU=4
54: ++ DGXNGPU=4
54: ++ export DGXSOCKETCORES=64
54: ++ DGXSOCKETCORES=64
54: ++ export DGXNSOCKET=2
54: ++ DGXNSOCKET=2
54: ++ export DGXHT=1
54: ++ DGXHT=1
54: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
54: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
54: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
54: ++ export MLPERF_SUBMISSION_ORG=Dell
54: ++ MLPERF_SUBMISSION_ORG=Dell
54: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
54: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
54: ++ export OMP_NUM_THREADS=8
54: ++ OMP_NUM_THREADS=8
54: + ulimit -Sn 100000
54: + '[' '' = 1 ']'
54: + : 48
54: + : 1
54: + : 0.0020992
54: + : 1059
54: + : 2
54: + : 2
54: + : ''
54: + : ''\'''\'''
54: + : 30118
54: + : 2508
54: + : 13
54: + : 4
54: + : ''
54: + : 0
54: + : 175000
54: + : 175000
54: + : 4500000
54: + : 0.60466
54: + : 0.85437
54: + : 0
54: + : 0.720
54: + : 0
54: + : 0.0
54: + : 0.0
54: + : 0.1
54: + : 0
54: + : 0
54: + : 0
54: + : 0
54: + : 0
54: + : 0
54: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
54: Run vars: id 2508 gpus 4 mparams ''
54: ++ date +%s
47: + export MASTER_ADDR=node022
47: + MASTER_ADDR=node022
47: MASTER_ADDR=node022
47: + echo MASTER_ADDR=node022
47: + export MASTER_PORT=19002
47: + MASTER_PORT=19002
47: + echo HOSTNAME=node022
47: HOSTNAME=node022
47: + declare -a CMD
47: + [[ -n 3 ]]
47: + [[ 64 -gt 16 ]]
47: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
47: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
47: =0     --bert_config_path=/workspace/phase1/bert_config.json '
47: + '[' -n 3 ']'
47: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
47: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
47: + [[ 0 != 1 ]]
47: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
47: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
47: + [[ '' -ge 1 ]]
47: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
47: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
47: + [[ 0 != 0 ]]
47: + '[' '' = apiLog.sh ']'
47: + '[' '' = 1 ']'
47: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
47:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=17587'
38: + START=1665667532
47: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
47: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=17587
38: ++ date '+%Y-%m-%d %r'
38: + START_FMT='2022-10-13 08:25:32 AM'
38: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
38: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
38: + '[' '!' -z '' ']'
38: + '[' 0 -gt 0 ']'
54: + START=1665667532
38: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
38: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
38: + PHASES=("$PHASE1" "$PHASE2")
38: + export RANK=38
38: + RANK=38
38: + export WORLD_SIZE=64
38: + WORLD_SIZE=64
38: WORLD_SIZE=64
38: + echo WORLD_SIZE=64
54: ++ date '+%Y-%m-%d %r'
38: ++ cut -d - -f1
38: ++ cut -d - -f2 -
38: ++ tr -d '['
38: ++ echo 'node[022-023,027-040]'
54: + START_FMT='2022-10-13 08:25:32 AM'
54: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
54: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
54: + '[' '!' -z '' ']'
54: + '[' 0 -gt 0 ']'
54: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
54: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
54: + PHASES=("$PHASE1" "$PHASE2")
54: + export RANK=54
54: + RANK=54
54: + export WORLD_SIZE=64
54: + WORLD_SIZE=64
54: WORLD_SIZE=64
54: + echo WORLD_SIZE=64
54: ++ cut -d - -f1
54: ++ cut -d - -f2 -
54: ++ tr -d '['
54: ++ echo 'node[022-023,027-040]'
15: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
15: ++ export BATCHSIZE=48
15: ++ BATCHSIZE=48
15: ++ export GRADIENT_STEPS=1
15: ++ GRADIENT_STEPS=1
15: ++ export LR=0.0020992
15: ++ LR=0.0020992
15: ++ export MAX_SAMPLES_TERMINATION=4500000
15: ++ MAX_SAMPLES_TERMINATION=4500000
15: ++ export MAX_STEPS=1059
15: ++ MAX_STEPS=1059
15: ++ export OPT_LAMB_BETA_1=0.60466
15: ++ OPT_LAMB_BETA_1=0.60466
15: ++ export OPT_LAMB_BETA_2=0.85437
15: ++ OPT_LAMB_BETA_2=0.85437
15: ++ export START_WARMUP_STEP=0
15: ++ START_WARMUP_STEP=0
15: ++ export WARMUP_PROPORTION=0.0
15: ++ WARMUP_PROPORTION=0.0
15: ++ export WEIGHT_DECAY_RATE=0.1
15: ++ WEIGHT_DECAY_RATE=0.1
15: ++ export INIT_LOSS_SCALE=4096.0
15: ++ INIT_LOSS_SCALE=4096.0
15: ++ export SBATCH_NETWORK=sharp
15: ++ SBATCH_NETWORK=sharp
15: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
15: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
15: ++ export PHASE=2
15: ++ PHASE=2
15: ++ export EVAL_ITER_START_SAMPLES=175000
15: ++ EVAL_ITER_START_SAMPLES=175000
15: ++ export EVAL_ITER_SAMPLES=175000
38: + export MASTER_ADDR=node022
38: + MASTER_ADDR=node022
15: ++ EVAL_ITER_SAMPLES=175000
15: ++ export DGXNNODES=16
15: ++ DGXNNODES=16
38: MASTER_ADDR=node022
38: + echo MASTER_ADDR=node022
38: + export MASTER_PORT=19002
38: + MASTER_PORT=19002
38: + echo HOSTNAME=node022
38: HOSTNAME=node022
38: + declare -a CMD
38: + [[ -n 2 ]]
38: + [[ 64 -gt 16 ]]
38: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
38: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
38: =0     --bert_config_path=/workspace/phase1/bert_config.json '
38: + '[' -n 2 ']'
38: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
38: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
38: + [[ 0 != 1 ]]
38: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
38: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
38: + [[ '' -ge 1 ]]
38: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
38: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
38: + [[ 0 != 0 ]]
38: + '[' '' = apiLog.sh ']'
38: + '[' '' = 1 ']'
38: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
38:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=26'
38: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
15: +++ sed 's/^config_//'
38: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=26
15: +++ sed 's/\.sh$//'
54: + export MASTER_ADDR=node022
54: + MASTER_ADDR=node022
15: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
54: MASTER_ADDR=node022
54: + echo MASTER_ADDR=node022
54: + export MASTER_PORT=19002
54: + MASTER_PORT=19002
54: HOSTNAME=node022
54: + echo HOSTNAME=node022
54: + declare -a CMD
54: + [[ -n 2 ]]
54: + [[ 64 -gt 16 ]]
54: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
54: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
54: =0     --bert_config_path=/workspace/phase1/bert_config.json '
54: + '[' -n 2 ']'
54: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
54: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
54: + [[ 0 != 1 ]]
54: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
54: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
54: + [[ '' -ge 1 ]]
54: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
54: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
54: + [[ 0 != 0 ]]
54: + '[' '' = apiLog.sh ']'
54: + '[' '' = 1 ']'
54: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
54:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=30118'
54: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
54: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=30118
15: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
15: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
15: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
15: ++ export WALLTIME_MINUTES=15
15: ++ WALLTIME_MINUTES=15
15: ++ export WALLTIME=20
15: ++ WALLTIME=20
15: ++ export DGXNGPU=4
15: ++ DGXNGPU=4
15: ++ export DGXSOCKETCORES=64
15: ++ DGXSOCKETCORES=64
15: ++ export DGXNSOCKET=2
15: ++ DGXNSOCKET=2
15: ++ export DGXHT=1
15: ++ DGXHT=1
15: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
15: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
15: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
15: ++ export MLPERF_SUBMISSION_ORG=Dell
15: ++ MLPERF_SUBMISSION_ORG=Dell
15: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
15: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
15: ++ export OMP_NUM_THREADS=8
15: ++ OMP_NUM_THREADS=8
15: + ulimit -Sn 100000
15: + '[' '' = 1 ']'
15: + : 48
15: + : 1
15: + : 0.0020992
15: + : 1059
15: + : 2
15: + : 3
15: + : ''
15: + : ''\'''\'''
15: + : 2984
15: + : 2508
15: + : 3
15: + : 4
15: + : ''
15: + : 0
15: + : 175000
15: + : 175000
15: + : 4500000
15: + : 0.60466
15: + : 0.85437
15: + : 0
15: + : 0.720
15: + : 0
15: + : 0.0
15: + : 0.0
15: + : 0.1
15: + : 0
15: + : 0
15: + : 0
15: + : 0
15: + : 0
15: + : 0
15: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
15: Run vars: id 2508 gpus 4 mparams ''
15: ++ date +%s
15: + START=1665667532
15: ++ date '+%Y-%m-%d %r'
15: + START_FMT='2022-10-13 08:25:32 AM'
15: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
15: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
15: + '[' '!' -z '' ']'
15: + '[' 0 -gt 0 ']'
15: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
15: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
15: + PHASES=("$PHASE1" "$PHASE2")
15: + export RANK=15
15: + RANK=15
15: + export WORLD_SIZE=64
15: + WORLD_SIZE=64
15: WORLD_SIZE=64
15: + echo WORLD_SIZE=64
15: ++ cut -d - -f1
15: ++ cut -d - -f2 -
15: ++ echo 'node[022-023,027-040]'
15: ++ tr -d '['
53: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
53: ++ export BATCHSIZE=48
53: ++ BATCHSIZE=48
53: ++ export GRADIENT_STEPS=1
53: ++ GRADIENT_STEPS=1
53: ++ export LR=0.0020992
53: ++ LR=0.0020992
53: ++ export MAX_SAMPLES_TERMINATION=4500000
53: ++ MAX_SAMPLES_TERMINATION=4500000
53: ++ export MAX_STEPS=1059
53: ++ MAX_STEPS=1059
53: ++ export OPT_LAMB_BETA_1=0.60466
53: ++ OPT_LAMB_BETA_1=0.60466
53: ++ export OPT_LAMB_BETA_2=0.85437
53: ++ OPT_LAMB_BETA_2=0.85437
53: ++ export START_WARMUP_STEP=0
53: ++ START_WARMUP_STEP=0
53: ++ export WARMUP_PROPORTION=0.0
53: ++ WARMUP_PROPORTION=0.0
53: ++ export WEIGHT_DECAY_RATE=0.1
53: ++ WEIGHT_DECAY_RATE=0.1
53: ++ export INIT_LOSS_SCALE=4096.0
53: ++ INIT_LOSS_SCALE=4096.0
53: ++ export SBATCH_NETWORK=sharp
53: ++ SBATCH_NETWORK=sharp
53: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
53: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
53: ++ export PHASE=2
53: ++ PHASE=2
53: ++ export EVAL_ITER_START_SAMPLES=175000
53: ++ EVAL_ITER_START_SAMPLES=175000
53: ++ export EVAL_ITER_SAMPLES=175000
53: ++ EVAL_ITER_SAMPLES=175000
53: ++ export DGXNNODES=16
53: ++ DGXNNODES=16
53: +++ sed 's/^config_//'
53: +++ sed 's/\.sh$//'
53: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
15: + export MASTER_ADDR=node022
15: + MASTER_ADDR=node022
15: MASTER_ADDR=node022
15: + echo MASTER_ADDR=node022
15: + export MASTER_PORT=19002
15: + MASTER_PORT=19002
15: + echo HOSTNAME=node022
15: HOSTNAME=node022
15: + declare -a CMD
15: + [[ -n 3 ]]
15: + [[ 64 -gt 16 ]]
15: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
15: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
15: =0     --bert_config_path=/workspace/phase1/bert_config.json '
15: + '[' -n 3 ']'
15: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
15: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
15: + [[ 0 != 1 ]]
15: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
15: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
15: + [[ '' -ge 1 ]]
15: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
15: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
15: + [[ 0 != 0 ]]
15: + '[' '' = apiLog.sh ']'
15: + '[' '' = 1 ']'
15: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
15:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=2984'
15: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
15: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=2984
53: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
53: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
53: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
53: ++ export WALLTIME_MINUTES=15
53: ++ WALLTIME_MINUTES=15
53: ++ export WALLTIME=20
53: ++ WALLTIME=20
53: ++ export DGXNGPU=4
53: ++ DGXNGPU=4
53: ++ export DGXSOCKETCORES=64
53: ++ DGXSOCKETCORES=64
53: ++ export DGXNSOCKET=2
53: ++ DGXNSOCKET=2
53: ++ export DGXHT=1
53: ++ DGXHT=1
53: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
53: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
53: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
53: ++ export MLPERF_SUBMISSION_ORG=Dell
53: ++ MLPERF_SUBMISSION_ORG=Dell
53: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
53: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
53: ++ export OMP_NUM_THREADS=8
53: ++ OMP_NUM_THREADS=8
53: + ulimit -Sn 100000
53: + '[' '' = 1 ']'
53: + : 48
53: + : 1
53: + : 0.0020992
53: + : 1059
53: + : 2
53: + : 1
53: + : ''
53: + : ''\'''\'''
53: + : 19021
53: + : 2508
53: + : 13
53: + : 4
53: + : ''
53: + : 0
53: + : 175000
53: + : 175000
53: + : 4500000
53: + : 0.60466
53: + : 0.85437
53: + : 0
53: + : 0.720
53: + : 0
53: + : 0.0
53: + : 0.0
53: + : 0.1
53: + : 0
53: + : 0
53: + : 0
53: + : 0
53: + : 0
53: + : 0
53: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
53: Run vars: id 2508 gpus 4 mparams ''
53: ++ date +%s
 9: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 9: ++ export BATCHSIZE=48
 9: ++ BATCHSIZE=48
 9: ++ export GRADIENT_STEPS=1
 9: ++ GRADIENT_STEPS=1
 9: ++ export LR=0.0020992
 9: ++ LR=0.0020992
 9: ++ export MAX_SAMPLES_TERMINATION=4500000
 9: ++ MAX_SAMPLES_TERMINATION=4500000
 9: ++ export MAX_STEPS=1059
 9: ++ MAX_STEPS=1059
 9: ++ export OPT_LAMB_BETA_1=0.60466
 9: ++ OPT_LAMB_BETA_1=0.60466
 9: ++ export OPT_LAMB_BETA_2=0.85437
 9: ++ OPT_LAMB_BETA_2=0.85437
 9: ++ export START_WARMUP_STEP=0
 9: ++ START_WARMUP_STEP=0
 9: ++ export WARMUP_PROPORTION=0.0
 9: ++ WARMUP_PROPORTION=0.0
 9: ++ export WEIGHT_DECAY_RATE=0.1
 9: ++ WEIGHT_DECAY_RATE=0.1
 9: ++ export INIT_LOSS_SCALE=4096.0
 9: ++ INIT_LOSS_SCALE=4096.0
 9: ++ export SBATCH_NETWORK=sharp
 9: ++ SBATCH_NETWORK=sharp
 9: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 9: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 9: ++ export PHASE=2
 9: ++ PHASE=2
 9: ++ export EVAL_ITER_START_SAMPLES=175000
 9: ++ EVAL_ITER_START_SAMPLES=175000
 9: ++ export EVAL_ITER_SAMPLES=175000
 9: ++ EVAL_ITER_SAMPLES=175000
 9: ++ export DGXNNODES=16
 9: ++ DGXNNODES=16
53: + START=1665667532
53: ++ date '+%Y-%m-%d %r'
 9: +++ sed 's/^config_//'
 9: +++ sed 's/\.sh$//'
 9: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
53: + START_FMT='2022-10-13 08:25:32 AM'
53: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
53: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
53: + '[' '!' -z '' ']'
53: + '[' 0 -gt 0 ']'
53: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
53: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
53: + PHASES=("$PHASE1" "$PHASE2")
53: + export RANK=53
53: + RANK=53
53: + export WORLD_SIZE=64
53: + WORLD_SIZE=64
53: + echo WORLD_SIZE=64
53: WORLD_SIZE=64
53: ++ cut -d - -f1
53: ++ cut -d - -f2 -
53: ++ tr -d '['
53: ++ echo 'node[022-023,027-040]'
 9: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
53: + export MASTER_ADDR=node022
53: + MASTER_ADDR=node022
53: MASTER_ADDR=node022
53: + echo MASTER_ADDR=node022
53: + export MASTER_PORT=19002
53: + MASTER_PORT=19002
53: HOSTNAME=node022
53: + echo HOSTNAME=node022
53: + declare -a CMD
53: + [[ -n 1 ]]
53: + [[ 64 -gt 16 ]]
53: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
53: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
53: =0     --bert_config_path=/workspace/phase1/bert_config.json '
53: + '[' -n 1 ']'
53: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
53: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
53: + [[ 0 != 1 ]]
53: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
53: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
53: + [[ '' -ge 1 ]]
53: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
53: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
53: + [[ 0 != 0 ]]
53: + '[' '' = apiLog.sh ']'
53: + '[' '' = 1 ']'
53: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
53:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=19021'
 9: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 9: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
53: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 9: ++ export WALLTIME_MINUTES=15
 9: ++ WALLTIME_MINUTES=15
 9: ++ export WALLTIME=20
 9: ++ WALLTIME=20
 9: ++ export DGXNGPU=4
 9: ++ DGXNGPU=4
 9: ++ export DGXSOCKETCORES=64
 9: ++ DGXSOCKETCORES=64
 9: ++ export DGXNSOCKET=2
 9: ++ DGXNSOCKET=2
 9: ++ export DGXHT=1
 9: ++ DGXHT=1
 9: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 9: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 9: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 9: ++ export MLPERF_SUBMISSION_ORG=Dell
 9: ++ MLPERF_SUBMISSION_ORG=Dell
53: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=19021
 9: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 9: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 9: ++ export OMP_NUM_THREADS=8
 9: ++ OMP_NUM_THREADS=8
 9: + ulimit -Sn 100000
 9: + '[' '' = 1 ']'
 9: + : 48
 9: + : 1
 9: + : 0.0020992
 9: + : 1059
 9: + : 2
 9: + : 1
 9: + : ''
 9: + : ''\'''\'''
 9: + : 19532
 9: + : 2508
 9: + : 2
 9: + : 4
 9: + : ''
 9: + : 0
 9: + : 175000
 9: + : 175000
 9: + : 4500000
 9: + : 0.60466
 9: + : 0.85437
 9: + : 0
 9: + : 0.720
 9: + : 0
 9: + : 0.0
 9: + : 0.0
 9: + : 0.1
 9: + : 0
 9: + : 0
 9: + : 0
 9: + : 0
 9: + : 0
 9: + : 0
 9: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
 9: Run vars: id 2508 gpus 4 mparams ''
 9: ++ date +%s
 9: + START=1665667532
 9: ++ date '+%Y-%m-%d %r'
59: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 9: + START_FMT='2022-10-13 08:25:32 AM'
59: ++ export BATCHSIZE=48
59: ++ BATCHSIZE=48
 9: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
 9: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
 9: + '[' '!' -z '' ']'
 9: + '[' 0 -gt 0 ']'
59: ++ export GRADIENT_STEPS=1
59: ++ GRADIENT_STEPS=1
59: ++ export LR=0.0020992
59: ++ LR=0.0020992
59: ++ export MAX_SAMPLES_TERMINATION=4500000
59: ++ MAX_SAMPLES_TERMINATION=4500000
59: ++ export MAX_STEPS=1059
59: ++ MAX_STEPS=1059
59: ++ export OPT_LAMB_BETA_1=0.60466
59: ++ OPT_LAMB_BETA_1=0.60466
59: ++ export OPT_LAMB_BETA_2=0.85437
59: ++ OPT_LAMB_BETA_2=0.85437
 9: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
59: ++ export START_WARMUP_STEP=0
59: ++ START_WARMUP_STEP=0
 9: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
59: ++ export WARMUP_PROPORTION=0.0
59: ++ WARMUP_PROPORTION=0.0
 9: + PHASES=("$PHASE1" "$PHASE2")
59: ++ export WEIGHT_DECAY_RATE=0.1
59: ++ WEIGHT_DECAY_RATE=0.1
59: ++ export INIT_LOSS_SCALE=4096.0
59: ++ INIT_LOSS_SCALE=4096.0
59: ++ export SBATCH_NETWORK=sharp
59: ++ SBATCH_NETWORK=sharp
59: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
59: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
59: ++ export PHASE=2
59: ++ PHASE=2
59: ++ export EVAL_ITER_START_SAMPLES=175000
59: ++ EVAL_ITER_START_SAMPLES=175000
59: ++ export EVAL_ITER_SAMPLES=175000
59: ++ EVAL_ITER_SAMPLES=175000
59: ++ export DGXNNODES=16
59: ++ DGXNNODES=16
 9: + export RANK=9
 9: + RANK=9
 9: + export WORLD_SIZE=64
 9: + WORLD_SIZE=64
 9: WORLD_SIZE=64
 9: + echo WORLD_SIZE=64
59: +++ sed 's/^config_//'
59: +++ sed 's/\.sh$//'
 9: ++ cut -d - -f1
 9: ++ echo 'node[022-023,027-040]'
59: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 9: ++ cut -d - -f2 -
 9: ++ tr -d '['
59: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 9: + export MASTER_ADDR=node022
 9: + MASTER_ADDR=node022
 9: MASTER_ADDR=node022
 9: + echo MASTER_ADDR=node022
 9: + export MASTER_PORT=19002
 9: + MASTER_PORT=19002
 9: + echo HOSTNAME=node022
 9: HOSTNAME=node022
 9: + declare -a CMD
 9: + [[ -n 1 ]]
 9: + [[ 64 -gt 16 ]]
 9: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 9: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 9: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 9: + '[' -n 1 ']'
 9: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 9: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
 9: + [[ 0 != 1 ]]
 9: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 9: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 9: + [[ '' -ge 1 ]]
 9: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 9: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 9: + [[ 0 != 0 ]]
 9: + '[' '' = apiLog.sh ']'
 9: + '[' '' = 1 ']'
 9: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
 9:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=19532'
 9: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 9: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=19532
59: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
59: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
59: ++ export WALLTIME_MINUTES=15
59: ++ WALLTIME_MINUTES=15
59: ++ export WALLTIME=20
59: ++ WALLTIME=20
59: ++ export DGXNGPU=4
59: ++ DGXNGPU=4
59: ++ export DGXSOCKETCORES=64
59: ++ DGXSOCKETCORES=64
59: ++ export DGXNSOCKET=2
59: ++ DGXNSOCKET=2
59: ++ export DGXHT=1
59: ++ DGXHT=1
59: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
59: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
59: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
59: ++ export MLPERF_SUBMISSION_ORG=Dell
59: ++ MLPERF_SUBMISSION_ORG=Dell
59: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
59: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
59: ++ export OMP_NUM_THREADS=8
59: ++ OMP_NUM_THREADS=8
59: + ulimit -Sn 100000
59: + '[' '' = 1 ']'
59: + : 48
59: + : 1
59: + : 0.0020992
59: + : 1059
59: + : 2
59: + : 3
59: + : ''
59: + : ''\'''\'''
59: + : 30769
59: + : 2508
59: + : 14
59: + : 4
59: + : ''
59: + : 0
59: + : 175000
59: + : 175000
59: + : 4500000
59: + : 0.60466
59: + : 0.85437
59: + : 0
59: + : 0.720
59: + : 0
59: + : 0.0
59: + : 0.0
59: + : 0.1
59: + : 0
59: + : 0
59: + : 0
59: + : 0
59: + : 0
59: + : 0
59: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
59: Run vars: id 2508 gpus 4 mparams ''
59: ++ date +%s
59: + START=1665667532
59: ++ date '+%Y-%m-%d %r'
59: + START_FMT='2022-10-13 08:25:32 AM'
59: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
59: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
59: + '[' '!' -z '' ']'
59: + '[' 0 -gt 0 ']'
59: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
59: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
59: + PHASES=("$PHASE1" "$PHASE2")
59: + export RANK=59
59: + RANK=59
59: + export WORLD_SIZE=64
59: + WORLD_SIZE=64
59: WORLD_SIZE=64
59: + echo WORLD_SIZE=64
59: ++ cut -d - -f1
59: ++ cut -d - -f2 -
59: ++ tr -d '['
59: ++ echo 'node[022-023,027-040]'
59: + export MASTER_ADDR=node022
59: + MASTER_ADDR=node022
59: + echo MASTER_ADDR=node022
59: MASTER_ADDR=node022
59: + export MASTER_PORT=19002
59: + MASTER_PORT=19002
59: + echo HOSTNAME=node022
59: HOSTNAME=node022
59: + declare -a CMD
59: + [[ -n 3 ]]
59: + [[ 64 -gt 16 ]]
59: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
59: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
59: =0     --bert_config_path=/workspace/phase1/bert_config.json '
59: + '[' -n 3 ']'
59: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
59: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
59: + [[ 0 != 1 ]]
59: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
59: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
59: + [[ '' -ge 1 ]]
59: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
59: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
59: + [[ 0 != 0 ]]
59: + '[' '' = apiLog.sh ']'
59: + '[' '' = 1 ']'
59: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
59:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=30769'
59: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
59: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=30769
33: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
33: ++ export BATCHSIZE=48
33: ++ BATCHSIZE=48
33: ++ export GRADIENT_STEPS=1
33: ++ GRADIENT_STEPS=1
33: ++ export LR=0.0020992
33: ++ LR=0.0020992
33: ++ export MAX_SAMPLES_TERMINATION=4500000
33: ++ MAX_SAMPLES_TERMINATION=4500000
33: ++ export MAX_STEPS=1059
33: ++ MAX_STEPS=1059
33: ++ export OPT_LAMB_BETA_1=0.60466
33: ++ OPT_LAMB_BETA_1=0.60466
33: ++ export OPT_LAMB_BETA_2=0.85437
33: ++ OPT_LAMB_BETA_2=0.85437
33: ++ export START_WARMUP_STEP=0
33: ++ START_WARMUP_STEP=0
33: ++ export WARMUP_PROPORTION=0.0
33: ++ WARMUP_PROPORTION=0.0
33: ++ export WEIGHT_DECAY_RATE=0.1
33: ++ WEIGHT_DECAY_RATE=0.1
33: ++ export INIT_LOSS_SCALE=4096.0
33: ++ INIT_LOSS_SCALE=4096.0
33: ++ export SBATCH_NETWORK=sharp
33: ++ SBATCH_NETWORK=sharp
33: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
33: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
33: ++ export PHASE=2
33: ++ PHASE=2
33: ++ export EVAL_ITER_START_SAMPLES=175000
33: ++ EVAL_ITER_START_SAMPLES=175000
33: ++ export EVAL_ITER_SAMPLES=175000
33: ++ EVAL_ITER_SAMPLES=175000
33: ++ export DGXNNODES=16
33: ++ DGXNNODES=16
33: +++ sed 's/^config_//'
33: +++ sed 's/\.sh$//'
33: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
29: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
29: ++ export BATCHSIZE=48
29: ++ BATCHSIZE=48
29: ++ export GRADIENT_STEPS=1
29: ++ GRADIENT_STEPS=1
29: ++ export LR=0.0020992
29: ++ LR=0.0020992
29: ++ export MAX_SAMPLES_TERMINATION=4500000
29: ++ MAX_SAMPLES_TERMINATION=4500000
29: ++ export MAX_STEPS=1059
29: ++ MAX_STEPS=1059
29: ++ export OPT_LAMB_BETA_1=0.60466
29: ++ OPT_LAMB_BETA_1=0.60466
29: ++ export OPT_LAMB_BETA_2=0.85437
29: ++ OPT_LAMB_BETA_2=0.85437
29: ++ export START_WARMUP_STEP=0
29: ++ START_WARMUP_STEP=0
29: ++ export WARMUP_PROPORTION=0.0
29: ++ WARMUP_PROPORTION=0.0
29: ++ export WEIGHT_DECAY_RATE=0.1
29: ++ WEIGHT_DECAY_RATE=0.1
29: ++ export INIT_LOSS_SCALE=4096.0
29: ++ INIT_LOSS_SCALE=4096.0
29: ++ export SBATCH_NETWORK=sharp
29: ++ SBATCH_NETWORK=sharp
29: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
29: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
29: ++ export PHASE=2
29: ++ PHASE=2
29: ++ export EVAL_ITER_START_SAMPLES=175000
29: ++ EVAL_ITER_START_SAMPLES=175000
29: ++ export EVAL_ITER_SAMPLES=175000
29: ++ EVAL_ITER_SAMPLES=175000
29: ++ export DGXNNODES=16
29: ++ DGXNNODES=16
29: +++ sed 's/^config_//'
29: +++ sed 's/\.sh$//'
29: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
33: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
29: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
33: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
33: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
33: ++ export WALLTIME_MINUTES=15
33: ++ WALLTIME_MINUTES=15
33: ++ export WALLTIME=20
33: ++ WALLTIME=20
33: ++ export DGXNGPU=4
33: ++ DGXNGPU=4
33: ++ export DGXSOCKETCORES=64
33: ++ DGXSOCKETCORES=64
33: ++ export DGXNSOCKET=2
33: ++ DGXNSOCKET=2
33: ++ export DGXHT=1
33: ++ DGXHT=1
33: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
33: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
33: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
33: ++ export MLPERF_SUBMISSION_ORG=Dell
33: ++ MLPERF_SUBMISSION_ORG=Dell
33: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
33: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
33: ++ export OMP_NUM_THREADS=8
33: ++ OMP_NUM_THREADS=8
33: + ulimit -Sn 100000
33: + '[' '' = 1 ']'
33: + : 48
33: + : 1
33: + : 0.0020992
33: + : 1059
33: + : 2
33: + : 1
33: + : ''
33: + : ''\'''\'''
33: + : 26375
33: + : 2508
33: + : 8
33: + : 4
33: + : ''
33: + : 0
33: + : 175000
33: + : 175000
33: + : 4500000
33: + : 0.60466
33: + : 0.85437
33: + : 0
33: + : 0.720
33: + : 0
33: + : 0.0
33: + : 0.0
33: + : 0.1
33: + : 0
33: + : 0
33: + : 0
33: + : 0
33: + : 0
33: + : 0
33: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
33: Run vars: id 2508 gpus 4 mparams ''
33: ++ date +%s
29: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
29: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
29: ++ export WALLTIME_MINUTES=15
29: ++ WALLTIME_MINUTES=15
29: ++ export WALLTIME=20
29: ++ WALLTIME=20
29: ++ export DGXNGPU=4
29: ++ DGXNGPU=4
29: ++ export DGXSOCKETCORES=64
29: ++ DGXSOCKETCORES=64
29: ++ export DGXNSOCKET=2
29: ++ DGXNSOCKET=2
29: ++ export DGXHT=1
29: ++ DGXHT=1
29: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
29: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
29: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
29: ++ export MLPERF_SUBMISSION_ORG=Dell
29: ++ MLPERF_SUBMISSION_ORG=Dell
29: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
29: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
29: ++ export OMP_NUM_THREADS=8
29: ++ OMP_NUM_THREADS=8
29: + ulimit -Sn 100000
29: + '[' '' = 1 ']'
29: + : 48
29: + : 1
29: + : 0.0020992
29: + : 1059
29: + : 2
29: + : 1
29: + : ''
29: + : ''\'''\'''
29: + : 12383
29: + : 2508
29: + : 7
29: + : 4
29: + : ''
29: + : 0
29: + : 175000
29: + : 175000
29: + : 4500000
29: + : 0.60466
29: + : 0.85437
29: + : 0
29: + : 0.720
29: + : 0
29: + : 0.0
29: + : 0.0
29: + : 0.1
29: + : 0
29: + : 0
29: + : 0
29: + : 0
29: + : 0
33: + START=1665667532
29: + : 0
29: Run vars: id 2508 gpus 4 mparams ''
29: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
29: ++ date +%s
33: ++ date '+%Y-%m-%d %r'
25: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
33: + START_FMT='2022-10-13 08:25:32 AM'
33: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
33: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
25: ++ export BATCHSIZE=48
25: ++ BATCHSIZE=48
33: + '[' '!' -z '' ']'
33: + '[' 0 -gt 0 ']'
25: ++ export GRADIENT_STEPS=1
25: ++ GRADIENT_STEPS=1
33: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
25: ++ export LR=0.0020992
33: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
25: ++ LR=0.0020992
33: + PHASES=("$PHASE1" "$PHASE2")
25: ++ export MAX_SAMPLES_TERMINATION=4500000
25: ++ MAX_SAMPLES_TERMINATION=4500000
25: ++ export MAX_STEPS=1059
25: ++ MAX_STEPS=1059
25: ++ export OPT_LAMB_BETA_1=0.60466
25: ++ OPT_LAMB_BETA_1=0.60466
25: ++ export OPT_LAMB_BETA_2=0.85437
25: ++ OPT_LAMB_BETA_2=0.85437
25: ++ export START_WARMUP_STEP=0
25: ++ START_WARMUP_STEP=0
25: ++ export WARMUP_PROPORTION=0.0
25: ++ WARMUP_PROPORTION=0.0
25: ++ export WEIGHT_DECAY_RATE=0.1
25: ++ WEIGHT_DECAY_RATE=0.1
25: ++ export INIT_LOSS_SCALE=4096.0
25: ++ INIT_LOSS_SCALE=4096.0
25: ++ export SBATCH_NETWORK=sharp
25: ++ SBATCH_NETWORK=sharp
25: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
25: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
25: ++ export PHASE=2
25: ++ PHASE=2
33: WORLD_SIZE=64
33: + export RANK=33
33: + RANK=33
25: ++ export EVAL_ITER_START_SAMPLES=175000
25: ++ EVAL_ITER_START_SAMPLES=175000
33: + export WORLD_SIZE=64
33: + WORLD_SIZE=64
25: ++ export EVAL_ITER_SAMPLES=175000
25: ++ EVAL_ITER_SAMPLES=175000
25: ++ export DGXNNODES=16
33: + echo WORLD_SIZE=64
25: ++ DGXNNODES=16
33: ++ cut -d - -f1
33: ++ cut -d - -f2 -
25: +++ sed 's/^config_//'
33: ++ tr -d '['
25: +++ sed 's/\.sh$//'
33: ++ echo 'node[022-023,027-040]'
25: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
29: + START=1665667532
29: ++ date '+%Y-%m-%d %r'
29: + START_FMT='2022-10-13 08:25:32 AM'
29: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:32 AM'
29: STARTING TIMING RUN AT 2022-10-13 08:25:32 AM
29: + '[' '!' -z '' ']'
29: + '[' 0 -gt 0 ']'
29: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
29: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
29: + PHASES=("$PHASE1" "$PHASE2")
29: + export RANK=29
29: + RANK=29
29: + export WORLD_SIZE=64
29: + WORLD_SIZE=64
29: WORLD_SIZE=64
29: + echo WORLD_SIZE=64
25: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
29: ++ cut -d - -f1
29: ++ cut -d - -f2 -
29: ++ echo 'node[022-023,027-040]'
29: ++ tr -d '['
33: + export MASTER_ADDR=node022
33: + MASTER_ADDR=node022
33: MASTER_ADDR=node022
33: + echo MASTER_ADDR=node022
33: + export MASTER_PORT=19002
33: + MASTER_PORT=19002
33: + echo HOSTNAME=node022
33: HOSTNAME=node022
33: + declare -a CMD
33: + [[ -n 1 ]]
33: + [[ 64 -gt 16 ]]
33: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
33: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
33: =0     --bert_config_path=/workspace/phase1/bert_config.json '
33: + '[' -n 1 ']'
33: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
33: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
33: + [[ 0 != 1 ]]
33: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
33: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
33: + [[ '' -ge 1 ]]
33: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
33: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
33: + [[ 0 != 0 ]]
33: + '[' '' = apiLog.sh ']'
33: + '[' '' = 1 ']'
33: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
33:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=26375'
33: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
33: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=26375
25: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
25: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
25: ++ export WALLTIME_MINUTES=15
25: ++ WALLTIME_MINUTES=15
25: ++ export WALLTIME=20
25: ++ WALLTIME=20
25: ++ export DGXNGPU=4
25: ++ DGXNGPU=4
25: ++ export DGXSOCKETCORES=64
25: ++ DGXSOCKETCORES=64
25: ++ export DGXNSOCKET=2
25: ++ DGXNSOCKET=2
25: ++ export DGXHT=1
25: ++ DGXHT=1
25: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
25: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
25: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
25: ++ export MLPERF_SUBMISSION_ORG=Dell
25: ++ MLPERF_SUBMISSION_ORG=Dell
25: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
25: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
25: ++ export OMP_NUM_THREADS=8
25: ++ OMP_NUM_THREADS=8
25: + ulimit -Sn 100000
25: + '[' '' = 1 ']'
25: + : 48
25: + : 1
25: + : 0.0020992
25: + : 1059
25: + : 2
25: + : 1
25: + : ''
25: + : ''\'''\'''
25: + : 5718
25: + : 2508
25: + : 6
25: + : 4
25: + : ''
25: + : 0
25: + : 175000
25: + : 175000
25: + : 4500000
25: + : 0.60466
25: + : 0.85437
25: + : 0
25: + : 0.720
25: + : 0
25: + : 0.0
25: + : 0.0
25: + : 0.1
25: + : 0
25: + : 0
25: + : 0
25: + : 0
25: + : 0
25: + : 0
29: + export MASTER_ADDR=node022
29: + MASTER_ADDR=node022
25: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
25: Run vars: id 2508 gpus 4 mparams ''
29: MASTER_ADDR=node022
29: + echo MASTER_ADDR=node022
29: + export MASTER_PORT=19002
29: + MASTER_PORT=19002
29: HOSTNAME=node022
29: + echo HOSTNAME=node022
29: + declare -a CMD
29: + [[ -n 1 ]]
29: + [[ 64 -gt 16 ]]
29: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
25: ++ date +%s
29: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
29: =0     --bert_config_path=/workspace/phase1/bert_config.json '
29: + '[' -n 1 ']'
29: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
29: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
29: + [[ 0 != 1 ]]
29: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
29: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
29: + [[ '' -ge 1 ]]
29: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
29: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
29: + [[ 0 != 0 ]]
29: + '[' '' = apiLog.sh ']'
29: + '[' '' = 1 ']'
29: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
29:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=12383'
29: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
29: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=12383
25: + START=1665667533
25: ++ date '+%Y-%m-%d %r'
25: + START_FMT='2022-10-13 08:25:33 AM'
25: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
25: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
25: + '[' '!' -z '' ']'
25: + '[' 0 -gt 0 ']'
25: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
25: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
25: + PHASES=("$PHASE1" "$PHASE2")
25: + export RANK=25
25: + RANK=25
25: + export WORLD_SIZE=64
25: + WORLD_SIZE=64
25: WORLD_SIZE=64
25: + echo WORLD_SIZE=64
25: ++ cut -d - -f1
25: ++ cut -d - -f2 -
25: ++ echo 'node[022-023,027-040]'
25: ++ tr -d '['
25: + export MASTER_ADDR=node022
25: + MASTER_ADDR=node022
25: MASTER_ADDR=node022
25: + echo MASTER_ADDR=node022
25: + export MASTER_PORT=19002
25: + MASTER_PORT=19002
25: + echo HOSTNAME=node022
25: HOSTNAME=node022
25: + declare -a CMD
25: + [[ -n 1 ]]
25: + [[ 64 -gt 16 ]]
25: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
25: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
25: =0     --bert_config_path=/workspace/phase1/bert_config.json '
25: + '[' -n 1 ']'
25: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
25: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
25: + [[ 0 != 1 ]]
25: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
25: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
25: + [[ '' -ge 1 ]]
25: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
25: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
25: + [[ 0 != 0 ]]
25: + '[' '' = apiLog.sh ']'
25: + '[' '' = 1 ']'
25: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
25:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=5718'
25: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
25: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=5718
 6: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
 6: ++ export BATCHSIZE=48
 6: ++ BATCHSIZE=48
 6: ++ export GRADIENT_STEPS=1
 6: ++ GRADIENT_STEPS=1
 6: ++ export LR=0.0020992
 6: ++ LR=0.0020992
 6: ++ export MAX_SAMPLES_TERMINATION=4500000
 6: ++ MAX_SAMPLES_TERMINATION=4500000
 6: ++ export MAX_STEPS=1059
 6: ++ MAX_STEPS=1059
 6: ++ export OPT_LAMB_BETA_1=0.60466
 6: ++ OPT_LAMB_BETA_1=0.60466
 6: ++ export OPT_LAMB_BETA_2=0.85437
 6: ++ OPT_LAMB_BETA_2=0.85437
 6: ++ export START_WARMUP_STEP=0
 6: ++ START_WARMUP_STEP=0
 6: ++ export WARMUP_PROPORTION=0.0
 6: ++ WARMUP_PROPORTION=0.0
 6: ++ export WEIGHT_DECAY_RATE=0.1
 6: ++ WEIGHT_DECAY_RATE=0.1
 6: ++ export INIT_LOSS_SCALE=4096.0
 6: ++ INIT_LOSS_SCALE=4096.0
 6: ++ export SBATCH_NETWORK=sharp
 6: ++ SBATCH_NETWORK=sharp
 6: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 6: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 6: ++ export PHASE=2
 6: ++ PHASE=2
 6: ++ export EVAL_ITER_START_SAMPLES=175000
 6: ++ EVAL_ITER_START_SAMPLES=175000
 6: ++ export EVAL_ITER_SAMPLES=175000
 6: ++ EVAL_ITER_SAMPLES=175000
 6: ++ export DGXNNODES=16
 6: ++ DGXNNODES=16
 6: +++ sed 's/^config_//'
 6: +++ sed 's/\.sh$//'
 6: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 6: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
 6: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 6: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
 6: ++ export WALLTIME_MINUTES=15
 6: ++ WALLTIME_MINUTES=15
 6: ++ export WALLTIME=20
 6: ++ WALLTIME=20
 6: ++ export DGXNGPU=4
 6: ++ DGXNGPU=4
 6: ++ export DGXSOCKETCORES=64
 6: ++ DGXSOCKETCORES=64
 6: ++ export DGXNSOCKET=2
 6: ++ DGXNSOCKET=2
 6: ++ export DGXHT=1
 6: ++ DGXHT=1
 6: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 6: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 6: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 6: ++ export MLPERF_SUBMISSION_ORG=Dell
 6: ++ MLPERF_SUBMISSION_ORG=Dell
 6: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 6: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
 6: ++ export OMP_NUM_THREADS=8
 6: ++ OMP_NUM_THREADS=8
 6: + ulimit -Sn 100000
 6: + '[' '' = 1 ']'
 6: + : 48
 6: + : 1
 6: + : 0.0020992
 6: + : 1059
 6: + : 2
 6: + : 2
 6: + : ''
 6: + : ''\'''\'''
 6: + : 9648
 6: + : 2508
 6: + : 1
 6: + : 4
 6: + : ''
 6: + : 0
 6: + : 175000
 6: + : 175000
 6: + : 4500000
 6: + : 0.60466
 6: + : 0.85437
 6: + : 0
 6: + : 0.720
 6: + : 0
 6: + : 0.0
 6: + : 0.0
 6: + : 0.1
 6: + : 0
 6: + : 0
 6: + : 0
 6: + : 0
 6: + : 0
 6: + : 0
 6: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
 6: Run vars: id 2508 gpus 4 mparams ''
 6: ++ date +%s
 6: + START=1665667533
 6: ++ date '+%Y-%m-%d %r'
 6: + START_FMT='2022-10-13 08:25:33 AM'
 6: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
 6: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
 6: + '[' '!' -z '' ']'
 6: + '[' 0 -gt 0 ']'
 6: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 6: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 6: + PHASES=("$PHASE1" "$PHASE2")
 6: + export RANK=6
 6: + RANK=6
 6: + export WORLD_SIZE=64
 6: + WORLD_SIZE=64
 6: WORLD_SIZE=64
 6: + echo WORLD_SIZE=64
 6: ++ cut -d - -f1
 6: ++ cut -d - -f2 -
 6: ++ tr -d '['
 6: ++ echo 'node[022-023,027-040]'
51: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
51: ++ export BATCHSIZE=48
51: ++ BATCHSIZE=48
51: ++ export GRADIENT_STEPS=1
51: ++ GRADIENT_STEPS=1
51: ++ export LR=0.0020992
51: ++ LR=0.0020992
51: ++ export MAX_SAMPLES_TERMINATION=4500000
51: ++ MAX_SAMPLES_TERMINATION=4500000
51: ++ export MAX_STEPS=1059
51: ++ MAX_STEPS=1059
51: ++ export OPT_LAMB_BETA_1=0.60466
51: ++ OPT_LAMB_BETA_1=0.60466
51: ++ export OPT_LAMB_BETA_2=0.85437
51: ++ OPT_LAMB_BETA_2=0.85437
51: ++ export START_WARMUP_STEP=0
51: ++ START_WARMUP_STEP=0
51: ++ export WARMUP_PROPORTION=0.0
51: ++ WARMUP_PROPORTION=0.0
51: ++ export WEIGHT_DECAY_RATE=0.1
51: ++ WEIGHT_DECAY_RATE=0.1
51: ++ export INIT_LOSS_SCALE=4096.0
51: ++ INIT_LOSS_SCALE=4096.0
51: ++ export SBATCH_NETWORK=sharp
51: ++ SBATCH_NETWORK=sharp
51: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
51: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
51: ++ export PHASE=2
51: ++ PHASE=2
51: ++ export EVAL_ITER_START_SAMPLES=175000
51: ++ EVAL_ITER_START_SAMPLES=175000
51: ++ export EVAL_ITER_SAMPLES=175000
51: ++ EVAL_ITER_SAMPLES=175000
51: ++ export DGXNNODES=16
51: ++ DGXNNODES=16
 6: + export MASTER_ADDR=node022
 6: + MASTER_ADDR=node022
 6: MASTER_ADDR=node022
 6: + echo MASTER_ADDR=node022
 6: + export MASTER_PORT=19002
 6: + MASTER_PORT=19002
 6: HOSTNAME=node022
 6: + echo HOSTNAME=node022
 6: + declare -a CMD
 6: + [[ -n 2 ]]
 6: + [[ 64 -gt 16 ]]
 6: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 6: =0     --bert_config_path=/workspace/phase1/bert_config.json '
 6: + '[' -n 2 ']'
 6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 6: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
 6: + [[ 0 != 1 ]]
51: +++ sed 's/^config_//'
 6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 6: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 6: + [[ '' -ge 1 ]]
 6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
 6: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 6: + [[ 0 != 0 ]]
 6: + '[' '' = apiLog.sh ']'
 6: + '[' '' = 1 ']'
51: +++ sed 's/\.sh$//'
 6: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
 6:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=9648'
51: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
 6: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
 6: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=9648
51: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
16: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
16: ++ export BATCHSIZE=48
16: ++ BATCHSIZE=48
51: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
51: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
16: ++ export GRADIENT_STEPS=1
16: ++ GRADIENT_STEPS=1
16: ++ export LR=0.0020992
16: ++ LR=0.0020992
16: ++ export MAX_SAMPLES_TERMINATION=4500000
16: ++ MAX_SAMPLES_TERMINATION=4500000
16: ++ export MAX_STEPS=1059
16: ++ MAX_STEPS=1059
16: ++ export OPT_LAMB_BETA_1=0.60466
51: ++ export WALLTIME_MINUTES=15
16: ++ OPT_LAMB_BETA_1=0.60466
51: ++ WALLTIME_MINUTES=15
16: ++ export OPT_LAMB_BETA_2=0.85437
16: ++ OPT_LAMB_BETA_2=0.85437
51: ++ export WALLTIME=20
51: ++ WALLTIME=20
16: ++ export START_WARMUP_STEP=0
16: ++ START_WARMUP_STEP=0
51: ++ export DGXNGPU=4
51: ++ DGXNGPU=4
16: ++ export WARMUP_PROPORTION=0.0
51: ++ export DGXSOCKETCORES=64
51: ++ DGXSOCKETCORES=64
16: ++ WARMUP_PROPORTION=0.0
51: ++ export DGXNSOCKET=2
51: ++ DGXNSOCKET=2
16: ++ export WEIGHT_DECAY_RATE=0.1
16: ++ WEIGHT_DECAY_RATE=0.1
51: ++ export DGXHT=1
51: ++ DGXHT=1
16: ++ export INIT_LOSS_SCALE=4096.0
16: ++ INIT_LOSS_SCALE=4096.0
51: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
51: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
16: ++ export SBATCH_NETWORK=sharp
16: ++ SBATCH_NETWORK=sharp
51: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
16: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
16: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
51: ++ export MLPERF_SUBMISSION_ORG=Dell
51: ++ MLPERF_SUBMISSION_ORG=Dell
16: ++ export PHASE=2
16: ++ PHASE=2
51: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
51: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
16: ++ export EVAL_ITER_START_SAMPLES=175000
16: ++ EVAL_ITER_START_SAMPLES=175000
51: ++ export OMP_NUM_THREADS=8
51: ++ OMP_NUM_THREADS=8
16: ++ export EVAL_ITER_SAMPLES=175000
16: ++ EVAL_ITER_SAMPLES=175000
51: + ulimit -Sn 100000
16: ++ export DGXNNODES=16
16: ++ DGXNNODES=16
51: + '[' '' = 1 ']'
51: + : 48
51: + : 1
51: + : 0.0020992
51: + : 1059
51: + : 2
51: + : 3
51: + : ''
51: + : ''\'''\'''
51: + : 32190
51: + : 2508
51: + : 12
51: + : 4
51: + : ''
51: + : 0
51: + : 175000
51: + : 175000
51: + : 4500000
51: + : 0.60466
51: Run vars: id 2508 gpus 4 mparams ''
51: + : 0.85437
51: + : 0
51: + : 0.720
51: + : 0
51: + : 0.0
51: + : 0.0
51: + : 0.1
51: + : 0
51: + : 0
51: + : 0
51: + : 0
51: + : 0
51: + : 0
51: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
51: ++ date +%s
16: +++ sed 's/^config_//'
16: +++ sed 's/\.sh$//'
16: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
60: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
60: ++ export BATCHSIZE=48
60: ++ BATCHSIZE=48
60: ++ export GRADIENT_STEPS=1
60: ++ GRADIENT_STEPS=1
60: ++ export LR=0.0020992
60: ++ LR=0.0020992
60: ++ export MAX_SAMPLES_TERMINATION=4500000
60: ++ MAX_SAMPLES_TERMINATION=4500000
60: ++ export MAX_STEPS=1059
60: ++ MAX_STEPS=1059
60: ++ export OPT_LAMB_BETA_1=0.60466
60: ++ OPT_LAMB_BETA_1=0.60466
60: ++ export OPT_LAMB_BETA_2=0.85437
60: ++ OPT_LAMB_BETA_2=0.85437
60: ++ export START_WARMUP_STEP=0
60: ++ START_WARMUP_STEP=0
60: ++ export WARMUP_PROPORTION=0.0
60: ++ WARMUP_PROPORTION=0.0
60: ++ export WEIGHT_DECAY_RATE=0.1
60: ++ WEIGHT_DECAY_RATE=0.1
60: ++ export INIT_LOSS_SCALE=4096.0
60: ++ INIT_LOSS_SCALE=4096.0
60: ++ export SBATCH_NETWORK=sharp
60: ++ SBATCH_NETWORK=sharp
60: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
60: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
60: ++ export PHASE=2
60: ++ PHASE=2
60: ++ export EVAL_ITER_START_SAMPLES=175000
60: ++ EVAL_ITER_START_SAMPLES=175000
60: ++ export EVAL_ITER_SAMPLES=175000
60: ++ EVAL_ITER_SAMPLES=175000
60: ++ export DGXNNODES=16
60: ++ DGXNNODES=16
51: + START=1665667533
16: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
51: ++ date '+%Y-%m-%d %r'
60: +++ sed 's/^config_//'
60: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
60: +++ sed 's/\.sh$//'
51: + START_FMT='2022-10-13 08:25:33 AM'
51: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
51: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
51: + '[' '!' -z '' ']'
51: + '[' 0 -gt 0 ']'
51: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
51: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
51: + PHASES=("$PHASE1" "$PHASE2")
51: + export RANK=51
51: + RANK=51
51: + export WORLD_SIZE=64
51: + WORLD_SIZE=64
51: WORLD_SIZE=64
51: + echo WORLD_SIZE=64
51: ++ cut -d - -f1
51: ++ cut -d - -f2 -
51: ++ echo 'node[022-023,027-040]'
51: ++ tr -d '['
16: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
60: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
16: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
16: ++ export WALLTIME_MINUTES=15
16: ++ WALLTIME_MINUTES=15
16: ++ export WALLTIME=20
16: ++ WALLTIME=20
16: ++ export DGXNGPU=4
16: ++ DGXNGPU=4
16: ++ export DGXSOCKETCORES=64
16: ++ DGXSOCKETCORES=64
16: ++ export DGXNSOCKET=2
16: ++ DGXNSOCKET=2
16: ++ export DGXHT=1
16: ++ DGXHT=1
16: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
16: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
16: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
16: ++ export MLPERF_SUBMISSION_ORG=Dell
16: ++ MLPERF_SUBMISSION_ORG=Dell
16: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
16: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
16: ++ export OMP_NUM_THREADS=8
16: ++ OMP_NUM_THREADS=8
16: + ulimit -Sn 100000
16: + '[' '' = 1 ']'
16: + : 48
16: + : 1
16: + : 0.0020992
16: + : 1059
16: + : 2
16: + : 0
16: + : ''
16: + : ''\'''\'''
16: + : 23551
16: + : 2508
16: + : 4
16: + : 4
16: + : ''
16: + : 0
16: + : 175000
16: + : 175000
16: + : 4500000
16: + : 0.60466
16: + : 0.85437
16: + : 0
16: + : 0.720
16: + : 0
16: + : 0.0
16: + : 0.0
16: + : 0.1
16: + : 0
16: + : 0
16: + : 0
16: + : 0
16: + : 0
16: + : 0
16: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
16: Run vars: id 2508 gpus 4 mparams ''
16: ++ date +%s
37: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
37: ++ export BATCHSIZE=48
37: ++ BATCHSIZE=48
37: ++ export GRADIENT_STEPS=1
37: ++ GRADIENT_STEPS=1
37: ++ export LR=0.0020992
37: ++ LR=0.0020992
37: ++ export MAX_SAMPLES_TERMINATION=4500000
37: ++ MAX_SAMPLES_TERMINATION=4500000
37: ++ export MAX_STEPS=1059
37: ++ MAX_STEPS=1059
37: ++ export OPT_LAMB_BETA_1=0.60466
37: ++ OPT_LAMB_BETA_1=0.60466
37: ++ export OPT_LAMB_BETA_2=0.85437
37: ++ OPT_LAMB_BETA_2=0.85437
37: ++ export START_WARMUP_STEP=0
37: ++ START_WARMUP_STEP=0
37: ++ export WARMUP_PROPORTION=0.0
37: ++ WARMUP_PROPORTION=0.0
37: ++ export WEIGHT_DECAY_RATE=0.1
37: ++ WEIGHT_DECAY_RATE=0.1
37: ++ export INIT_LOSS_SCALE=4096.0
37: ++ INIT_LOSS_SCALE=4096.0
37: ++ export SBATCH_NETWORK=sharp
37: ++ SBATCH_NETWORK=sharp
37: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
37: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
37: ++ export PHASE=2
37: ++ PHASE=2
37: ++ export EVAL_ITER_START_SAMPLES=175000
37: ++ EVAL_ITER_START_SAMPLES=175000
37: ++ export EVAL_ITER_SAMPLES=175000
37: ++ EVAL_ITER_SAMPLES=175000
37: ++ export DGXNNODES=16
37: ++ DGXNNODES=16
42: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
51: + export MASTER_ADDR=node022
51: + MASTER_ADDR=node022
42: ++ export BATCHSIZE=48
42: ++ BATCHSIZE=48
51: MASTER_ADDR=node022
51: + echo MASTER_ADDR=node022
51: + export MASTER_PORT=19002
51: + MASTER_PORT=19002
51: + echo HOSTNAME=node022
51: HOSTNAME=node022
51: + declare -a CMD
51: + [[ -n 3 ]]
51: + [[ 64 -gt 16 ]]
51: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
42: ++ export GRADIENT_STEPS=1
42: ++ GRADIENT_STEPS=1
42: ++ export LR=0.0020992
42: ++ LR=0.0020992
42: ++ export MAX_SAMPLES_TERMINATION=4500000
42: ++ MAX_SAMPLES_TERMINATION=4500000
42: ++ export MAX_STEPS=1059
42: ++ MAX_STEPS=1059
42: ++ export OPT_LAMB_BETA_1=0.60466
42: ++ OPT_LAMB_BETA_1=0.60466
42: ++ export OPT_LAMB_BETA_2=0.85437
42: ++ OPT_LAMB_BETA_2=0.85437
42: ++ export START_WARMUP_STEP=0
42: ++ START_WARMUP_STEP=0
42: ++ export WARMUP_PROPORTION=0.0
42: ++ WARMUP_PROPORTION=0.0
42: ++ export WEIGHT_DECAY_RATE=0.1
42: ++ WEIGHT_DECAY_RATE=0.1
42: ++ export INIT_LOSS_SCALE=4096.0
42: ++ INIT_LOSS_SCALE=4096.0
42: ++ export SBATCH_NETWORK=sharp
42: ++ SBATCH_NETWORK=sharp
51: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
42: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
42: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
37: +++ sed 's/^config_//'
51: =0     --bert_config_path=/workspace/phase1/bert_config.json '
42: ++ export PHASE=2
42: ++ PHASE=2
42: ++ export EVAL_ITER_START_SAMPLES=175000
42: ++ EVAL_ITER_START_SAMPLES=175000
42: ++ export EVAL_ITER_SAMPLES=175000
42: ++ EVAL_ITER_SAMPLES=175000
42: ++ export DGXNNODES=16
42: ++ DGXNNODES=16
51: + '[' -n 3 ']'
51: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
51: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
51: + [[ 0 != 1 ]]
37: +++ sed 's/\.sh$//'
51: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
51: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
51: + [[ '' -ge 1 ]]
51: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
51: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
51: + [[ 0 != 0 ]]
37: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
51: + '[' '' = apiLog.sh ']'
51: + '[' '' = 1 ']'
51: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
51:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=32190'
51: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
51: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=32190
42: +++ sed 's/^config_//'
42: +++ sed 's/\.sh$//'
42: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
60: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
60: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
60: ++ export WALLTIME_MINUTES=15
60: ++ WALLTIME_MINUTES=15
60: ++ export WALLTIME=20
60: ++ WALLTIME=20
60: ++ export DGXNGPU=4
60: ++ DGXNGPU=4
60: ++ export DGXSOCKETCORES=64
60: ++ DGXSOCKETCORES=64
60: ++ export DGXNSOCKET=2
60: ++ DGXNSOCKET=2
60: ++ export DGXHT=1
60: ++ DGXHT=1
60: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
60: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
60: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
60: ++ export MLPERF_SUBMISSION_ORG=Dell
60: ++ MLPERF_SUBMISSION_ORG=Dell
60: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
60: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
60: ++ export OMP_NUM_THREADS=8
60: ++ OMP_NUM_THREADS=8
60: + ulimit -Sn 100000
60: + '[' '' = 1 ']'
60: + : 48
60: + : 1
60: + : 0.0020992
60: + : 1059
60: + : 2
60: + : 0
60: + : ''
60: + : ''\'''\'''
60: + : 13450
16: + START=1665667533
60: + : 2508
60: + : 15
60: + : 4
60: + : ''
60: + : 0
60: + : 175000
60: + : 175000
60: + : 4500000
60: + : 0.60466
60: + : 0.85437
60: + : 0
60: + : 0.720
60: + : 0
60: + : 0.0
60: + : 0.0
60: + : 0.1
60: + : 0
60: + : 0
60: + : 0
60: + : 0
60: + : 0
60: + : 0
60: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
60: Run vars: id 2508 gpus 4 mparams ''
16: ++ date '+%Y-%m-%d %r'
60: ++ date +%s
20: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
20: ++ export BATCHSIZE=48
20: ++ BATCHSIZE=48
20: ++ export GRADIENT_STEPS=1
20: ++ GRADIENT_STEPS=1
20: ++ export LR=0.0020992
20: ++ LR=0.0020992
20: ++ export MAX_SAMPLES_TERMINATION=4500000
20: ++ MAX_SAMPLES_TERMINATION=4500000
20: ++ export MAX_STEPS=1059
20: ++ MAX_STEPS=1059
20: ++ export OPT_LAMB_BETA_1=0.60466
20: ++ OPT_LAMB_BETA_1=0.60466
20: ++ export OPT_LAMB_BETA_2=0.85437
20: ++ OPT_LAMB_BETA_2=0.85437
20: ++ export START_WARMUP_STEP=0
20: ++ START_WARMUP_STEP=0
20: ++ export WARMUP_PROPORTION=0.0
20: ++ WARMUP_PROPORTION=0.0
20: ++ export WEIGHT_DECAY_RATE=0.1
20: ++ WEIGHT_DECAY_RATE=0.1
20: ++ export INIT_LOSS_SCALE=4096.0
20: ++ INIT_LOSS_SCALE=4096.0
20: ++ export SBATCH_NETWORK=sharp
20: ++ SBATCH_NETWORK=sharp
20: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
20: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
20: ++ export PHASE=2
20: ++ PHASE=2
20: ++ export EVAL_ITER_START_SAMPLES=175000
20: ++ EVAL_ITER_START_SAMPLES=175000
20: ++ export EVAL_ITER_SAMPLES=175000
20: ++ EVAL_ITER_SAMPLES=175000
20: ++ export DGXNNODES=16
20: ++ DGXNNODES=16
16: + START_FMT='2022-10-13 08:25:33 AM'
16: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
16: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
16: + '[' '!' -z '' ']'
16: + '[' 0 -gt 0 ']'
37: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
16: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
16: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
16: + PHASES=("$PHASE1" "$PHASE2")
16: + export RANK=16
16: + RANK=16
16: + export WORLD_SIZE=64
16: + WORLD_SIZE=64
16: + echo WORLD_SIZE=64
16: WORLD_SIZE=64
20: +++ sed 's/^config_//'
42: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
20: +++ sed 's/\.sh$//'
20: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
16: ++ cut -d - -f1
16: ++ cut -d - -f2 -
16: ++ tr -d '['
16: ++ echo 'node[022-023,027-040]'
60: + START=1665667533
60: ++ date '+%Y-%m-%d %r'
60: + START_FMT='2022-10-13 08:25:33 AM'
60: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
60: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
60: + '[' '!' -z '' ']'
60: + '[' 0 -gt 0 ']'
60: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
60: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
60: + PHASES=("$PHASE1" "$PHASE2")
60: + export RANK=60
60: + RANK=60
60: + export WORLD_SIZE=64
60: + WORLD_SIZE=64
60: WORLD_SIZE=64
60: + echo WORLD_SIZE=64
37: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
37: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
37: ++ export WALLTIME_MINUTES=15
37: ++ WALLTIME_MINUTES=15
37: ++ export WALLTIME=20
37: ++ WALLTIME=20
37: ++ export DGXNGPU=4
37: ++ DGXNGPU=4
37: ++ export DGXSOCKETCORES=64
37: ++ DGXSOCKETCORES=64
37: ++ export DGXNSOCKET=2
37: ++ DGXNSOCKET=2
37: ++ export DGXHT=1
37: ++ DGXHT=1
45: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
37: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
37: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
37: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
37: ++ export MLPERF_SUBMISSION_ORG=Dell
37: ++ MLPERF_SUBMISSION_ORG=Dell
20: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
37: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
37: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
37: ++ export OMP_NUM_THREADS=8
37: ++ OMP_NUM_THREADS=8
37: + ulimit -Sn 100000
37: + '[' '' = 1 ']'
37: + : 48
37: + : 1
37: + : 0.0020992
37: + : 1059
37: + : 2
42: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
42: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
37: + : 1
45: ++ export BATCHSIZE=48
45: ++ BATCHSIZE=48
37: + : ''
37: + : ''\'''\'''
37: + : 21550
37: + : 2508
37: + : 9
37: + : 4
37: + : ''
37: + : 0
37: + : 175000
37: + : 175000
37: + : 4500000
37: + : 0.60466
60: ++ cut -d - -f1
42: ++ export WALLTIME_MINUTES=15
37: + : 0.85437
45: ++ export GRADIENT_STEPS=1
45: ++ GRADIENT_STEPS=1
42: ++ WALLTIME_MINUTES=15
37: + : 0
45: ++ export LR=0.0020992
45: ++ LR=0.0020992
42: ++ export WALLTIME=20
42: ++ WALLTIME=20
37: + : 0.720
45: ++ export MAX_SAMPLES_TERMINATION=4500000
45: ++ MAX_SAMPLES_TERMINATION=4500000
42: ++ export DGXNGPU=4
42: ++ DGXNGPU=4
37: + : 0
45: ++ export MAX_STEPS=1059
45: ++ MAX_STEPS=1059
42: ++ export DGXSOCKETCORES=64
37: Run vars: id 2508 gpus 4 mparams ''
37: + : 0.0
45: ++ export OPT_LAMB_BETA_1=0.60466
42: ++ DGXSOCKETCORES=64
37: + : 0.0
45: ++ OPT_LAMB_BETA_1=0.60466
42: ++ export DGXNSOCKET=2
42: ++ DGXNSOCKET=2
37: + : 0.1
45: ++ export OPT_LAMB_BETA_2=0.85437
45: ++ OPT_LAMB_BETA_2=0.85437
42: ++ export DGXHT=1
42: ++ DGXHT=1
37: + : 0
45: ++ export START_WARMUP_STEP=0
45: ++ START_WARMUP_STEP=0
42: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
42: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
37: + : 0
45: ++ export WARMUP_PROPORTION=0.0
45: ++ WARMUP_PROPORTION=0.0
42: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
37: + : 0
45: ++ export WEIGHT_DECAY_RATE=0.1
45: ++ WEIGHT_DECAY_RATE=0.1
37: + : 0
45: ++ export INIT_LOSS_SCALE=4096.0
45: ++ INIT_LOSS_SCALE=4096.0
60: ++ cut -d - -f2 -
37: + : 0
45: ++ export SBATCH_NETWORK=sharp
45: ++ SBATCH_NETWORK=sharp
37: + : 0
45: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
45: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
42: ++ export MLPERF_SUBMISSION_ORG=Dell
42: ++ MLPERF_SUBMISSION_ORG=Dell
37: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
45: ++ export PHASE=2
45: ++ PHASE=2
42: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
45: ++ export EVAL_ITER_START_SAMPLES=175000
45: ++ EVAL_ITER_START_SAMPLES=175000
42: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
45: ++ export EVAL_ITER_SAMPLES=175000
45: ++ EVAL_ITER_SAMPLES=175000
42: ++ export OMP_NUM_THREADS=8
42: ++ OMP_NUM_THREADS=8
45: ++ export DGXNNODES=16
45: ++ DGXNNODES=16
42: + ulimit -Sn 100000
42: + '[' '' = 1 ']'
42: + : 48
42: + : 1
42: + : 0.0020992
42: + : 1059
60: ++ tr -d '['
42: + : 2
16: MASTER_ADDR=node022
42: + : 2
42: + : ''
16: HOSTNAME=node022
42: + : ''\'''\'''
42: + : 31764
42: + : 2508
42: Run vars: id 2508 gpus 4 mparams ''
42: + : 10
42: + : 4
42: + : ''
42: + : 0
16: + export MASTER_ADDR=node022
16: + MASTER_ADDR=node022
42: + : 175000
42: + : 175000
42: + : 4500000
42: + : 0.60466
42: + : 0.85437
42: + : 0
42: + : 0.720
42: + : 0
37: ++ date +%s
42: + : 0.0
42: + : 0.0
42: + : 0.1
42: + : 0
42: + : 0
42: + : 0
42: + : 0
16: + echo MASTER_ADDR=node022
16: + export MASTER_PORT=19002
16: + MASTER_PORT=19002
42: + : 0
42: + : 0
16: + echo HOSTNAME=node022
42: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
16: + declare -a CMD
16: + [[ -n 0 ]]
16: + [[ 64 -gt 16 ]]
16: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
16: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
16: =0     --bert_config_path=/workspace/phase1/bert_config.json '
16: + '[' -n 0 ']'
16: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
16: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
42: ++ date +%s
16: + [[ 0 != 1 ]]
16: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
16: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
16: + [[ '' -ge 1 ]]
16: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
16: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
16: + [[ 0 != 0 ]]
16: + '[' '' = apiLog.sh ']'
16: + '[' '' = 1 ']'
16: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
16:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=23551'
60: ++ echo 'node[022-023,027-040]'
16: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
45: +++ sed 's/^config_//'
16: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=23551
45: +++ sed 's/\.sh$//'
45: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
20: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
20: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
20: ++ export WALLTIME_MINUTES=15
20: ++ WALLTIME_MINUTES=15
20: ++ export WALLTIME=20
20: ++ WALLTIME=20
20: ++ export DGXNGPU=4
20: ++ DGXNGPU=4
20: ++ export DGXSOCKETCORES=64
20: ++ DGXSOCKETCORES=64
20: ++ export DGXNSOCKET=2
20: ++ DGXNSOCKET=2
20: ++ export DGXHT=1
20: ++ DGXHT=1
20: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
20: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
20: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
20: ++ export MLPERF_SUBMISSION_ORG=Dell
20: ++ MLPERF_SUBMISSION_ORG=Dell
20: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
20: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
20: ++ export OMP_NUM_THREADS=8
20: ++ OMP_NUM_THREADS=8
20: + ulimit -Sn 100000
20: + '[' '' = 1 ']'
20: + : 48
20: + : 1
20: + : 0.0020992
20: + : 1059
20: + : 2
20: + : 0
20: + : ''
20: + : ''\'''\'''
20: + : 27432
20: + : 2508
20: + : 5
20: + : 4
20: + : ''
20: + : 0
20: + : 175000
20: + : 175000
20: + : 4500000
20: + : 0.60466
20: + : 0.85437
20: + : 0
20: + : 0.720
20: + : 0
20: + : 0.0
20: + : 0.0
20: + : 0.1
20: + : 0
20: + : 0
42: + START=1665667533
20: + : 0
20: + : 0
20: + : 0
20: + : 0
20: Run vars: id 2508 gpus 4 mparams ''
20: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
60: + export MASTER_ADDR=node022
60: + MASTER_ADDR=node022
37: + START=1665667533
60: MASTER_ADDR=node022
20: ++ date +%s
60: + echo MASTER_ADDR=node022
60: + export MASTER_PORT=19002
60: + MASTER_PORT=19002
60: HOSTNAME=node022
42: ++ date '+%Y-%m-%d %r'
60: + echo HOSTNAME=node022
60: + declare -a CMD
60: + [[ -n 0 ]]
60: + [[ 64 -gt 16 ]]
60: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
37: ++ date '+%Y-%m-%d %r'
45: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
60: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
60: =0     --bert_config_path=/workspace/phase1/bert_config.json '
60: + '[' -n 0 ']'
60: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
60: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
60: + [[ 0 != 1 ]]
60: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
60: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
60: + [[ '' -ge 1 ]]
60: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
60: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
60: + [[ 0 != 0 ]]
60: + '[' '' = apiLog.sh ']'
60: + '[' '' = 1 ']'
60: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
60:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=13450'
60: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
60: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=13450
37: + START_FMT='2022-10-13 08:25:33 AM'
37: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
37: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
37: + '[' '!' -z '' ']'
37: + '[' 0 -gt 0 ']'
37: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
42: + START_FMT='2022-10-13 08:25:33 AM'
37: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
37: + PHASES=("$PHASE1" "$PHASE2")
37: + export RANK=37
37: + RANK=37
37: + export WORLD_SIZE=64
37: + WORLD_SIZE=64
37: WORLD_SIZE=64
37: + echo WORLD_SIZE=64
42: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
42: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
42: + '[' '!' -z '' ']'
42: + '[' 0 -gt 0 ']'
42: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
42: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
42: + PHASES=("$PHASE1" "$PHASE2")
42: + export RANK=42
42: + RANK=42
42: + export WORLD_SIZE=64
42: + WORLD_SIZE=64
42: WORLD_SIZE=64
42: + echo WORLD_SIZE=64
37: ++ cut -d - -f1
12: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
37: ++ echo 'node[022-023,027-040]'
37: ++ cut -d - -f2 -
12: ++ export BATCHSIZE=48
12: ++ BATCHSIZE=48
42: ++ cut -d - -f1
37: ++ tr -d '['
12: ++ export GRADIENT_STEPS=1
12: ++ GRADIENT_STEPS=1
12: ++ export LR=0.0020992
12: ++ LR=0.0020992
12: ++ export MAX_SAMPLES_TERMINATION=4500000
12: ++ MAX_SAMPLES_TERMINATION=4500000
12: ++ export MAX_STEPS=1059
12: ++ MAX_STEPS=1059
12: ++ export OPT_LAMB_BETA_1=0.60466
12: ++ OPT_LAMB_BETA_1=0.60466
42: ++ cut -d - -f2 -
20: + START=1665667533
12: ++ export OPT_LAMB_BETA_2=0.85437
12: ++ OPT_LAMB_BETA_2=0.85437
12: ++ export START_WARMUP_STEP=0
12: ++ START_WARMUP_STEP=0
12: ++ export WARMUP_PROPORTION=0.0
12: ++ WARMUP_PROPORTION=0.0
12: ++ export WEIGHT_DECAY_RATE=0.1
12: ++ WEIGHT_DECAY_RATE=0.1
12: ++ export INIT_LOSS_SCALE=4096.0
12: ++ INIT_LOSS_SCALE=4096.0
12: ++ export SBATCH_NETWORK=sharp
12: ++ SBATCH_NETWORK=sharp
12: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
12: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
12: ++ export PHASE=2
12: ++ PHASE=2
12: ++ export EVAL_ITER_START_SAMPLES=175000
12: ++ EVAL_ITER_START_SAMPLES=175000
42: ++ tr -d '['
12: ++ export EVAL_ITER_SAMPLES=175000
12: ++ EVAL_ITER_SAMPLES=175000
12: ++ export DGXNNODES=16
12: ++ DGXNNODES=16
42: ++ echo 'node[022-023,027-040]'
45: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
45: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
20: ++ date '+%Y-%m-%d %r'
45: ++ export WALLTIME_MINUTES=15
45: ++ WALLTIME_MINUTES=15
45: ++ export WALLTIME=20
45: ++ WALLTIME=20
45: ++ export DGXNGPU=4
45: ++ DGXNGPU=4
45: ++ export DGXSOCKETCORES=64
45: ++ DGXSOCKETCORES=64
45: ++ export DGXNSOCKET=2
45: ++ DGXNSOCKET=2
45: ++ export DGXHT=1
45: ++ DGXHT=1
45: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
45: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
45: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
45: ++ export MLPERF_SUBMISSION_ORG=Dell
45: ++ MLPERF_SUBMISSION_ORG=Dell
45: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
45: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
45: ++ export OMP_NUM_THREADS=8
45: ++ OMP_NUM_THREADS=8
45: + ulimit -Sn 100000
45: + '[' '' = 1 ']'
45: + : 48
45: + : 1
45: + : 0.0020992
45: + : 1059
45: + : 2
45: + : 1
45: + : ''
45: + : ''\'''\'''
45: + : 18733
45: + : 2508
45: + : 11
45: + : 4
12: +++ sed 's/\.sh$//'
12: +++ sed 's/^config_//'
45: + : ''
45: + : 0
45: + : 175000
45: + : 175000
45: + : 4500000
45: + : 0.60466
45: + : 0.85437
45: + : 0
45: + : 0.720
45: + : 0
45: + : 0.0
45: + : 0.0
12: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
45: + : 0.1
45: + : 0
45: + : 0
45: + : 0
45: + : 0
45: + : 0
45: + : 0
45: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
45: Run vars: id 2508 gpus 4 mparams ''
45: ++ date +%s
20: + START_FMT='2022-10-13 08:25:33 AM'
20: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
20: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
20: + '[' '!' -z '' ']'
20: + '[' 0 -gt 0 ']'
20: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
20: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
20: + PHASES=("$PHASE1" "$PHASE2")
20: + export RANK=20
20: + RANK=20
20: + export WORLD_SIZE=64
20: + WORLD_SIZE=64
20: WORLD_SIZE=64
20: + echo WORLD_SIZE=64
20: ++ cut -d - -f1
20: ++ cut -d - -f2 -
20: ++ tr -d '['
37: + export MASTER_ADDR=node022
20: ++ echo 'node[022-023,027-040]'
37: + MASTER_ADDR=node022
37: + echo MASTER_ADDR=node022
37: MASTER_ADDR=node022
37: + export MASTER_PORT=19002
37: + MASTER_PORT=19002
37: HOSTNAME=node022
37: + echo HOSTNAME=node022
37: + declare -a CMD
37: + [[ -n 1 ]]
37: + [[ 64 -gt 16 ]]
37: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
37: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
37: =0     --bert_config_path=/workspace/phase1/bert_config.json '
37: + '[' -n 1 ']'
37: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
37: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
37: + [[ 0 != 1 ]]
42: + export MASTER_ADDR=node022
42: + MASTER_ADDR=node022
37: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
37: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
37: + [[ '' -ge 1 ]]
37: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
37: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
42: MASTER_ADDR=node022
37: + [[ 0 != 0 ]]
42: + echo MASTER_ADDR=node022
42: + export MASTER_PORT=19002
42: + MASTER_PORT=19002
42: HOSTNAME=node022
37: + '[' '' = apiLog.sh ']'
42: + echo HOSTNAME=node022
42: + declare -a CMD
42: + [[ -n 2 ]]
42: + [[ 64 -gt 16 ]]
42: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
37: + '[' '' = 1 ']'
37: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
37:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=21550'
42: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
12: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
42: =0     --bert_config_path=/workspace/phase1/bert_config.json '
37: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
42: + '[' -n 2 ']'
37: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=21550
42: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
42: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
42: + [[ 0 != 1 ]]
42: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
42: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
42: + [[ '' -ge 1 ]]
42: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
42: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
42: + [[ 0 != 0 ]]
42: + '[' '' = apiLog.sh ']'
42: + '[' '' = 1 ']'
42: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
42:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=31764'
42: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
42: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=31764
45: + START=1665667533
45: ++ date '+%Y-%m-%d %r'
20: + export MASTER_ADDR=node022
20: + MASTER_ADDR=node022
45: + START_FMT='2022-10-13 08:25:33 AM'
20: + echo MASTER_ADDR=node022
20: MASTER_ADDR=node022
20: + export MASTER_PORT=19002
20: + MASTER_PORT=19002
20: HOSTNAME=node022
20: + echo HOSTNAME=node022
20: + declare -a CMD
45: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
45: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
45: + '[' '!' -z '' ']'
45: + '[' 0 -gt 0 ']'
20: + [[ -n 0 ]]
20: + [[ 64 -gt 16 ]]
20: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
45: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
45: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
45: + PHASES=("$PHASE1" "$PHASE2")
20: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
20: =0     --bert_config_path=/workspace/phase1/bert_config.json '
20: + '[' -n 0 ']'
45: + export RANK=45
45: + RANK=45
45: + export WORLD_SIZE=64
45: + WORLD_SIZE=64
45: WORLD_SIZE=64
45: + echo WORLD_SIZE=64
20: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
20: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
20: + [[ 0 != 1 ]]
20: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
20: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
20: + [[ '' -ge 1 ]]
20: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
20: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
20: + [[ 0 != 0 ]]
20: + '[' '' = apiLog.sh ']'
20: + '[' '' = 1 ']'
20: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
20:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=27432'
12: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
12: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
20: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
12: ++ export WALLTIME_MINUTES=15
12: ++ WALLTIME_MINUTES=15
12: ++ export WALLTIME=20
12: ++ WALLTIME=20
12: ++ export DGXNGPU=4
12: ++ DGXNGPU=4
12: ++ export DGXSOCKETCORES=64
12: ++ DGXSOCKETCORES=64
20: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=27432
12: ++ export DGXNSOCKET=2
12: ++ DGXNSOCKET=2
12: ++ export DGXHT=1
12: ++ DGXHT=1
12: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
12: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
12: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
12: ++ export MLPERF_SUBMISSION_ORG=Dell
12: ++ MLPERF_SUBMISSION_ORG=Dell
12: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
12: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
12: ++ export OMP_NUM_THREADS=8
12: ++ OMP_NUM_THREADS=8
12: + ulimit -Sn 100000
12: + '[' '' = 1 ']'
12: + : 48
12: + : 1
12: + : 0.0020992
12: + : 1059
12: + : 2
12: + : 0
45: ++ cut -d - -f1
12: + : ''
12: + : ''\'''\'''
12: + : 13629
12: + : 2508
12: + : 3
12: + : 4
12: + : ''
12: + : 0
12: + : 175000
45: ++ echo 'node[022-023,027-040]'
12: + : 175000
12: + : 4500000
12: + : 0.60466
12: + : 0.85437
12: + : 0
12: + : 0.720
12: + : 0
12: + : 0.0
12: + : 0.0
12: + : 0.1
45: ++ cut -d - -f2 -
12: + : 0
12: + : 0
45: ++ tr -d '['
12: + : 0
12: + : 0
12: + : 0
12: + : 0
12: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
12: Run vars: id 2508 gpus 4 mparams ''
12: ++ date +%s
12: + START=1665667533
12: ++ date '+%Y-%m-%d %r'
45: + export MASTER_ADDR=node022
45: + MASTER_ADDR=node022
45: MASTER_ADDR=node022
45: + echo MASTER_ADDR=node022
45: + export MASTER_PORT=19002
45: + MASTER_PORT=19002
45: HOSTNAME=node022
45: + echo HOSTNAME=node022
45: + declare -a CMD
45: + [[ -n 1 ]]
45: + [[ 64 -gt 16 ]]
45: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
45: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
12: + START_FMT='2022-10-13 08:25:33 AM'
45: =0     --bert_config_path=/workspace/phase1/bert_config.json '
45: + '[' -n 1 ']'
45: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
45: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
45: + [[ 0 != 1 ]]
45: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
45: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
45: + [[ '' -ge 1 ]]
12: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
12: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
12: + '[' '!' -z '' ']'
12: + '[' 0 -gt 0 ']'
45: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
45: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
45: + [[ 0 != 0 ]]
45: + '[' '' = apiLog.sh ']'
45: + '[' '' = 1 ']'
12: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
12: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
45: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
12: + PHASES=("$PHASE1" "$PHASE2")
45:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=18733'
12: WORLD_SIZE=64
12: + export RANK=12
12: + RANK=12
12: + export WORLD_SIZE=64
12: + WORLD_SIZE=64
12: + echo WORLD_SIZE=64
45: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
45: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=18733
12: ++ cut -d - -f1
12: ++ echo 'node[022-023,027-040]'
12: ++ cut -d - -f2 -
12: ++ tr -d '['
12: + export MASTER_ADDR=node022
12: + MASTER_ADDR=node022
12: + echo MASTER_ADDR=node022
12: MASTER_ADDR=node022
12: + export MASTER_PORT=19002
12: + MASTER_PORT=19002
12: HOSTNAME=node022
12: + echo HOSTNAME=node022
12: + declare -a CMD
12: + [[ -n 0 ]]
12: + [[ 64 -gt 16 ]]
12: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
12: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
12: =0     --bert_config_path=/workspace/phase1/bert_config.json '
12: + '[' -n 0 ']'
12: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
12: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
12: + [[ 0 != 1 ]]
12: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
12: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
12: + [[ '' -ge 1 ]]
12: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
12: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
12: + [[ 0 != 0 ]]
12: + '[' '' = apiLog.sh ']'
12: + '[' '' = 1 ']'
61: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
12: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
12:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=13629'
12: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
61: ++ export BATCHSIZE=48
12: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=13629
61: ++ BATCHSIZE=48
61: ++ export GRADIENT_STEPS=1
61: ++ GRADIENT_STEPS=1
61: ++ export LR=0.0020992
61: ++ LR=0.0020992
61: ++ export MAX_SAMPLES_TERMINATION=4500000
61: ++ MAX_SAMPLES_TERMINATION=4500000
61: ++ export MAX_STEPS=1059
61: ++ MAX_STEPS=1059
61: ++ export OPT_LAMB_BETA_1=0.60466
61: ++ OPT_LAMB_BETA_1=0.60466
61: ++ export OPT_LAMB_BETA_2=0.85437
61: ++ OPT_LAMB_BETA_2=0.85437
61: ++ export START_WARMUP_STEP=0
61: ++ START_WARMUP_STEP=0
61: ++ export WARMUP_PROPORTION=0.0
61: ++ WARMUP_PROPORTION=0.0
61: ++ export WEIGHT_DECAY_RATE=0.1
61: ++ WEIGHT_DECAY_RATE=0.1
61: ++ export INIT_LOSS_SCALE=4096.0
61: ++ INIT_LOSS_SCALE=4096.0
61: ++ export SBATCH_NETWORK=sharp
61: ++ SBATCH_NETWORK=sharp
61: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
61: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
61: ++ export PHASE=2
61: ++ PHASE=2
61: ++ export EVAL_ITER_START_SAMPLES=175000
61: ++ EVAL_ITER_START_SAMPLES=175000
61: ++ export EVAL_ITER_SAMPLES=175000
61: ++ EVAL_ITER_SAMPLES=175000
61: ++ export DGXNNODES=16
61: ++ DGXNNODES=16
61: +++ sed 's/^config_//'
61: +++ sed 's/\.sh$//'
61: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
61: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
61: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
61: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
61: ++ export WALLTIME_MINUTES=15
61: ++ WALLTIME_MINUTES=15
61: ++ export WALLTIME=20
61: ++ WALLTIME=20
61: ++ export DGXNGPU=4
61: ++ DGXNGPU=4
61: ++ export DGXSOCKETCORES=64
61: ++ DGXSOCKETCORES=64
61: ++ export DGXNSOCKET=2
61: ++ DGXNSOCKET=2
61: ++ export DGXHT=1
61: ++ DGXHT=1
61: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
61: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
61: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
61: ++ export MLPERF_SUBMISSION_ORG=Dell
61: ++ MLPERF_SUBMISSION_ORG=Dell
61: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
61: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
61: ++ export OMP_NUM_THREADS=8
61: ++ OMP_NUM_THREADS=8
61: + ulimit -Sn 100000
61: + '[' '' = 1 ']'
61: + : 48
61: + : 1
61: + : 0.0020992
61: + : 1059
61: + : 2
61: + : 1
61: + : ''
61: + : ''\'''\'''
61: + : 27892
61: + : 2508
61: + : 15
61: + : 4
61: + : ''
61: + : 0
61: + : 175000
61: + : 175000
61: + : 4500000
61: + : 0.60466
61: + : 0.85437
61: + : 0
61: + : 0.720
61: + : 0
61: + : 0.0
61: + : 0.0
61: + : 0.1
61: + : 0
61: + : 0
61: + : 0
61: + : 0
61: + : 0
61: + : 0
61: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
61: Run vars: id 2508 gpus 4 mparams ''
61: ++ date +%s
61: + START=1665667533
61: ++ date '+%Y-%m-%d %r'
55: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
55: ++ export BATCHSIZE=48
55: ++ BATCHSIZE=48
55: ++ export GRADIENT_STEPS=1
55: ++ GRADIENT_STEPS=1
55: ++ export LR=0.0020992
55: ++ LR=0.0020992
55: ++ export MAX_SAMPLES_TERMINATION=4500000
55: ++ MAX_SAMPLES_TERMINATION=4500000
55: ++ export MAX_STEPS=1059
55: ++ MAX_STEPS=1059
55: ++ export OPT_LAMB_BETA_1=0.60466
55: ++ OPT_LAMB_BETA_1=0.60466
55: ++ export OPT_LAMB_BETA_2=0.85437
55: ++ OPT_LAMB_BETA_2=0.85437
55: ++ export START_WARMUP_STEP=0
55: ++ START_WARMUP_STEP=0
55: ++ export WARMUP_PROPORTION=0.0
55: ++ WARMUP_PROPORTION=0.0
55: ++ export WEIGHT_DECAY_RATE=0.1
55: ++ WEIGHT_DECAY_RATE=0.1
55: ++ export INIT_LOSS_SCALE=4096.0
55: ++ INIT_LOSS_SCALE=4096.0
55: ++ export SBATCH_NETWORK=sharp
55: ++ SBATCH_NETWORK=sharp
55: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
55: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
55: ++ export PHASE=2
55: ++ PHASE=2
55: ++ export EVAL_ITER_START_SAMPLES=175000
55: ++ EVAL_ITER_START_SAMPLES=175000
55: ++ export EVAL_ITER_SAMPLES=175000
55: ++ EVAL_ITER_SAMPLES=175000
55: ++ export DGXNNODES=16
55: ++ DGXNNODES=16
55: +++ sed 's/^config_//'
61: + START_FMT='2022-10-13 08:25:33 AM'
55: +++ sed 's/\.sh$//'
61: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
55: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
61: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
61: + '[' '!' -z '' ']'
61: + '[' 0 -gt 0 ']'
61: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
61: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
61: + PHASES=("$PHASE1" "$PHASE2")
61: + export RANK=61
61: + RANK=61
61: + export WORLD_SIZE=64
61: + WORLD_SIZE=64
61: WORLD_SIZE=64
61: + echo WORLD_SIZE=64
61: ++ cut -d - -f1
61: ++ echo 'node[022-023,027-040]'
61: ++ cut -d - -f2 -
61: ++ tr -d '['
55: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
61: + export MASTER_ADDR=node022
61: + MASTER_ADDR=node022
61: MASTER_ADDR=node022
61: + echo MASTER_ADDR=node022
61: + export MASTER_PORT=19002
61: + MASTER_PORT=19002
61: + echo HOSTNAME=node022
61: HOSTNAME=node022
61: + declare -a CMD
61: + [[ -n 1 ]]
61: + [[ 64 -gt 16 ]]
61: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
61: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
61: =0     --bert_config_path=/workspace/phase1/bert_config.json '
61: + '[' -n 1 ']'
61: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
61: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
61: + [[ 0 != 1 ]]
61: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
61: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
61: + [[ '' -ge 1 ]]
61: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
61: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
61: + [[ 0 != 0 ]]
61: + '[' '' = apiLog.sh ']'
61: + '[' '' = 1 ']'
61: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
61:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=27892'
61: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
61: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=27892
55: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
55: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
55: ++ export WALLTIME_MINUTES=15
55: ++ WALLTIME_MINUTES=15
55: ++ export WALLTIME=20
55: ++ WALLTIME=20
55: ++ export DGXNGPU=4
55: ++ DGXNGPU=4
55: ++ export DGXSOCKETCORES=64
55: ++ DGXSOCKETCORES=64
55: ++ export DGXNSOCKET=2
55: ++ DGXNSOCKET=2
55: ++ export DGXHT=1
55: ++ DGXHT=1
55: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
55: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
55: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
55: ++ export MLPERF_SUBMISSION_ORG=Dell
55: ++ MLPERF_SUBMISSION_ORG=Dell
55: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
55: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
55: ++ export OMP_NUM_THREADS=8
55: ++ OMP_NUM_THREADS=8
55: + ulimit -Sn 100000
55: + '[' '' = 1 ']'
55: + : 48
55: + : 1
55: + : 0.0020992
55: + : 1059
55: + : 2
55: + : 3
55: + : ''
55: + : ''\'''\'''
55: + : 22595
55: + : 2508
55: + : 13
55: + : 4
55: + : ''
55: + : 0
55: + : 175000
55: + : 175000
55: + : 4500000
55: + : 0.60466
55: + : 0.85437
55: + : 0
55: + : 0.720
55: + : 0
55: + : 0.0
55: + : 0.0
55: + : 0.1
55: + : 0
55: + : 0
55: + : 0
55: + : 0
55: + : 0
55: + : 0
55: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
55: Run vars: id 2508 gpus 4 mparams ''
55: ++ date +%s
62: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
62: ++ export BATCHSIZE=48
62: ++ BATCHSIZE=48
62: ++ export GRADIENT_STEPS=1
62: ++ GRADIENT_STEPS=1
62: ++ export LR=0.0020992
62: ++ LR=0.0020992
62: ++ export MAX_SAMPLES_TERMINATION=4500000
62: ++ MAX_SAMPLES_TERMINATION=4500000
62: ++ export MAX_STEPS=1059
62: ++ MAX_STEPS=1059
62: ++ export OPT_LAMB_BETA_1=0.60466
62: ++ OPT_LAMB_BETA_1=0.60466
62: ++ export OPT_LAMB_BETA_2=0.85437
62: ++ OPT_LAMB_BETA_2=0.85437
62: ++ export START_WARMUP_STEP=0
62: ++ START_WARMUP_STEP=0
62: ++ export WARMUP_PROPORTION=0.0
62: ++ WARMUP_PROPORTION=0.0
62: ++ export WEIGHT_DECAY_RATE=0.1
62: ++ WEIGHT_DECAY_RATE=0.1
62: ++ export INIT_LOSS_SCALE=4096.0
62: ++ INIT_LOSS_SCALE=4096.0
62: ++ export SBATCH_NETWORK=sharp
62: ++ SBATCH_NETWORK=sharp
62: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
62: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
62: ++ export PHASE=2
62: ++ PHASE=2
62: ++ export EVAL_ITER_START_SAMPLES=175000
62: ++ EVAL_ITER_START_SAMPLES=175000
62: ++ export EVAL_ITER_SAMPLES=175000
62: ++ EVAL_ITER_SAMPLES=175000
62: ++ export DGXNNODES=16
62: ++ DGXNNODES=16
62: +++ sed 's/^config_//'
62: +++ sed 's/\.sh$//'
62: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
55: + START=1665667533
55: ++ date '+%Y-%m-%d %r'
55: + START_FMT='2022-10-13 08:25:33 AM'
55: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
55: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
55: + '[' '!' -z '' ']'
55: + '[' 0 -gt 0 ']'
55: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
55: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
55: + PHASES=("$PHASE1" "$PHASE2")
55: + export RANK=55
55: + RANK=55
55: + export WORLD_SIZE=64
55: + WORLD_SIZE=64
55: WORLD_SIZE=64
55: + echo WORLD_SIZE=64
62: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
55: ++ cut -d - -f1
55: ++ echo 'node[022-023,027-040]'
55: ++ cut -d - -f2 -
55: ++ tr -d '['
62: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
62: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
62: ++ export WALLTIME_MINUTES=15
62: ++ WALLTIME_MINUTES=15
62: ++ export WALLTIME=20
62: ++ WALLTIME=20
62: ++ export DGXNGPU=4
62: ++ DGXNGPU=4
62: ++ export DGXSOCKETCORES=64
62: ++ DGXSOCKETCORES=64
62: ++ export DGXNSOCKET=2
62: ++ DGXNSOCKET=2
62: ++ export DGXHT=1
62: ++ DGXHT=1
62: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
62: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
62: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
62: ++ export MLPERF_SUBMISSION_ORG=Dell
62: ++ MLPERF_SUBMISSION_ORG=Dell
62: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
62: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
62: ++ export OMP_NUM_THREADS=8
62: ++ OMP_NUM_THREADS=8
62: + ulimit -Sn 100000
62: + '[' '' = 1 ']'
62: + : 48
62: + : 1
62: + : 0.0020992
62: + : 1059
62: + : 2
62: + : 2
62: + : ''
55: + export MASTER_ADDR=node022
55: + MASTER_ADDR=node022
62: + : ''\'''\'''
62: + : 25375
62: + : 2508
62: + : 15
62: + : 4
62: + : ''
62: + : 0
62: + : 175000
55: MASTER_ADDR=node022
62: + : 175000
62: + : 4500000
55: + echo MASTER_ADDR=node022
55: HOSTNAME=node022
62: + : 0.60466
55: + export MASTER_PORT=19002
55: + MASTER_PORT=19002
62: + : 0.85437
62: + : 0
55: + echo HOSTNAME=node022
62: + : 0.720
55: + declare -a CMD
62: + : 0
55: + [[ -n 3 ]]
62: + : 0.0
62: + : 0.0
62: + : 0.1
62: + : 0
62: + : 0
62: + : 0
62: + : 0
62: + : 0
62: + : 0
62: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
62: Run vars: id 2508 gpus 4 mparams ''
55: + [[ 64 -gt 16 ]]
55: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
55: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
55: =0     --bert_config_path=/workspace/phase1/bert_config.json '
55: + '[' -n 3 ']'
55: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
55: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
55: + [[ 0 != 1 ]]
55: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
55: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
62: ++ date +%s
55: + [[ '' -ge 1 ]]
55: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
55: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
55: + [[ 0 != 0 ]]
55: + '[' '' = apiLog.sh ']'
55: + '[' '' = 1 ']'
55: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
55:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=22595'
55: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
55: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=22595
62: + START=1665667533
62: ++ date '+%Y-%m-%d %r'
62: + START_FMT='2022-10-13 08:25:33 AM'
62: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
62: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
62: + '[' '!' -z '' ']'
62: + '[' 0 -gt 0 ']'
62: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
62: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
62: + PHASES=("$PHASE1" "$PHASE2")
62: + export RANK=62
62: + RANK=62
62: + export WORLD_SIZE=64
62: + WORLD_SIZE=64
62: WORLD_SIZE=64
62: + echo WORLD_SIZE=64
62: ++ cut -d - -f1
62: ++ cut -d - -f2 -
62: ++ tr -d '['
62: ++ echo 'node[022-023,027-040]'
62: + export MASTER_ADDR=node022
62: + MASTER_ADDR=node022
62: + echo MASTER_ADDR=node022
62: MASTER_ADDR=node022
62: + export MASTER_PORT=19002
62: + MASTER_PORT=19002
62: HOSTNAME=node022
62: + echo HOSTNAME=node022
62: + declare -a CMD
62: + [[ -n 2 ]]
62: + [[ 64 -gt 16 ]]
62: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
62: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
62: =0     --bert_config_path=/workspace/phase1/bert_config.json '
62: + '[' -n 2 ']'
62: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
62: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
62: + [[ 0 != 1 ]]
62: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
62: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
62: + [[ '' -ge 1 ]]
62: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
62: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
62: + [[ 0 != 0 ]]
62: + '[' '' = apiLog.sh ']'
62: + '[' '' = 1 ']'
62: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
62:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=25375'
62: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
62: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=25375
 0: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 1: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 2: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
63: + source ./config_16xXE8545x4A100-SXM4-40GB.sh
63: ++ export BATCHSIZE=48
63: ++ BATCHSIZE=48
63: ++ export GRADIENT_STEPS=1
63: ++ GRADIENT_STEPS=1
63: ++ export LR=0.0020992
63: ++ LR=0.0020992
63: ++ export MAX_SAMPLES_TERMINATION=4500000
63: ++ MAX_SAMPLES_TERMINATION=4500000
63: ++ export MAX_STEPS=1059
63: ++ MAX_STEPS=1059
63: ++ export OPT_LAMB_BETA_1=0.60466
63: ++ OPT_LAMB_BETA_1=0.60466
63: ++ export OPT_LAMB_BETA_2=0.85437
63: ++ OPT_LAMB_BETA_2=0.85437
63: ++ export START_WARMUP_STEP=0
63: ++ START_WARMUP_STEP=0
63: ++ export WARMUP_PROPORTION=0.0
63: ++ WARMUP_PROPORTION=0.0
63: ++ export WEIGHT_DECAY_RATE=0.1
63: ++ WEIGHT_DECAY_RATE=0.1
63: ++ export INIT_LOSS_SCALE=4096.0
63: ++ INIT_LOSS_SCALE=4096.0
63: ++ export SBATCH_NETWORK=sharp
63: ++ SBATCH_NETWORK=sharp
63: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
63: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
63: ++ export PHASE=2
63: ++ PHASE=2
63: ++ export EVAL_ITER_START_SAMPLES=175000
63: ++ EVAL_ITER_START_SAMPLES=175000
63: ++ export EVAL_ITER_SAMPLES=175000
63: ++ EVAL_ITER_SAMPLES=175000
63: ++ export DGXNNODES=16
63: ++ DGXNNODES=16
63: +++ sed 's/^config_//'
63: +++ sed 's/\.sh$//'
63: ++++ readlink -f ./config_16xXE8545x4A100-SXM4-40GB.sh
63: +++ basename /workspace/bert/config_16xXE8545x4A100-SXM4-40GB.sh
63: ++ export DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
63: ++ DGXSYSTEM=16xXE8545x4A100-SXM4-40GB
63: ++ export WALLTIME_MINUTES=15
63: ++ WALLTIME_MINUTES=15
63: ++ export WALLTIME=20
63: ++ WALLTIME=20
63: ++ export DGXNGPU=4
63: ++ DGXNGPU=4
63: ++ export DGXSOCKETCORES=64
63: ++ DGXSOCKETCORES=64
63: ++ export DGXNSOCKET=2
63: ++ DGXNSOCKET=2
63: ++ export DGXHT=1
63: ++ DGXHT=1
63: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
63: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
63: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
63: ++ export MLPERF_SUBMISSION_ORG=Dell
63: ++ MLPERF_SUBMISSION_ORG=Dell
63: ++ export MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
63: ++ MLPERF_SUBMISSION_PLATFORM=16xXE8545x4A100-SXM4-40GB
63: ++ export OMP_NUM_THREADS=8
63: ++ OMP_NUM_THREADS=8
63: + ulimit -Sn 100000
63: + '[' '' = 1 ']'
63: + : 48
63: + : 1
63: + : 0.0020992
63: + : 1059
63: + : 2
63: + : 3
63: + : ''
63: + : ''\'''\'''
63: + : 4595
63: + : 2508
63: + : 15
63: + : 4
63: + : ''
63: + : 0
63: + : 175000
63: + : 175000
63: + : 4500000
63: + : 0.60466
63: + : 0.85437
63: + : 0
63: + : 0.720
63: + : 0
63: + : 0.0
63: + : 0.0
63: + : 0.1
63: + : 0
63: + : 0
63: + : 0
63: + : 0
63: + : 0
63: + : 0
63: Run vars: id 2508 gpus 4 mparams ''
63: + echo 'Run vars: id 2508 gpus 4 mparams '\'''\'''
63: ++ date +%s
63: + START=1665667533
63: ++ date '+%Y-%m-%d %r'
63: + START_FMT='2022-10-13 08:25:33 AM'
63: STARTING TIMING RUN AT 2022-10-13 08:25:33 AM
63: + echo 'STARTING TIMING RUN AT 2022-10-13 08:25:33 AM'
63: + '[' '!' -z '' ']'
63: + '[' 0 -gt 0 ']'
63: + PHASE1='    --train_batch_size=48     --learning_rate=0.0020992     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
63: + PHASE2='    --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
63: + PHASES=("$PHASE1" "$PHASE2")
63: + export RANK=63
63: + RANK=63
63: + export WORLD_SIZE=64
63: + WORLD_SIZE=64
63: + echo WORLD_SIZE=64
63: WORLD_SIZE=64
63: ++ cut -d - -f1
63: ++ echo 'node[022-023,027-040]'
63: ++ cut -d - -f2 -
63: ++ tr -d '['
63: + export MASTER_ADDR=node022
63: + MASTER_ADDR=node022
63: MASTER_ADDR=node022
63: + echo MASTER_ADDR=node022
63: + export MASTER_PORT=19002
63: + MASTER_PORT=19002
63: + echo HOSTNAME=node022
63: HOSTNAME=node022
63: + declare -a CMD
63: + [[ -n 3 ]]
63: + [[ 64 -gt 16 ]]
63: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
63: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
63: =0     --bert_config_path=/workspace/phase1/bert_config.json '
63: + '[' -n 3 ']'
63: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
63: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
63: + [[ 0 != 1 ]]
63: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
63: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
63: + [[ '' -ge 1 ]]
63: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq
63: =0     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
63: + [[ 0 != 0 ]]
63: + '[' '' = apiLog.sh ']'
63: + '[' '' = 1 ']'
63: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.0020992     --opt_lamb_beta_1=0.60466     --opt_lamb_beta_2=0.85437     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=1059     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.1     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0 
63:     --bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=4595'
63: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.0020992 --opt_lamb_beta_1=0.60466 --opt_lamb_beta_2=0.85437 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=1059 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.1 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp1
63: 6 --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=4595
 3: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
57: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
10: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 8: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
28: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
30: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
56: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 4: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
59: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
11: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
31: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
24: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
34: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
35: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 7: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
32: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
27: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
26: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
48: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
50: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 6: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
51: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
39: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
36: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
18: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
19: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
37: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
17: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
22: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
21: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
43: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
41: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
23: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
40: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
46: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
44: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
52: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
45: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
14: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
13: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
15: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
29: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
54: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 9: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
58: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
53: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
33: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 5: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
49: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
25: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
60: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
16: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
42: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
38: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
20: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
12: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
61: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
47: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
62: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
55: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
63: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 1: :::MLLOG {"namespace": "", "time_ms": 1665667535580, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667535580, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 2: :::MLLOG {"namespace": "", "time_ms": 1665667535580, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 3: :::MLLOG {"namespace": "", "time_ms": 1665667535580, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 4: :::MLLOG {"namespace": "", "time_ms": 1665667535827, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 5: :::MLLOG {"namespace": "", "time_ms": 1665667535827, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 6: :::MLLOG {"namespace": "", "time_ms": 1665667535827, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 7: :::MLLOG {"namespace": "", "time_ms": 1665667535827, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
30: :::MLLOG {"namespace": "", "time_ms": 1665667535840, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
31: :::MLLOG {"namespace": "", "time_ms": 1665667535840, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
29: :::MLLOG {"namespace": "", "time_ms": 1665667535840, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
28: :::MLLOG {"namespace": "", "time_ms": 1665667535840, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
33: :::MLLOG {"namespace": "", "time_ms": 1665667535862, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
35: :::MLLOG {"namespace": "", "time_ms": 1665667535862, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
34: :::MLLOG {"namespace": "", "time_ms": 1665667535862, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
32: :::MLLOG {"namespace": "", "time_ms": 1665667535862, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
49: :::MLLOG {"namespace": "", "time_ms": 1665667535902, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
51: :::MLLOG {"namespace": "", "time_ms": 1665667535902, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
50: :::MLLOG {"namespace": "", "time_ms": 1665667535902, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
48: :::MLLOG {"namespace": "", "time_ms": 1665667535902, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
56: :::MLLOG {"namespace": "", "time_ms": 1665667535904, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
58: :::MLLOG {"namespace": "", "time_ms": 1665667535904, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
59: :::MLLOG {"namespace": "", "time_ms": 1665667535904, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
57: :::MLLOG {"namespace": "", "time_ms": 1665667535904, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
17: :::MLLOG {"namespace": "", "time_ms": 1665667535916, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
18: :::MLLOG {"namespace": "", "time_ms": 1665667535916, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
19: :::MLLOG {"namespace": "", "time_ms": 1665667535916, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 8: :::MLLOG {"namespace": "", "time_ms": 1665667535918, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 9: :::MLLOG {"namespace": "", "time_ms": 1665667535918, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
11: :::MLLOG {"namespace": "", "time_ms": 1665667535918, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
10: :::MLLOG {"namespace": "", "time_ms": 1665667535918, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
16: :::MLLOG {"namespace": "", "time_ms": 1665667535916, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
24: :::MLLOG {"namespace": "", "time_ms": 1665667535919, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
26: :::MLLOG {"namespace": "", "time_ms": 1665667535919, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
27: :::MLLOG {"namespace": "", "time_ms": 1665667535919, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
25: :::MLLOG {"namespace": "", "time_ms": 1665667535919, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
37: :::MLLOG {"namespace": "", "time_ms": 1665667536033, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
38: :::MLLOG {"namespace": "", "time_ms": 1665667536033, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
39: :::MLLOG {"namespace": "", "time_ms": 1665667536033, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
36: :::MLLOG {"namespace": "", "time_ms": 1665667536033, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
44: :::MLLOG {"namespace": "", "time_ms": 1665667536039, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
46: :::MLLOG {"namespace": "", "time_ms": 1665667536039, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
45: :::MLLOG {"namespace": "", "time_ms": 1665667536039, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
47: :::MLLOG {"namespace": "", "time_ms": 1665667536039, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
53: :::MLLOG {"namespace": "", "time_ms": 1665667536051, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
55: :::MLLOG {"namespace": "", "time_ms": 1665667536051, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
54: :::MLLOG {"namespace": "", "time_ms": 1665667536051, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
52: :::MLLOG {"namespace": "", "time_ms": 1665667536051, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
43: :::MLLOG {"namespace": "", "time_ms": 1665667536057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
21: :::MLLOG {"namespace": "", "time_ms": 1665667536057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
23: :::MLLOG {"namespace": "", "time_ms": 1665667536057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
41: :::MLLOG {"namespace": "", "time_ms": 1665667536057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
22: :::MLLOG {"namespace": "", "time_ms": 1665667536057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
40: :::MLLOG {"namespace": "", "time_ms": 1665667536057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
20: :::MLLOG {"namespace": "", "time_ms": 1665667536057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
14: :::MLLOG {"namespace": "", "time_ms": 1665667536060, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
12: :::MLLOG {"namespace": "", "time_ms": 1665667536060, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
15: :::MLLOG {"namespace": "", "time_ms": 1665667536060, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
13: :::MLLOG {"namespace": "", "time_ms": 1665667536060, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
42: :::MLLOG {"namespace": "", "time_ms": 1665667536057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
61: :::MLLOG {"namespace": "", "time_ms": 1665667536128, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
62: :::MLLOG {"namespace": "", "time_ms": 1665667536128, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
63: :::MLLOG {"namespace": "", "time_ms": 1665667536128, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
60: :::MLLOG {"namespace": "", "time_ms": 1665667536128, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 0: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536191, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536191, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536191, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536191, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536191, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "16xXE8545x4A100-SXM4-40GB", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536191, "event_type": "POINT_IN_TIME", "key": "seed", "value": 20189, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1188}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536191, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3072, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1190}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536192, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536192, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1194}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536192, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1196}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536192, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 1059.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1198}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667536192, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1200}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, average_packing_rate=1, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=4, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_gemm_gelu=True, fused_mha=False, g
 0: radient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0020992, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_pack_factor=1, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=1059.0, min_samples_to_start_checkpoints=3000000, n_gpu=64, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.60466, opt_lamb_beta_2=0.85437, output_dir='/results', packed_samples=False, pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, seed=20189, skip_checkpoint=True, start_warmup_step=0.0, synthetic_input=False, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_step
 0: s=0.0, weight_decay_rate=0.1)
 8: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
26: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 9: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
 5: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
10: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
11: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
25: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
27: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
24: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 4: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 6: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
 7: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
30: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
49: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
28: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
29: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
31: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
51: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
55: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
52: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
54: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
53: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
50: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
48: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
61: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
62: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
20: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
60: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
63: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
40: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
38: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
41: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
43: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
22: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
23: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
21: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
39: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
37: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
46: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
58: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
36: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
44: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
42: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
45: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
47: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
57: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
59: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
32: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
56: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
17: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
35: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
34: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
33: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
18: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
19: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
16: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
 1: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
 3: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
 2: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
13: device: cuda:1 n_gpu: 64, distributed training: True, 16-bits training: True
14: device: cuda:2 n_gpu: 64, distributed training: True, 16-bits training: True
12: device: cuda:0 n_gpu: 64, distributed training: True, 16-bits training: True
15: device: cuda:3 n_gpu: 64, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538054, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/word_embeddings"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/position_embeddings"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/token_type_embeddings"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538056, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538057, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538058, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538059, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538060, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538061, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538063, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538064, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538065, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538066, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538067, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538068, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538069, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538071, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538072, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538073, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538074, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538075, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538076, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/pooler/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/pooler/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/output_bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/seq_relationship/output_weights"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/seq_relationship/output_bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667538411, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0020992, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 817}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667541305, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 853}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667541306, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.60466, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667541306, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.85437, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 857}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667541306, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 858}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667541456, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667541457, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667541458, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
 2: Torch distributed is available.
 2: Torch distributed is initialized.
31: Torch distributed is available.
31: Torch distributed is initialized.
30: Torch distributed is available.
30: Torch distributed is initialized.
33: Torch distributed is available.
33: Torch distributed is initialized.
34: Torch distributed is available.
34: Torch distributed is initialized.
 9: Torch distributed is available.
 9: Torch distributed is initialized.
29: Torch distributed is available.
29: Torch distributed is initialized.
14: Torch distributed is available.
14: Torch distributed is initialized.
10: Torch distributed is available.
10: Torch distributed is initialized.
 5: Torch distributed is available.
 5: Torch distributed is initialized.
 3: Torch distributed is available.
 3: Torch distributed is initialized.
 0: Torch distributed is available.
 0: Torch distributed is initialized.
11: Torch distributed is available.
11: Torch distributed is initialized.
50: Torch distributed is available.
50: Torch distributed is initialized.
45: Torch distributed is available.
45: Torch distributed is initialized.
17: Torch distributed is available.
17: Torch distributed is initialized.
35: Torch distributed is available.
35: Torch distributed is initialized.
51: Torch distributed is available.
51: Torch distributed is initialized.
46: Torch distributed is available.
46: Torch distributed is initialized.
49: Torch distributed is available.
49: Torch distributed is initialized.
43: Torch distributed is available.
43: Torch distributed is initialized.
23: Torch distributed is available.
23: Torch distributed is initialized.
37: Torch distributed is available.
37: Torch distributed is initialized.
 7: Torch distributed is available.
 7: Torch distributed is initialized.
 6: Torch distributed is available.
 6: Torch distributed is initialized.
19: Torch distributed is available.
19: Torch distributed is initialized.
47: Torch distributed is available.
47: Torch distributed is initialized.
22: Torch distributed is available.
22: Torch distributed is initialized.
41: Torch distributed is available.
41: Torch distributed is initialized.
15: Torch distributed is available.
15: Torch distributed is initialized.
21: Torch distributed is available.
21: Torch distributed is initialized.
57: Torch distributed is available.
57: Torch distributed is initialized.
58: Torch distributed is available.
58: Torch distributed is initialized.
38: Torch distributed is available.
38: Torch distributed is initialized.
59: Torch distributed is available.
59: Torch distributed is initialized.
27: Torch distributed is available.
27: Torch distributed is initialized.
25: Torch distributed is available.
25: Torch distributed is initialized.
26: Torch distributed is available.
26: Torch distributed is initialized.
61: Torch distributed is available.
61: Torch distributed is initialized.
63: Torch distributed is available.
63: Torch distributed is initialized.
42: Torch distributed is available.
42: Torch distributed is initialized.
39: Torch distributed is available.
39: Torch distributed is initialized.
62: Torch distributed is available.
62: Torch distributed is initialized.
53: Torch distributed is available.
53: Torch distributed is initialized.
54: Torch distributed is available.
54: Torch distributed is initialized.
 8: Torch distributed is available.
 8: Torch distributed is initialized.
55: Torch distributed is available.
55: Torch distributed is initialized.
44: Torch distributed is available.
44: Torch distributed is initialized.
60: Torch distributed is available.
60: Torch distributed is initialized.
40: Torch distributed is available.
40: Torch distributed is initialized.
56: Torch distributed is available.
56: Torch distributed is initialized.
28: Torch distributed is available.
28: Torch distributed is initialized.
24: Torch distributed is available.
24: Torch distributed is initialized.
36: Torch distributed is available.
36: Torch distributed is initialized.
20: Torch distributed is available.
20: Torch distributed is initialized.
 1: Torch distributed is available.
 1: Torch distributed is initialized.
48: Torch distributed is available.
48: Torch distributed is initialized.
12: Torch distributed is available.
12: Torch distributed is initialized.
32: Torch distributed is available.
32: Torch distributed is initialized.
 4: Torch distributed is available.
 4: Torch distributed is initialized.
18: Torch distributed is available.
18: Torch distributed is initialized.
16: Torch distributed is available.
16: Torch distributed is initialized.
52: Torch distributed is available.
52: Torch distributed is initialized.
13: Torch distributed is available.
13: Torch distributed is initialized.
 0: :::MLLOG {"namespace": "", "time_ms": 1665667545559, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1521}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667545559, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1521}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667545572, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1533, "epoch_num": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667545572, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1535, "first_epoch_num": 1, "epoch_count": 1}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, average_packing_rate=1, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=4, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_gemm_gelu=True, fused_mha=False, g
 0: radient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.0020992, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_pack_factor=1, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=1059.0, min_samples_to_start_checkpoints=3000000, n_gpu=64, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.60466, opt_lamb_beta_2=0.85437, output_dir='/results', packed_samples=False, pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=20189, skip_checkpoint=True, start_warmup_step=0.0, synthetic_input=False, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0
 0: .0, warmup_steps=0.0, weight_decay_rate=0.1)
 0: epoch: 1
 0: :::MLLOG {"namespace": "", "time_ms": 1665667545573, "event_type": "POINT_IN_TIME", "key": "data_file", "value": "/workspace/data_phase2/part_01940_of_04320.hdf5", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1569}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667560244, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3698483407497406, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 175104}}
 0: {'global_steps': 57, 'eval_loss': 4.146492004394531, 'eval_mlm_accuracy': 0.3698483407497406}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667573137, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3795322775840759, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 350208}}
 0: {'global_steps': 114, 'eval_loss': 4.045576572418213, 'eval_mlm_accuracy': 0.3795322775840759}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667586033, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.40187281370162964, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 525312}}
 0: {'global_steps': 171, 'eval_loss': 3.8545780181884766, 'eval_mlm_accuracy': 0.40187281370162964}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667598936, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4264434278011322, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 700416}}
 0: {'global_steps': 228, 'eval_loss': 3.604198932647705, 'eval_mlm_accuracy': 0.4264434278011322}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667611876, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4806753396987915, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 875520}}
 0: {'global_steps': 285, 'eval_loss': 3.136798143386841, 'eval_mlm_accuracy': 0.4806753396987915}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667624790, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5773582458496094, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1050624}}
 0: {'global_steps': 342, 'eval_loss': 2.3449957370758057, 'eval_mlm_accuracy': 0.5773582458496094}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667637725, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6810092329978943, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1225728}}
 0: {'global_steps': 399, 'eval_loss': 1.5556713342666626, 'eval_mlm_accuracy': 0.6810092329978943}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667650659, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7049773931503296, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1400832}}
 0: {'global_steps': 456, 'eval_loss': 1.3944584131240845, 'eval_mlm_accuracy': 0.7049773931503296}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667663593, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.710472047328949, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1575936}}
 0: {'global_steps': 513, 'eval_loss': 1.3635807037353516, 'eval_mlm_accuracy': 0.710472047328949}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667676519, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7128235697746277, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1751040}}
 0: {'global_steps': 570, 'eval_loss': 1.3486064672470093, 'eval_mlm_accuracy': 0.7128235697746277}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667689464, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7147781252861023, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1926144}}
 0: {'global_steps': 627, 'eval_loss': 1.336409091949463, 'eval_mlm_accuracy': 0.7147781252861023}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667702405, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7155113220214844, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2101248}}
 0: {'global_steps': 684, 'eval_loss': 1.3272442817687988, 'eval_mlm_accuracy': 0.7155113220214844}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667715362, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7167256474494934, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2276352}}
 0: {'global_steps': 741, 'eval_loss': 1.3215088844299316, 'eval_mlm_accuracy': 0.7167256474494934}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667729137, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7182014584541321, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2451456}}
 0: {'global_steps': 798, 'eval_loss': 1.3143856525421143, 'eval_mlm_accuracy': 0.7182014584541321}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667742399, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7191308736801147, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2626560}}
 0: {'global_steps': 855, 'eval_loss': 1.310445785522461, 'eval_mlm_accuracy': 0.7191308736801147}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667755658, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7193737030029297, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2801664}}
 0: {'global_steps': 912, 'eval_loss': 1.307234764099121, 'eval_mlm_accuracy': 0.7193737030029297}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667768901, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7200929522514343, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2976768}}
 0: {'global_steps': 969, 'eval_loss': 1.3038862943649292, 'eval_mlm_accuracy': 0.7200929522514343}
 0: 0.720093 > 0.720000, Target MLM Accuracy reached at 969
 0: (1, 969.0) {'final_loss': 0.0}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667768949, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1850, "first_epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667768949, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1853, "epoch_num": 2976768}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667768949, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 2976768, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1861}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667768949, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665667768968, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1867, "status": "success"}}
 0: {'e2e_time': 233.46267127990723, 'training_sequences_per_second': 14400.4400276311, 'final_loss': 0.0, 'raw_train_time': 225.91309666633606}
 3: + set +x
 3: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
 3: RESULT,bert,11897,237,root,2022-10-13 08:25:32 AM
19: + set +x
19: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
19: RESULT,bert,11593,237,root,2022-10-13 08:25:32 AM
 0: + set +x
 0: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
 0: RESULT,bert,20189,237,root,2022-10-13 08:25:32 AM
50: + set +x
50: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
50: RESULT,bert,2968,237,root,2022-10-13 08:25:32 AM
 5: + set +x
 5: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
 5: RESULT,bert,22881,237,root,2022-10-13 08:25:32 AM
34: + set +x
34: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
34: RESULT,bert,6334,237,root,2022-10-13 08:25:32 AM
57: + set +x
45: + set +x
57: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
57: RESULT,bert,16398,237,root,2022-10-13 08:25:32 AM
30: + set +x
45: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
45: RESULT,bert,18733,236,root,2022-10-13 08:25:33 AM
27: + set +x
30: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
30: RESULT,bert,2484,237,root,2022-10-13 08:25:32 AM
55: + set +x
22: + set +x
12: + set +x
27: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
27: RESULT,bert,9153,237,root,2022-10-13 08:25:32 AM
55: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
55: RESULT,bert,22595,236,root,2022-10-13 08:25:33 AM
22: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
22: RESULT,bert,10354,237,root,2022-10-13 08:25:32 AM
12: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
12: RESULT,bert,13629,236,root,2022-10-13 08:25:33 AM
 9: + set +x
 9: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
 9: RESULT,bert,19532,237,root,2022-10-13 08:25:32 AM
49: + set +x
49: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
49: RESULT,bert,7691,237,root,2022-10-13 08:25:32 AM
41: + set +x
38: + set +x
41: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
41: RESULT,bert,15141,237,root,2022-10-13 08:25:32 AM
61: + set +x
38: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
38: RESULT,bert,26,237,root,2022-10-13 08:25:32 AM
 6: + set +x
61: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
61: RESULT,bert,27892,236,root,2022-10-13 08:25:33 AM
 6: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
 6: RESULT,bert,9648,236,root,2022-10-13 08:25:33 AM
17: + set +x
17: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
17: RESULT,bert,29761,237,root,2022-10-13 08:25:32 AM
35: + set +x
35: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
35: RESULT,bert,9385,237,root,2022-10-13 08:25:32 AM
59: + set +x
26: + set +x
54: + set +x
59: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
59: RESULT,bert,30769,237,root,2022-10-13 08:25:32 AM
26: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
26: RESULT,bert,22524,237,root,2022-10-13 08:25:32 AM
21: + set +x
46: + set +x
54: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
54: RESULT,bert,30118,237,root,2022-10-13 08:25:32 AM
21: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
21: RESULT,bert,2250,237,root,2022-10-13 08:25:32 AM
46: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
46: RESULT,bert,13123,237,root,2022-10-13 08:25:32 AM
14: + set +x
14: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
14: RESULT,bert,27654,237,root,2022-10-13 08:25:32 AM
 2: + set +x
 2: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
 2: RESULT,bert,6609,237,root,2022-10-13 08:25:32 AM
31: + set +x
11: + set +x
31: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
31: RESULT,bert,11478,237,root,2022-10-13 08:25:32 AM
11: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
11: RESULT,bert,4557,237,root,2022-10-13 08:25:32 AM
37: + set +x
 7: + set +x
37: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
37: RESULT,bert,21550,236,root,2022-10-13 08:25:33 AM
 7: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
 7: RESULT,bert,6519,237,root,2022-10-13 08:25:32 AM
63: + set +x
43: + set +x
63: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
63: RESULT,bert,4595,236,root,2022-10-13 08:25:33 AM
43: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
43: RESULT,bert,28056,237,root,2022-10-13 08:25:32 AM
33: + set +x
33: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
33: RESULT,bert,26375,237,root,2022-10-13 08:25:32 AM
53: + set +x
25: + set +x
53: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
53: RESULT,bert,19021,237,root,2022-10-13 08:25:32 AM
25: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
25: RESULT,bert,5718,236,root,2022-10-13 08:25:33 AM
58: + set +x
47: + set +x
58: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
58: RESULT,bert,23659,237,root,2022-10-13 08:25:32 AM
47: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
47: RESULT,bert,17587,237,root,2022-10-13 08:25:32 AM
23: + set +x
18: + set +x
23: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
23: RESULT,bert,31002,237,root,2022-10-13 08:25:32 AM
51: + set +x
15: + set +x
18: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
18: RESULT,bert,5332,237,root,2022-10-13 08:25:32 AM
51: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
51: RESULT,bert,32190,236,root,2022-10-13 08:25:33 AM
15: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
15: RESULT,bert,2984,237,root,2022-10-13 08:25:32 AM
29: + set +x
29: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
29: RESULT,bert,12383,237,root,2022-10-13 08:25:32 AM
10: + set +x
39: + set +x
10: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
10: RESULT,bert,12599,237,root,2022-10-13 08:25:32 AM
39: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
39: RESULT,bert,19665,237,root,2022-10-13 08:25:32 AM
62: + set +x
62: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
62: RESULT,bert,25375,236,root,2022-10-13 08:25:33 AM
42: + set +x
42: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
42: RESULT,bert,31764,236,root,2022-10-13 08:25:33 AM
 1: + set +x
 1: ENDING TIMING RUN AT 2022-10-13 08:29:29 AM
 1: RESULT,bert,12433,237,root,2022-10-13 08:25:32 AM
44: + set +x
52: + set +x
44: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
44: RESULT,bert,24819,238,root,2022-10-13 08:25:32 AM
52: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
52: RESULT,bert,17288,238,root,2022-10-13 08:25:32 AM
32: + set +x
32: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
32: RESULT,bert,21354,238,root,2022-10-13 08:25:32 AM
 4: + set +x
 4: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
 4: RESULT,bert,16599,238,root,2022-10-13 08:25:32 AM
20: + set +x
20: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
20: RESULT,bert,27432,237,root,2022-10-13 08:25:33 AM
24: + set +x
13: + set +x
24: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
24: RESULT,bert,24998,238,root,2022-10-13 08:25:32 AM
13: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
13: RESULT,bert,22271,238,root,2022-10-13 08:25:32 AM
48: + set +x
48: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
48: RESULT,bert,5868,238,root,2022-10-13 08:25:32 AM
16: + set +x
16: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
16: RESULT,bert,23551,237,root,2022-10-13 08:25:33 AM
56: + set +x
60: + set +x
28: + set +x
56: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
56: RESULT,bert,4603,238,root,2022-10-13 08:25:32 AM
60: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
60: RESULT,bert,13450,237,root,2022-10-13 08:25:33 AM
28: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
28: RESULT,bert,150,238,root,2022-10-13 08:25:32 AM
 8: + set +x
 8: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
 8: RESULT,bert,28765,238,root,2022-10-13 08:25:32 AM
36: + set +x
36: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
36: RESULT,bert,9949,238,root,2022-10-13 08:25:32 AM
40: + set +x
40: ENDING TIMING RUN AT 2022-10-13 08:29:30 AM
40: RESULT,bert,16855,238,root,2022-10-13 08:25:32 AM
